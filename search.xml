<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>LSTM时序预测</title>
    <url>/2023/10/28/LSTM%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>【Pytorch基础】从numpy到tensor学习神经网络常用工具</title>
    <url>/2023/10/16/PyTorch%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h1><h1 id="一、Numpy基础"><a href="#一、Numpy基础" class="headerlink" title="一、Numpy基础"></a>一、Numpy基础</h1><p>python本身含有列表list和数组array：</p>
<p>列表list：存储索引的项目列表,元素可以是任何对象，保存的是对象的指针</p>
<pre><code>            eg: words = [&quot;Hello&quot;,&quot;word&quot;]、number = [1,2,3]

            对于数值运算，list有三个元素就需要三个指针，浪费内存资源
</code></pre>
<p>数组array：保存数值，和一维数组类似，不支持多维：<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img-blog.csdnimg.cn/20200501183930210.png#pic_center"
                     
                ></p>
<p>numpy提供了<a class="link"   href="https://so.csdn.net/so/search?q=ndarray&spm=1001.2101.3001.7020" >ndarray <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>和ufunc弥补了python本身所带工具的不足：</p>
<p><strong>ndarray：存储单一数据类型的多维数组，封装了许多常用的数学运算函数</strong></p>
<p><strong>ufunc：对数组进行处理的函数</strong></p>
<h2 id="1、numpy生成ndarray的几种方法"><a href="#1、numpy生成ndarray的几种方法" class="headerlink" title="1、numpy生成ndarray的几种方法"></a>1、numpy生成ndarray的几种方法</h2><p>以列表为例：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">#将列表转换成ndarray</span><br><span class="line">import numpy as np</span><br><span class="line">lst1 = [3.14, 2.17, 0, 1, 2]</span><br><span class="line">nd1 =np.array(lst1)</span><br><span class="line">print(nd1)</span><br><span class="line"># [3.14 2.17 0. 1. 2. ]</span><br><span class="line">print(type(nd1))</span><br><span class="line"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span><br><span class="line"> </span><br><span class="line">#嵌套列表转换成多为ndarray</span><br><span class="line">import numpy as np</span><br><span class="line">lst2 = [[3.14, 2.17, 0, 1, 2], [1, 2, 3, 4, 5]]</span><br><span class="line">nd2 =np.array(lst2)</span><br><span class="line">print(nd2)</span><br><span class="line"># [[3.14 2.17 0. 1. 2. ]</span><br><span class="line"># [1. 2. 3. 4. 5. ]]</span><br><span class="line">print(type(nd2))</span><br><span class="line"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span><br></pre></td></tr></table></figure></div>

<h2 id="2-numpy元素获取"><a href="#2-numpy元素获取" class="headerlink" title="2.numpy元素获取"></a>2.numpy元素获取</h2><p>np[2::2,::3]</p>
<ol>
<li><code>2::2</code>: 这是行的高级索引。<ul>
<li><code>2</code>: 从第二行开始（Python的索引是从0开始的，所以这实际上是第三行）。</li>
<li><code>::2</code>: 每两行取一行。因此，这个部分会选择数组中的奇数行。</li>
</ul>
</li>
<li><code>::3</code>: 这是列的高级索引。<ul>
<li><code>::3</code>: 每三列取一列。因此，这个部分会选择数组中的每三列。</li>
</ul>
</li>
</ol>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.arange(<span class="number">2019</span>)</span><br><span class="line">nd11 = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#截取固定间隔数据</span></span><br><span class="line"><span class="built_in">print</span>(nd11[<span class="number">1</span>:<span class="number">6</span>:<span class="number">2</span>])</span><br><span class="line"><span class="comment">#[1 3 5]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#倒序取数</span></span><br><span class="line"><span class="built_in">print</span>(nd11[-<span class="number">4</span>:])</span><br><span class="line"><span class="comment">#[6 7 8 9]</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nd11[::-<span class="number">1</span>])</span><br><span class="line"><span class="comment">#[9 8 7 6 5 4 3 2 1 0]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#截取一个多维数组的一个区域内数据</span></span><br><span class="line">nd12=np.arange(<span class="number">16</span>).reshape([<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(nd12)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 0  1  2  3]</span></span><br><span class="line"><span class="string"> [ 4  5  6  7]</span></span><br><span class="line"><span class="string"> [ 8  9 10 11]</span></span><br><span class="line"><span class="string"> [12 13 14 15]]</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(nd12[<span class="number">1</span>:<span class="number">3</span>,<span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 5  6]</span></span><br><span class="line"><span class="string"> [ 9 10]]</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#截取一个多维数组中，数值在一个值域之内的数据</span></span><br><span class="line">nd12[(nd12&gt;<span class="number">3</span>)&amp;(nd12&lt;<span class="number">10</span>)]</span><br><span class="line"><span class="comment">#截取多维数组中，指定的行,如读取第2,3行</span></span><br><span class="line"><span class="built_in">print</span>(nd12[[<span class="number">1</span>,<span class="number">2</span>]]) <span class="comment">#或nd12[1:3,:]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 4  5  6  7]</span></span><br><span class="line"><span class="string"> [ 8  9 10 11]]&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##截取多维数组中，指定的列,如读取第2,3列</span></span><br><span class="line"><span class="built_in">print</span>(nd12[:,<span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ 1  2]</span></span><br><span class="line"><span class="string"> [ 5  6]</span></span><br><span class="line"><span class="string"> [ 9 10]</span></span><br><span class="line"><span class="string"> [13 14]]&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li></li>
</ol>
<h1 id="二、Pytorch基础"><a href="#二、Pytorch基础" class="headerlink" title="二、Pytorch基础"></a>二、Pytorch基础</h1><p>PyTorch由4个主要包组成包组成，具体如下。</p>
<ul>
<li>torch：类似于NumPy的通用数组库，可将张量类型转换为torch.cuda.TensorFloat，并在GPU上进行计算。<br>torch.autograd：用于构建计算图形并自动获取梯度的包。<br>torch.nn：具有共享层和损失函数的神经网络库。<br>torch.optim：具有通用优化算法（如SGD，Adam等）的优化包。</li>
<li>torch.autograd：用于构建计算图形并自动获取梯度的包。</li>
<li>torch.nn：具有共享层和损失函数的神经网络库。</li>
<li>torch.optim：具有通用优化算法（如SGD，Adam等）的优化包。</li>
</ul>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cuda是否可用；</span></span><br><span class="line">torch.cuda.is_available()</span><br><span class="line"><span class="comment"># 返回gpu数量；</span></span><br><span class="line">torch.cuda.device_count()</span><br><span class="line"><span class="comment"># 返回gpu名字，设备索引默认从0开始</span></span><br><span class="line">torch.cuda.get_device_name(index)  <span class="comment"># index 是索引, 默认从 0 开始</span></span><br><span class="line"><span class="comment"># 返回当前设备索引；</span></span><br><span class="line">torch.cuda.current_device()</span><br><span class="line"></span><br><span class="line">x.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line">y = <span class="number">2</span>*torch.dot(x,x)</span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line">x.grad.zero_()<span class="comment">#  重写、</span></span><br><span class="line"></span><br><span class="line">a = torch.randn(size=(), requires_grad = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></div>

<h2 id="指定GPU"><a href="#指定GPU" class="headerlink" title="指定GPU"></a>指定GPU</h2><p>代码中指定</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"># 可以同时指定多个设备（设备是真实存在的，不要指定不存在的设备）</span><br><span class="line"></span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0, 1, 2, 3&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<hr>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img-blog.csdnimg.cn/fd5f2dd87d044aaa9cb3b7cd73dd6c7a.png"
                      alt="修改tensor的形状"
                ></p>
<h2 id="nn-Sequential、nn-Module、nn-List-ModuleDict"><a href="#nn-Sequential、nn-Module、nn-List-ModuleDict" class="headerlink" title="nn.Sequential、nn.Module、nn.List_ModuleDict"></a>nn.Sequential、nn.Module、nn.List_ModuleDict</h2><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h3><p>1）nn.Sequential、nn.ModuleList、nn.ModuleDict 类都继承自 Module 类。</p>
<p>2）nn.Sequential、nn.ModuleList、nn.ModuleDict 语法，类似如下：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">32</span>, <span class="number">64</span>), nn.ReLU())</span><br><span class="line"></span><br><span class="line">net = nn.ModuleList([nn.Linear(<span class="number">32</span>, <span class="number">6</span>)<span class="number">4</span>, nn.ReLU()])</span><br><span class="line"></span><br><span class="line">net = nn.ModuleDict(&#123;<span class="string">&#x27;linear&#x27;</span>: nn.Linear(<span class="number">32</span>, <span class="number">64</span>), <span class="string">&#x27;act&#x27;</span>: nn.ReLU()&#125;)</span><br></pre></td></tr></table></figure></div>

<h3 id="2、nn-Sequential、nn-Module、nn-List-ModuleDict-区别"><a href="#2、nn-Sequential、nn-Module、nn-List-ModuleDict-区别" class="headerlink" title="2、nn.Sequential、nn.Module、nn.List_ModuleDict 区别"></a>2、nn.Sequential、nn.Module、nn.List_ModuleDict 区别</h3><p>1）<code>nn.ModuleList</code> 仅仅是一个储存各种模块的列表，这些模块之间没有联系也没有顺序（所以不用保证相邻层的输入输出维度匹配），而且没有实现 forward 功能需要自己实现</p>
<p>2）和<code>nn.ModuleList</code> 一样， <code>nn.ModuleDict</code> 实例仅仅是存放了一些模块的字典，并没有定义 forward 函数需要自己定义</p>
<p>3）而 <code>nn.Sequential</code> 内的模块需要按照顺序排列，要保证相邻层的输入输出大小相匹配；<code>nn.sequential</code> 内部 forward 功能已经实现，直接调用的，不需要再写 forward</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">net1 = nn.Sequential(nn.Linear(<span class="number">32</span>, <span class="number">64</span>), nn.ReLU())</span><br><span class="line">net2 = nn.ModuleList([nn.Linear(<span class="number">32</span>, <span class="number">64</span>), nn.ReLU()])</span><br><span class="line">net3 = nn.ModuleDict(&#123;<span class="string">&#x27;linear&#x27;</span>: nn.Linear(<span class="number">32</span>, <span class="number">64</span>), <span class="string">&#x27;act&#x27;</span>: nn.ReLU()&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(net1)</span></span><br><span class="line"><span class="comment"># print(net2)</span></span><br><span class="line"><span class="comment"># print(net3)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Sequential(</span></span><br><span class="line"><span class="string">  (0): Linear(in_features=32, out_features=64, bias=True)</span></span><br><span class="line"><span class="string">  (1): ReLU()</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">8</span>, <span class="number">3</span>, <span class="number">32</span>)</span><br><span class="line"><span class="built_in">print</span>(net1(x).shape)     <span class="comment">#torch.Size([8, 3, 64])</span></span><br><span class="line"><span class="comment"># print(net2(x).shape)  # 会报错，提示缺少forward</span></span><br><span class="line"><span class="comment"># print(net3(x).shape)   # 会报错，提示缺少forward</span></span><br></pre></td></tr></table></figure></div>

<hr>
<p>为 nn.ModuleList 写 forward 函数</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">My_Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(My_Model, self).__init__()</span><br><span class="line">        self.layers = nn.ModuleList([nn.Linear(<span class="number">32</span>, <span class="number">64</span>),nn.ReLU()])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = My_Model()</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">8</span>, <span class="number">3</span>, <span class="number">32</span>)</span><br><span class="line">out = net(x)</span><br><span class="line"><span class="built_in">print</span>(out.shape)</span><br><span class="line"><span class="comment">#torch.Size([8, 3, 64])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>将 nn.ModuleList 转换成 nn.Sequential</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">module_list = nn.ModuleList([nn.Linear(<span class="number">32</span>, <span class="number">64</span>), nn.ReLU()])</span><br><span class="line">net = nn.Sequential(*module_list)</span><br><span class="line">x = torch.randn(<span class="number">8</span>, <span class="number">3</span>, <span class="number">32</span>)</span><br><span class="line"><span class="built_in">print</span>(net(x).shape)</span><br></pre></td></tr></table></figure></div>

<p>将 nn.ModuleDict 转换成 nn.Sequential</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">module_dict = nn.ModuleDict(&#123;<span class="string">&#x27;linear&#x27;</span>: nn.Linear(<span class="number">32</span>, <span class="number">64</span>), <span class="string">&#x27;act&#x27;</span>: nn.ReLU()&#125;)</span><br><span class="line">net = nn.Sequential(*module_dict.values())</span><br><span class="line">x = torch.randn(<span class="number">8</span>, <span class="number">3</span>, <span class="number">32</span>)</span><br><span class="line"><span class="built_in">print</span>(net(x).shape)</span><br></pre></td></tr></table></figure></div>

<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><h3 id="numpy数组转化为torch中的tensor："><a href="#numpy数组转化为torch中的tensor：" class="headerlink" title="numpy数组转化为torch中的tensor："></a>numpy数组转化为torch中的tensor：</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.tensor(numpy.arr)</span><br><span class="line">Tensor = torch.Tensor(numpy.arr)</span><br><span class="line">as_tensor = torch.as_tensor(numpy.arr)</span><br><span class="line">from_numpy = torch.from_numpy(numpy.arr)</span><br></pre></td></tr></table></figure></div>

<h3 id="torch中的tensor转化为numpy数组"><a href="#torch中的tensor转化为numpy数组" class="headerlink" title="torch中的tensor转化为numpy数组"></a>torch中的tensor转化为numpy数组</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">np = tensor.numpy()</span><br></pre></td></tr></table></figure></div>

<h3 id="np-ndarray与Tensor中图像格式区别"><a href="#np-ndarray与Tensor中图像格式区别" class="headerlink" title="np.ndarray与Tensor中图像格式区别"></a>np.ndarray与Tensor中图像格式区别</h3><p>两者均以三维数组来表示一张图像，他们的区别在于图像信息被保存在数组中的不同位置，具体来说：</p>
<ul>
<li><code>np.ndarray</code>的<code>[h, w, c]</code>格式：数组中第一层元素为图像的每一行像素，第二层元素为每一列像素，最后一层元素为每一个通道的像素值，它将图片中的每一个像素作为描述单元，记录它三个通道的像素值。</li>
<li><code>Tensor</code>的<code>[c, h, w]</code>格式：数组中第一层元素为图像的三个通道，第二层元素为某个通道上的一行像素，第三层为该通道上某列的像素值，它将图像某个通道的某行像素值作为描述单元。</li>
</ul>
<blockquote>
<p>n：样本数量<br>c：图像通道数<br>w：图像宽度<br>h：图像高度</p>
</blockquote>
<h3 id="如何从-h-w-c-转为-c-h-w"><a href="#如何从-h-w-c-转为-c-h-w" class="headerlink" title="如何从[h, w, c]转为[c, h, w]"></a>如何从[h, w, c]转为[c, h, w]</h3><p>可以借助<code>numpy</code>的<code>transpose()</code>函数来实现这个转换。是的只要像下面简简单单的一句话即可实现</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">image = np.random.randint(<span class="number">256</span>, size=<span class="number">60</span>)</span><br><span class="line">image_hwc = image.reshape((<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(image_hwc.shape)</span><br><span class="line"><span class="comment">#(5, 4, 3)</span></span><br><span class="line"></span><br><span class="line">image_chw = np.transpose(image_hwc, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(image_chw.shape)</span><br><span class="line"><span class="comment">#(3, 5, 4)</span></span><br><span class="line"></span><br><span class="line">image_hcw = np.transpose(image_hwc, (<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(image_hcw.shape)</span><br><span class="line"><span class="comment">#(5, 3, 4)</span></span><br><span class="line"></span><br><span class="line">image_hcw_tensor = torch.tensor(image_hcw)</span><br><span class="line"><span class="built_in">print</span>(image_hcw_tensor.shape)</span><br><span class="line"><span class="comment">#torch.Size([5, 3, 4])</span></span><br><span class="line"></span><br><span class="line">x = torch.transpose(image_hcw_tensor,<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#等价于#</span></span><br><span class="line"><span class="comment">#x = torch.transpose(image_hcw_tensor,1,0)</span></span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="comment">#torch.Size([3, 5, 4])</span></span><br><span class="line"></span><br><span class="line">y_hcw = image_hcw_tensor.transpose(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(y_hcw.shape)</span><br><span class="line"><span class="comment">#torch.Size([3, 5, 4])</span></span><br><span class="line"></span><br><span class="line">z_hcw = image_hwc.transpose(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(z_hcw.shape)</span><br><span class="line"><span class="comment">#(5, 3, 4)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>



<p><strong>注意到，np的transpose和tensor的transpose不一样#</strong></p>
<p>np的可以<code>[np_arr = np.transpose(np_arr, (2,0,1))]</code>  tensor的不可以，每次转两个</p>
<p>​    在<a class="link"   href="https://so.csdn.net/so/search?q=Pytorch&spm=1001.2101.3001.7020" >Pytorch <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>中，transpose是Tensor类的一个重要方法，同时它也是torch模块中的一个函数，它们的语法如下所示。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">Tensor.transpose(dim0, dim1) → Tensor</span><br><span class="line">torch.transpose(<span class="built_in">input</span>, dim0, dim1) → Tensor</span><br><span class="line"> </span><br><span class="line"><span class="built_in">input</span> (Tensor) – the <span class="built_in">input</span> tensor.</span><br><span class="line">dim0 (<span class="built_in">int</span>) – the first dimension to be transposed</span><br><span class="line">dim1 (<span class="built_in">int</span>) – the second dimension to be transposed</span><br></pre></td></tr></table></figure></div>

<hr>
<hr>
]]></content>
  </entry>
  <entry>
    <title>arg的用法</title>
    <url>/2023/10/19/arg%E7%9A%84%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>transformer-注意力机制</title>
    <url>/2023/10/23/transformer-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>my_first_blog</title>
    <url>/2023/10/16/my-first-blog/</url>
    <content><![CDATA[<h1 id="写在前面的话："><a href="#写在前面的话：" class="headerlink" title="写在前面的话："></a>写在前面的话：</h1><p>记录一下，第一次写博客，希望每天可以进步一点点，要把之前学过整理出来，以后的学习要做一个记录。走得快走得慢不重要，走下去就是胜利。</p>
<hr>
<p>刚开始不熟练，记录markdown的一些用法。</p>
<h2 id="标题用-加空格"><a href="#标题用-加空格" class="headerlink" title="标题用# !加空格"></a>标题用# !加空格</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">*斜体文本*</span><br><span class="line">_斜体文本_</span><br><span class="line">**粗体文本**</span><br><span class="line">__粗体文本__</span><br><span class="line">***粗斜体文本***</span><br><span class="line">___粗斜体文本___</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>



<h2 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">----------</span><br><span class="line"></span><br><span class="line">_ _ _</span><br></pre></td></tr></table></figure></div>



<hr>
<hr>
<hr>
<h2 id="删除线和下划线"><a href="#删除线和下划线" class="headerlink" title="删除线和下划线"></a>删除线和下划线</h2><p><del>文本</del></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;u&gt;这是一个有下划线的文本&lt;/u&gt;</span><br><span class="line">~~文本~~</span><br></pre></td></tr></table></figure></div>

<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><ul>
<li>1</li>
</ul>
<ul>
<li>1</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">* 空格第一项</span><br><span class="line">* 第二项</span><br><span class="line">* 第三项</span><br><span class="line"></span><br><span class="line">+ 第一项</span><br><span class="line">+ 第二项</span><br><span class="line">+ 第三项</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- 第一项</span><br><span class="line">- 第二项</span><br><span class="line">- 第三项</span><br></pre></td></tr></table></figure></div>

<h3 id="有序列表-1"><a href="#有序列表-1" class="headerlink" title="有序列表"></a>有序列表</h3><p>有序列表其实很简单，就是数字加上<code>.</code></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 空格第一项</span><br><span class="line">2. 第二项</span><br><span class="line">3. 第三项</span><br></pre></td></tr></table></figure></div>

<h3 id="列表嵌套"><a href="#列表嵌套" class="headerlink" title="列表嵌套"></a>列表嵌套</h3><p>有序和无序可以一起使用，只需要在子列表的选项添加四个空格</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 第一项：</span><br><span class="line">    - 子列表1</span><br><span class="line">    - 子列表2</span><br><span class="line">2. 第二项：</span><br><span class="line">    - 子列表1</span><br><span class="line">    - 子列表2</span><br></pre></td></tr></table></figure></div>

<ol>
<li>第一项</li>
</ol>
<p>​    - 子列表1 </p>
<ol>
<li>​    - 子列表1</li>
</ol>
<h2 id="区块"><a href="#区块" class="headerlink" title="区块"></a>区块</h2><p>区块是用来引用的，比如链接或者一段文本</p>
<p>在段落的开头使用<code>&gt;</code>符号，使用空格，隔开文本</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; 引用的内容</span><br><span class="line">&gt;</span><br><span class="line">&gt; 第二段引用的内容</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>引用的内容</p>
<p>第二段引用的内容</p>
</blockquote>
<h3 id="区块嵌套"><a href="#区块嵌套" class="headerlink" title="区块嵌套"></a>区块嵌套</h3><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; 引用</span><br><span class="line">&gt;&gt; 2</span><br><span class="line">&gt;&gt;</span><br><span class="line">&gt;&gt;&gt;3</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>引用</p>
<blockquote>
<p>2</p>
</blockquote>
<blockquote>
<blockquote>
<p>3</p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>在一个文章里面插入图片是必不可少的，本地的文章可以使用本地图片，在你上传博客之后，也必须上传本地图片，但这样会有弊端。</p>
<p>使用本地图片会严重拖慢博客速度，我们需要使用超链接进行插入图片，也就是把图片上传的某个服务器上面，然后获取图片在服务器上面的地址。</p>
<p>但是我们也可以使用免费的托管或者图床，上传我们的图片，本篇教程不教图床的使用，下篇文章将会提到。</p>
<p>插入图片的语法：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">![图片描述](图片的链接)</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/%E5%9B%BE%E7%89%87%E7%9A%84%E9%93%BE%E6%8E%A5"
                      alt="图片描述"
                ></p>
]]></content>
  </entry>
  <entry>
    <title>图神经网络实战</title>
    <url>/2023/10/23/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>图神经网络</title>
    <url>/2023/10/19/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(%E4%BA%8C)/</url>
    <content><![CDATA[<p>[TOC] </p>
<ul>
<li><a href="#%E5%A6%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">一级标题</a><ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">标题 1-1</a></li>
<li>[标题 1-2](#二级标题 1-2)</li>
</ul>
</li>
<li><a href="#%E4%BA%8C%E7%BA%A7%E6%A0%87%E9%A2%98">二级标题</a><ul>
<li>[标题 2-1](#二级标题 2-1)</li>
<li>[标题 2-2](#二级标题 2-2)</li>
</ul>
</li>
<li><a href="#%E4%B8%80%E7%BA%A7%E6%A0%87%E9%A2%98">一级标题</a><ul>
<li>[标题 1-1](#二级标题 1-1)</li>
<li>[标题 1-2](#二级标题 1-2)</li>
</ul>
</li>
<li><a href="#%E4%BA%8C%E7%BA%A7%E6%A0%87%E9%A2%98">二级标题</a><ul>
<li>[标题 2-1](#二级标题 2-1)</li>
<li>[标题 2-2](#二级标题 2-2)</li>
</ul>
</li>
</ul>
<h1 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h1><p>图神经网络（GNN）是一种处理图结构数据的深度学习方法。本教程将详细介绍图神经网络的基本概念、主要模型、应用场景以及代码实现。</p>
<h2 id="什么是图神经网络"><a href="#什么是图神经网络" class="headerlink" title="什么是图神经网络"></a>什么是图神经网络</h2><p>图神经网络（Graph Neural Networks, GNN）是一类用于处理图结构数据的神经网络模型，与传统的神经网络（例如卷积神经网络、循环神经网络等）处理规则数据结构（如图像、时间序列）不同，图神经网络专门处理不规则的图结构数据，如社交网络、知识图谱等。图结构数据是一种由节点和边组成的复杂关系网络，其中节点代表实体，边代表实体之间的关系。与传统的神经网络不同，图神经网络需要考虑节点之间的关系，因此需要一种新的方式来表示节点和边。</p>
<p>图神经网络的核心思想是将每个节点的特征与其周围节点的特征进行聚合，形成新的节点表示。这个过程可以通过消息传递来实现，每个节点接收来自其邻居节点的消息，并将这些消息聚合成一个新的节点表示。这种方法可以反复迭代多次，以获取更全面的图结构信息。</p>
<p>图神经网络的结构通常由多个层组成，每个层都包含节点嵌入、消息传递和池化等操作。在节点嵌入操作中，每个节点的特征被转换为低维向量表示，以便于神经网络进行学习和处理。在消息传递操作中，每个节点接收其邻居节点的信息，并将这些信息聚合成一个新的节点表示。在池化操作中，节点表示被合并为整个图的表示，以便于进行图级任务的预测。</p>
<p>目前，图神经网络已经广泛应用于许多领域，例如社交网络分析、药物发现、推荐系统等。同时，也出现了许多变种的图神经网络模型，例如图卷积网络（Graph Convolutional Network, GCN）、图注意力网络（Graph Attention Network, GAT）等，以适应不同的任务和数据类型。</p>
<p>图卷积网络（Graph Convolution Networks，GCN）<br>图注意力网络（Graph Attention Networks）<br>图自编码器（ Graph Autoencoders）<br>图生成网络（ Graph Generative Networks）<br>图时空网络（Graph Spatial-temporal Networks）<br>图神经网络把以往的传统神经网络道路基本又走了一遍，很多思想都是想通，所谓万法归一，道法自然吧，其实从来都没啥无中生有，有的只是发现而已。下面重点介绍下图卷积神经网络DCN吧，后续的待后面系列再介绍</p>
<h2 id="图神经网络的基本概念"><a href="#图神经网络的基本概念" class="headerlink" title="图神经网络的基本概念"></a>图神经网络的基本概念</h2><p>好的，我来对每个部分进行补充。</p>
<ol>
<li><h3 id="图（Graph）"><a href="#图（Graph）" class="headerlink" title="图（Graph）"></a>图（Graph）</h3></li>
</ol>
<p>  图是一种用顶点（Vertex）和边（Edge）表示实体及其关系的数学结构。一个图可以表示为 G &#x3D; (V, E)，其中 V 是顶点集合，E 是边集合。在图中，顶点表示实体，边表示实体之间的关系。例如，在社交网络中，顶点可以表示用户，边可以表示用户之间的关注或好友关系。</p>
<p>图可以分为有向图和无向图两种类型。在无向图中，边没有方向；在有向图中，边有方向。此外，图还可以带有权重，表示实体之间的关系强度。有权重的图通常被称为带权图。</p>
<ol start="2">
<li><h3 id="邻接矩阵（Adjacency-Matrix）"><a href="#邻接矩阵（Adjacency-Matrix）" class="headerlink" title="邻接矩阵（Adjacency Matrix）"></a>邻接矩阵（Adjacency Matrix）</h3></li>
</ol>
<p>  邻接矩阵 A 是一种表示图中顶点间关系的矩阵。设 V 为顶点集合，A 的大小为 |V|×|V|。对于无向图，A 的元素 A(i, j) &#x3D; 1表示顶点 i 和顶点 j 相邻，即存在一条边；A(i, j) &#x3D; 0 表示顶点 i 和顶点 j 不相邻。有向图的邻接矩阵表示有方向的边。</p>
<p>邻接矩阵可以用于表示图结构，同时也可以用于进行图算法的实现。通过邻接矩阵，我们可以快速地查询两个顶点之间是否存在边，以及边的类型和权重等信息。</p>
<p>另外，邻接矩阵可以被视为图的一种表示形式，与其他表示方式（如邻接表、边列表等）相比，邻接矩阵可以用于描述稠密图，具有空间利用率高、查询效率高的优点。</p>
<ol start="3">
<li><h3 id="图信号（Graph-Signal）"><a href="#图信号（Graph-Signal）" class="headerlink" title="图信号（Graph Signal）"></a>图信号（Graph Signal）</h3></li>
</ol>
<p>  图信号是定义在图顶点上的信号，可以看作是顶点的特征。对于顶点集合 V，我们可以将图信号表示为一个 |V|×d 的矩阵 X，其中 d 是特征维度。</p>
<p>图信号可以表示顶点的属性或特征，例如在社交网络中，每个顶点可以表示为一个包含用户属性的向量，如性别、年龄、职业等。在化学分子中，每个原子可以表示为一个包含化学性质的向量，如电子亲和力、电荷等。</p>
<p>图信号可以用于图结构数据的分析和处理，例如对图进行分类、聚类、预测等任务。通常情况下，我们需要将图信号与图上的拓扑结构相结合，从而更好地利用图结构数据的特点。例如，在图卷积神经网络中，我们可以通过图信号和邻接矩阵的卷积操作来提取节点的特征表示。</p>
<ol start="4">
<li><h3 id="图卷积（Graph-Convolution）"><a href="#图卷积（Graph-Convolution）" class="headerlink" title="图卷积（Graph Convolution）"></a>图卷积（Graph Convolution）</h3></li>
</ol>
<p>  图卷积是一种操作，将传统卷积的概念扩展到图结构数据。图卷积通常表示为邻接矩阵 A 和图信号 X 之间的一个函数：f(A, X)。通过这个函数，可以在图上实现信息传递和特征提取。与传统卷积不同的是，图卷积考虑了节点在图上的拓扑结构，因此可以捕捉节点之间的关系和依赖关系。</p>
<p>图卷积的实现方式有多种，其中最常见的是基于谱域的方法和基于空域的方法。基于谱域的方法利用图的拉普拉斯矩阵的特征值和特征向量来定义卷积操作。基于空域的方法则利用邻接矩阵和节点特征来进行卷积操作。</p>
<p>图卷积可以用于许多图结构数据的任务，例如节点分类、图分类、链接预测等。在图神经网络中，图卷积是一种核心操作，可以帮助提取图结构数据中的特征表示，从而实现更高效和准确的图结构数据分析和处理。</p>
<h2 id="主要图神经网络模型"><a href="#主要图神经网络模型" class="headerlink" title="主要图神经网络模型"></a>主要图神经网络模型</h2><h3 id="GCN（Graph-Convolutional-Networks）"><a href="#GCN（Graph-Convolutional-Networks）" class="headerlink" title="GCN（Graph Convolutional Networks）"></a>GCN（Graph Convolutional Networks）</h3><ul>
<li>对每个节点计算特征</li>
<li>然后合成每个节点的特征</li>
<li>将合成的特征传入全连接网络进行分类</li>
</ul>
<p>GCN 是一种基于谱域（Spectral Domain）的图卷积方法。它利用图的拉普拉斯矩阵，通过对特征向量进行卷积操作实现信息传递和特征提取。GCN 的核心思想是通过邻接矩阵 A 和图信号 X 的乘积来实现信息传递。</p>
<p>在 GCN 中，每个节点的特征向量会与其邻居节点的特征向量进行加权平均。权重由邻接矩阵 A 中的值确定。具体来说，GCN 的卷积操作可以表示为：</p>
<p>$$<br>Z &#x3D; f(X,A) &#x3D; softmax(\hat{A}\quad ReLU(AXW^{(0)})W^{(1)}）<br>$$<br>其中，D 是 A 的度矩阵，W 是可学习的权重矩阵。</p>
<p>GCN 已被广泛应用于节点分类、图分类、链接预测等任务，并取得了很好的效果。但是，GCN 的局限性在于其卷积操作仅考虑一阶邻居节点，无法捕捉更长程的关系和全局信息。因此，后续的研究提出了许多改进版本的图卷积网络，如下面所介绍的 GAT 和 GraphSAGE。</p>
<h3 id="GAT（Graph-Attention-Networks）"><a href="#GAT（Graph-Attention-Networks）" class="headerlink" title="GAT（Graph Attention Networks）"></a>GAT（Graph Attention Networks）</h3><p>GAT 是一种基于空域（Spatial Domain）的图卷积方法。GAT 引入了注意力机制，使得模型可以为不同的边赋予不同的权重，从而更好地捕捉节点之间的关系。在 GAT 中，每个节点的特征向量会与其邻居节点的特征向量进行加权平均，权重由注意力机制计算得到。</p>
<p>具体来说，GAT 的卷积操作可以表示为：</p>
<p>Z &#x3D; f(A, X) &#x3D; CONCAT(ATTENTION(A, X)W)</p>
<p>其中，ATTENTION 是计算注意力权重的函数，CONCAT 是连接操作。ATTENTION 函数通常包括两个步骤：首先计算每个邻居节点与当前节点的相似度，然后利用 softmax 函数将相似度转化为权重。这样，每个邻居节点的权重就可以不同，从而更好地表达节点之间的关系。</p>
<p>GAT 的注意力机制使得模型能够更好地适应不同的图结构和任务，并在许多图分类、节点分类、链接预测等任务中取得了很好的效果。</p>
<h3 id="GraphSAGE（Graph-Sample-and-AggregatE）"><a href="#GraphSAGE（Graph-Sample-and-AggregatE）" class="headerlink" title="GraphSAGE（Graph Sample and AggregatE）"></a>GraphSAGE（Graph Sample and AggregatE）</h3><p>GraphSAGE 是一种基于空域（Spatial Domain）的图卷积方法，提出了一种邻居采样和聚合策略，使得模型能够处理大规模的图数据。在 GraphSAGE 中，每个节点的特征向量会与其邻居节点的特征向量进行聚合。不同于 GCN 和 GAT，GraphSAGE 不是对所有邻居节点进行平均或加权平均，而是采用一定的邻居采样策略，只考虑一个节点的一阶或 k 阶邻居节点进行聚合，从而减少计算复杂度。</p>
<p>具体来说，GraphSAGE 的卷积操作可以表示为：</p>
<p>Z &#x3D; f(A, X) &#x3D; AGGREGATE(NEIGHBORS(A, X)) W</p>
<p>其中，NEIGHBORS 是邻居采样函数，用于从一个节点的邻居中随机采样一些节点作为聚合的输入；AGGREGATE 是聚合函数，用于聚合邻居节点的特征向量，如均值、最大值等；W 是可学习的权重矩阵。</p>
<p>GraphSAGE 可以处理大规模的图数据，并在节点分类、图分类、链接预测等任务中取得了很好的效果。它的邻居采样和聚合策略也被许多后续的图卷积网络所借鉴和改进。</p>
<h2 id="图神经网络的应用场景"><a href="#图神经网络的应用场景" class="headerlink" title="图神经网络的应用场景"></a>图神经网络的应用场景</h2><p>图神经网络在许多领域都有广泛的应用，主要包括：</p>
<p>节点分类（Node Classification）：预测图中节点的类别，如在社交网络中预测用户的兴趣标签。<br>链接预测（Link Prediction）：预测图中节点之间是否存在边，如在知识图谱中预测实体间的关系。<br>图分类（Graph Classification）：预测整个图的类别，如在生物分子网络中预测分子的活性。<br>图生成（Graph Generation）：生成具有某些特性的图，如生成满足特定拓扑特征的网络。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>以下是使用Cora数据集训练图卷积神经网络的示例代码，使用PyTorch Geometric库实现：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断是否有可用的GPU，如果有就使用GPU，否则使用CPU</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Cora数据集</span></span><br><span class="line">dataset = Planetoid(root=<span class="string">&#x27;data/Cora&#x27;</span>, name=<span class="string">&#x27;Cora&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个GCN模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCN, self).__init__()</span><br><span class="line">        <span class="comment"># 第一个图卷积层</span></span><br><span class="line">        self.conv1 = GCNConv(input_dim, hidden_dim)</span><br><span class="line">        <span class="comment"># 第二个图卷积层</span></span><br><span class="line">        self.conv2 = GCNConv(hidden_dim, output_dim)</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        self.fc = nn.Linear(output_dim, dataset.num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># 第一次图卷积，使用ReLU激活函数</span></span><br><span class="line">        x = F.relu(self.conv1(x, edge_index))</span><br><span class="line">        <span class="comment"># 第二次图卷积</span></span><br><span class="line">        x = self.conv2(x, edge_index))</span><br><span class="line">        <span class="comment"># Dropout操作，防止过拟合</span></span><br><span class="line">        x = F.dropout(x, training=self.training)</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="comment"># 使用log_softmax进行分类</span></span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建GCN模型实例，并将模型移动到设备上（GPU或CPU）</span></span><br><span class="line">model = GCN(dataset.num_features, <span class="number">16</span>, dataset.num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器和损失函数</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, optimizer, criterion, data</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    out = model(data.x.to(device), data.edge_index.to(device))</span><br><span class="line">    loss = criterion(out[data.train_mask], data.y[data.train_mask].to(device))</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, data</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    out = model(data.x.to(device), data.edge_index.to(device))</span><br><span class="line">    pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line">    acc = pred[data.test_mask].eq(data.y[data.test_mask].to(device)).<span class="built_in">sum</span>().item() / data.test_mask.<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行模型训练和测试，并输出测试集准确率</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    train(model, optimizer, criterion, dataset[<span class="number">0</span>])</span><br><span class="line">    test_acc = test(model, dataset[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;:03d&#125;, Test Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, test_acc))</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

]]></content>
  </entry>
  <entry>
    <title>差分隐私（一）</title>
    <url>/2023/10/20/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/</url>
    <content><![CDATA[<p><a class="link"   href="https://programming-dp.com/ch5.html" >非常非常有用的，学习差分隐私特别友好的网址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h1 id="拉普拉斯机制（ϵ-DP）"><a href="#拉普拉斯机制（ϵ-DP）" class="headerlink" title="拉普拉斯机制（ϵ-DP）"></a>拉普拉斯机制（<em>ϵ</em>-DP）</h1><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/31/UL95ArTPoyGMtb4.png"
                      alt="拉普拉斯定义" style="zoom:50%;" 
                > 

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">noisy = np.random.laplace(loc=<span class="number">0</span>, scale=sensitivity/epsilon)</span><br></pre></td></tr></table></figure></div>

<h2 id="差分隐私的特性"><a href="#差分隐私的特性" class="headerlink" title="差分隐私的特性"></a>差分隐私的特性</h2><ul>
<li>#Sequential Composition（顺序组合）#： 顺序组合指的是当多个隐私机制依次应用在同一数据上时，其隐私保护仍然有效。也就是说，如果你依次使用了多个差分隐私机制来处理数据，每个机制都满足差分隐私的要求，那么它们的组合也仍然满足差分隐私。</li>
<li>#Parallel Composition（并行组合）#： 并行组合涉及到将多个差分隐私机制同时应用于不同的数据集，然后将它们的输出合并在一起。这个特性确保当你对多个不相关的数据集进行处理时，整体的隐私保护也仍然有效。</li>
<li>Post-processing（后处理）： 差分隐私机制的输出可以在满足差分隐私的前提下进行一定的后处理，例如添加噪音或进行数据聚合，而不会丧失差分隐私的性质。这意味着对差分隐私输出的进一步处理仍然可以保护隐私，只要这些处理不会增加原始机制的灵敏度。</li>
</ul>
<h3 id="顺序组合（Sequential-Composition）"><a href="#顺序组合（Sequential-Composition）" class="headerlink" title="顺序组合（Sequential Composition）"></a>顺序组合（Sequential Composition）</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/19/nptMmBCAGTF2aJV.png"
                      alt="image.png" style="zoom:50%;" 
                >
因为它允许个体限定他们通过参与所有这些分析所承担的总隐私成本。顺序组合给出的隐私成本上限，两个具体的差分隐私发布的实际隐私成本可能小于这个上限，但不会大于它。

<h3 id="并行组合（Parallel-Composition）"><a href="#并行组合（Parallel-Composition）" class="headerlink" title="并行组合（Parallel Composition）"></a>并行组合（Parallel Composition）</h3><p>差分隐私的第二个重要性质被称为并行组合。并行组合可以看作是顺序组合的一种替代方式，它是计算多次数据发布的总隐私成本上界的另一种方法。<br>并行组合是基于将数据集分割成不重叠的块，并在每个块上单独运行差分隐私机制的思想。由于这些块是不重叠的，每个个体的数据只出现在一个块中 - 因此，即使总共有 k 个块（因此有 k 次机制运行），机制在每个个体的数据上也只运行一次。形式上，这可以表示为：<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/19/P3eQMBrVFxZzJKu.png"
                      alt="image.png" style="zoom:50%;" 
                ></p>
<h3 id="后处理"><a href="#后处理" class="headerlink" title="后处理"></a>后处理</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/19/ZzLRxfNe8bV9F4s.png"
                      alt="image.png" style="zoom:50%;" 
                > 

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>顺序组合限制了在相同输入数据上发布多个差分隐私机制的总隐私成本。</li>
<li>并行组合基于将数据集分割成不相交的块并分别在每个块上运行差分隐私机制的概念。</li>
<li>后处理属性意味着对差分隐私机制的输出进行任意计算始终是安全的。</li>
</ul>
<h1 id="高斯机制-近似差分隐私-ϵ，δ-DP"><a href="#高斯机制-近似差分隐私-ϵ，δ-DP" class="headerlink" title="高斯机制-(近似差分隐私(ϵ，δ)-DP)"></a>高斯机制-(近似差分隐私(<em>ϵ</em>，<em>δ</em>)-DP)</h1><p>δ表示定义的“失败概率”<br>$$<br>\delta &#x3D; 10^{-5}<br>$$<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/31/Gsl4MUJoHEZ3Dw2.png"
                      alt="image.png" style="zoom:50%;" 
                > </p>
<h2 id="高斯机制"><a href="#高斯机制" class="headerlink" title="高斯机制"></a>高斯机制</h2><p>高斯机制是拉普拉斯机制的替代方案，拉普拉斯机制增加了高斯噪声而不是拉普拉斯噪声。高斯机制不满足纯<em>ϵ</em>-差分隐私，但满足(<em>ϵ</em>-<em>δ</em>)差分隐私。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="F:\typora文件\bksjSfOE3n8AChT.png"
                      alt="image.png" style="zoom:50%;" 
                >‘s’是’f’的灵敏度，N是高斯噪声分布</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sigma = np.sqrt(<span class="number">2</span> * np.log(<span class="number">1.25</span> / delta)) * <span class="number">1</span> / epsilon   <span class="comment"># s = 1</span></span><br></pre></td></tr></table></figure></div>

<h2 id="近似差分隐私的特性"><a href="#近似差分隐私的特性" class="headerlink" title="近似差分隐私的特性"></a>近似差分隐私的特性</h2><p>近似差分隐私与纯差分隐私具有相似的性质。它满足<strong>顺序组成</strong>（Sequential Composition）。</p>
<p>Approximate differential privacy also satisfies post-processing and parallel composition.</p>
<p><strong>后处理和并行组会同样满足</strong></p>
<h2 id="Advanced-Composition-高级组合"><a href="#Advanced-Composition-高级组合" class="headerlink" title="Advanced Composition (高级组合)"></a>Advanced Composition (高级组合)</h2><p>(<em>ϵ</em>，<em>δ</em>)差分隐私提供了一种分析差分隐私机制<strong>顺序组成</strong>的新方法，可以降低隐私成本。</p>
<p>原文：The advanced composition theorem [7] is usually stated in terms of mechanisms which are instances of  k-fold adaptive composition.</p>
<p>k-fold通常表示一个动作或过程重复k次，即重复执行k次。在差分隐私的上下文中，k-fold adaptive composition表示将一个机制连续应用k次，可能在不同的输入上，以进行隐私分析。这是一种用于描述差分隐私机制的统计性质的方式，通常用于分析机制的隐私成本。</p>
<p>差分隐私中的”Adaptive Composition”意味着针对一系列隐私保护需求进行自适应组合或调整隐私机制。这种组合方式考虑了不同隐私机制之间的相互关系，并根据需要进行调整，以更好地满足隐私保护的要求。这是一种用于处理多个隐私需求的方法，以确保用户的隐私得到适当的保护。</p>
<p>迭代程序（例如循环或递归函数）几乎总是k倍自适应组合的例子。例如，运行1000次迭代的for循环是一个1000倍的自适应组合。更具体地说，平均攻击是k倍自适应组合的一个示例：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># works for sensitivity-1 queries</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">avg_attack</span>(<span class="params">query, epsilon, k</span>):</span><br><span class="line">    results = [query + np.random.laplace(loc=<span class="number">0</span>, scale=<span class="number">1</span>/epsilon) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k)]</span><br><span class="line">    <span class="keyword">return</span> np.mean(results)</span><br><span class="line"></span><br><span class="line">avg_attack(<span class="number">10</span>, <span class="number">1</span>, <span class="number">500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在这个示例中，机制的顺序在提前确定（我们每次使用相同的机制），而k = 500</span></span><br><span class="line"><span class="comment"># 标准的串行组合定理指出，这个机制的总隐私成本是kϵ。在这里是500 * ϵ = 500</span></span><br></pre></td></tr></table></figure></div>

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/31/TeSIu37XHJFkRbA.png"
                      alt="高级组合定理" style="zoom:67%;" 
                > 

<p>假设，<em>ϵ</em>是1，k &#x3D; 500，<em>δ</em> &#x3D; 10^{-5},那么多隐私预算为<br>$$<br>假设，ϵ是1，k &#x3D; 500，δ &#x3D; 10^{-5},那么新的隐私预算\epsilon^′&#x3D;2<em>1\sqrt{2</em>500*\log_2（\frac{1}{\delta^′}）} &#x3D; 215<br>$$<br>因此，对于相同的机制，高级组合得出的界限比顺序组合(500)低得多。这是什么意思？</p>
<ol>
<li>“Advanced composition”根据相同的机制提供了更低的隐私下限(e)。这意味着，对于相同的机制，使用”advanced composition”获得的隐私成本下限要比”sequential composition”更低。</li>
<li>“Sequential composition”给出的边界松散，无法紧密限制计算的实际隐私成本。虽然”advanced composition”也提供松散的边界，但它们比”sequential composition”给出的边界略微更紧凑。</li>
</ol>
<p>总的来说，这意味着在差分隐私分析中，”advanced composition”提供了更准确的边界，而”sequential composition”的边界较松散，不够准确。”Advanced composition”边界也不是非常紧凑，但相对而言更接近实际的隐私成本。</p>
<p>需要注意的是，这两个边界在技术上是不可比较的，因为”advanced composition”引入了一个参数 δ（delta）。然而，当 δ 很小时，通常会比较两种方法给出的 ε（epsilon）。也就是说，当 δ 趋于零时，我们通常会比较两种方法所得到的 ε 值。</p>
<p>那么，我们是否应该总是使用”advanced composition”呢？事实证明，不应该总是使用。让我们尝试上面的实验，针对不同的 k 值，并绘制出在”sequential composition”和”advanced composition”下的总隐私成本。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/31/wW8zNcxnGQCjrZt.png"
                      alt="image.png" style="zoom: 50%;" 
                > 

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/31/YPwtVoKLEQpOxdZ.png"
                      alt="image.png" style="zoom:50%;" 
                > 

<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><ul>
<li><p>在 L2 敏感性远低于 L1 敏感性的应用中，高斯机制允许添加更少的噪音。</p>
</li>
<li><p>当循环中的迭代次数非常大时，高级组合方法可以在准确性方面产生重大影响。</p>
</li>
</ul>
<h1 id="L1和L2-Norm"><a href="#L1和L2-Norm" class="headerlink" title="L1和L2-Norm"></a>L1和L2-Norm</h1><p>这几个讲的非常好</p>
<p><a class="link"   href="https://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/3_regularization.html" >正则化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://www.bookstack.cn/read/huaxiaozhuan-ai/spilt.1.d07cc9a8a1364f3d.md" >正则化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://hellozhaozheng.github.io/z_post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90/" >正则化方法深入解析 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a href="https://www.cnblogs.com/callyblog/p/8094745.html"><a class="link"   href="https://www.cnblogs.com/callyblog/p/8094745.html" >正则化之L1和L2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></a></p>
<h2 id="L1和L2"><a href="#L1和L2" class="headerlink" title="L1和L2"></a>L1和L2</h2><p>L1：在二维空间中，两个向量之间差的范数产生它们之间的“曼哈顿距离”</p>
<p>L2 ：长度向量的范数定义为（即平方和的平方根）。在二维空间中，这是“欧几里得距离”，它总是小于或等于范数。<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/19/tik3uWsMOgUDrwX.png"
                      alt="image.png" style="zoom:50%;" 
                > </p>
<h1 id="灵敏度"><a href="#灵敏度" class="headerlink" title="灵敏度"></a>灵敏度</h1><h2 id="全局灵敏度"><a href="#全局灵敏度" class="headerlink" title="全局灵敏度"></a>全局灵敏度</h2><p>全局敏感度的定义是，对于<em>任意两个</em>相邻的数据集 和 ，和之间的差值最多为 。这种敏感度度量称为“全局”，因为它独立于所查询的实际数据集（<em>它适用于相邻</em>和 的任何选择）。另一种敏感度度量称为<em>局部敏感度</em>，它将其中一个数据集固定为被查询的数据集;我们将在后面的章节中讨论这项措施。目前，当我们说“敏感性”时，我们指的是全局敏感性</p>
<h2 id="局部灵敏度"><a href="#局部灵敏度" class="headerlink" title="局部灵敏度"></a>局部灵敏度</h2><hr>
<p>_____<em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>没看懂</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></p>
<hr>
<p>这就是本地敏感性（local sensitivity）[8]的原始原理：将两个数据集中的一个固定为实际被查询的数据集，并考虑它的所有相邻数据集。在形式上，函数的本地敏感性可表示为：</p>
<p>需要注意的是，局部敏感度是查询（f）和实际数据集（x）的函数。不同于全局敏感度的情况，我们不能讨论一个函数的局部敏感度，而不考虑发生这种局部敏感度的数据集</p>
<h3 id="局部灵敏度的均值"><a href="#局部灵敏度的均值" class="headerlink" title="局部灵敏度的均值"></a>局部灵敏度的均值</h3><p>本地敏感性允许我们对一些难以界定全局敏感性的函数的敏感性设置有限的界限。平均函数就是一个例子。到目前为止，我们通过将查询拆分为两个查询来计算差分隐私均值：差分隐私总和（分子）和差分隐私计数（分母）。通过顺序组合和后处理，这两个结果的商满足差分隐私。</p>
<p>为什么要这样做呢？因为均值查询的输出在添加或删除数据集中的行时可能发生变化的量取决于数据集的大小。如果我们想要界定均值查询的全局敏感性，我们必须假设最坏的情况：数据集大小为1。在这种情况下，如果数据属性值在上限和下限 u 和 l 之间，均值的全局敏感性就是 |l-u|。对于大型数据集来说，这是非常悲观的，而“嘈杂的总和除以嘈杂的计数”方法要好得多。</p>
<p>在计算差分隐私均值时，通常采用一种方法，即将均值查询（平均值计算）拆分为两个子查询操作：一个是差分隐私总和（分子），另一个是差分隐私计数（分母）。这两个子查询操作分别用于计算总和和计数。</p>
<ol>
<li><strong>差分隐私总和（分子）</strong>：这个部分涉及计算数据集中数值属性的总和。为了保护数据隐私，会向每个数值属性的总和添加一些差分隐私噪音。这样，即使在不泄露个别数据点的具体值的情况下，可以估计出总和的范围。</li>
<li><strong>差分隐私计数（分母）</strong>：这个部分涉及计算数据集中满足某些条件的数据点的数量。类似地，为了保护数据隐私，会向计数结果添加一些差分隐私噪音。</li>
</ol>
<p>通过计算这两个部分，您得到了两个带有噪音的结果，一个是总和的估计值，另一个是计数的估计值。然后，通过将这两个结果相除，您获得了差分隐私均值的估计值。</p>
<p>顺序组合和后处理是指在计算这两个结果之后，可以使用顺序组合（如差分隐私的序列性质）和后处理算法来确保最终的均值估计值满足差分隐私的定义和要求。这些步骤有助于减小噪音的影响，使得估计的均值更为准确。因此，最终的均值估计值满足差分隐私的要求，同时也有较高的数据隐私保护级别。</p>
<hr>
<p>计数应该根据特定条件进行，以确保它与求和的条件一致</p>
<hr>
<h2 id="通过局部灵敏度实现差分隐私"><a href="#通过局部灵敏度实现差分隐私" class="headerlink" title="通过局部灵敏度实现差分隐私"></a>通过局部灵敏度实现差分隐私</h2><h3 id="Propose-Test-Release"><a href="#Propose-Test-Release" class="headerlink" title="Propose-Test-Release"></a>Propose-Test-Release</h3><p>提出-测试-发布（propose-test-release）框架采用了以下方法。首先，该框架要求分析员提出要应用的函数的局部敏感性的上限。然后，该框架运行差分隐私测试，以检查被查询的数据集是否与局部敏感性高于提出的上限的数据集“有一定距离”。如果测试通过，该框架将发布一个带有已校准到提出上限的噪声结果。这种方法可以帮助确保在保护隐私的同时提供有用的信息。</p>
<h1 id="差分隐私的变体"><a href="#差分隐私的变体" class="headerlink" title="差分隐私的变体"></a>差分隐私的变体</h1><p> Rényi 差分隐私和零集中差分隐私</p>
<p>阅读本章后，您将能够：</p>
<ul>
<li>定义 Rényi 差分隐私和零集中差分隐私</li>
<li>描述这些变体相对于(<em>ϵ</em>，<em>δ</em>)差分隐私的优势</li>
<li>将这些变体的隐私成本转换为(<em>ϵ</em>，<em>δ</em>)差分隐私</li>
</ul>
<p>高级组合和“vectorized” case的噪声，</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/02/zlDhHfp2GKa7JVZ.png"
                      alt="image.png" style="zoom:50%;" 
                > 

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">ks = np.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">epsilon = <span class="number">.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># L1 sensitivity of each query: 1</span></span><br><span class="line"><span class="comment"># noise per query: 1/epsilon</span></span><br><span class="line"><span class="comment"># number of queries: k</span></span><br><span class="line">noises_seq = [k*(<span class="number">1</span>/epsilon) <span class="keyword">for</span> k <span class="keyword">in</span> ks]</span><br><span class="line">plt.plot(ks, noises_seq, label=<span class="string">&#x27;Sequential Composition&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of queries: 1</span></span><br><span class="line"><span class="comment"># L1 sensitivity of each query: k</span></span><br><span class="line"><span class="comment"># noise per query: k / epsilon</span></span><br><span class="line">noises_l1 = [<span class="number">1</span>*(k/epsilon) <span class="keyword">for</span> k <span class="keyword">in</span> ks]</span><br><span class="line">plt.plot(ks, noises_l1, label=<span class="string">&#x27;Vectorized&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Laplace Mechanism: Vectorized vs. Composition&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Queries&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Scale of Noise&#x27;</span>)</span><br><span class="line">plt.legend();</span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################################################################################</span></span><br><span class="line">ks = np.linspace(<span class="number">1</span>, <span class="number">100</span>, <span class="number">20</span>)</span><br><span class="line">epsilon = <span class="number">.1</span></span><br><span class="line">delta = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># L2 sensitivity of each query: 1</span></span><br><span class="line"><span class="comment"># number of queries: k</span></span><br><span class="line">noises_seq = [<span class="number">16</span>*k*np.log((<span class="number">2.5</span>*k)/delta)*np.log(<span class="number">2</span>/delta)/(epsilon**<span class="number">2</span>) <span class="keyword">for</span> k <span class="keyword">in</span> ks]</span><br><span class="line">plt.plot(ks, noises_seq, label=<span class="string">&#x27;Advanced Composition&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of queries: 1</span></span><br><span class="line"><span class="comment"># L2 sensitivity of each query: sqrt(k)</span></span><br><span class="line">noises_l1 = [<span class="number">2</span>*k*np.log(<span class="number">1.25</span>/delta)/(epsilon**<span class="number">2</span>) <span class="keyword">for</span> k <span class="keyword">in</span> ks]</span><br><span class="line">plt.title(<span class="string">&#x27;Gaussian Mechanism: Vectorized vs. Composition&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of Queries&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Scale of Noise&#x27;</span>)</span><br><span class="line">plt.plot(ks, noises_l1, label=<span class="string">&#x27;Vectorized&#x27;</span>)</span><br><span class="line">plt.legend();</span><br><span class="line"><span class="comment">#############################################################</span></span><br><span class="line"><span class="comment">#   对比了In the “vectorized” case与顺序组合L1和高级组合L2的单次的噪声规模</span></span><br></pre></td></tr></table></figure></div>

<h2 id="Max-Divergence-and-Renyi-Divergence（最大散度和-Renyi-散度）"><a href="#Max-Divergence-and-Renyi-Divergence（最大散度和-Renyi-散度）" class="headerlink" title="Max Divergence and Rényi Divergence（最大散度和 Rényi 散度）"></a>Max Divergence and Rényi Divergence（最大散度和 Rényi 散度）</h2><p>在统计学中，”divergence”是一种用于衡量两个概率分布之间距离的方法，而这正是差分隐私所要做的事情。”max divergence”是Kullback-Leibler散度的最坏情况对应，而KL散度是最常见的距离度量之一。</p>
<p>差分隐私领域的一个有趣研究方向是探索与其他分歧度相关的替代隐私定义。其中，Rényi散度尤为引人注目，因为它（与max散度类似）也允许我们恢复差分隐私的原始定义。Rényi散度是一种用于度量两个概率分布之间差异的方法，它可以提供不同的隐私保护度量，同时与差分隐私的核心概念相关联。这使得Rényi散度成为了一个有潜力的研究方向，有助于更深入地理解差分隐私的各种方面。</p>
<p>概率分布P和Q之间的阶数为α的Rényi散度被定义为（其中p(x)和q(x)分别表示P和Q在点x处的概率密度）：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/02/pHthrVxofvZBny3.png"
                      alt="image.png" style="zoom:67%;" 
                > 

<p>如果α &#x3D;∞，得到ϵ-differential privac.如果我们将α设为特定的值，那么我们会立即恢复到(<em>ϵ</em>，<em>δ</em>)-differential privacy的定义！一个显而易见的问题是，如果我们将α设置为其他值会发生什么？正如我们将看到的，可以使用Rényi散度来导出差分隐私的有趣松弛，从而允许更好的组合定理，同时避免了在(<em>ϵ</em>，<em>δ</em>) -差分隐私下可能发生的“灾难”.</p>
<p>不同的Rényi散度的阶数（通常用α表示）会导致不同的性质和效果，因此研究人员可以根据具体应用场景选择适当的阶数来平衡隐私保护和数据效用之间的权衡。</p>
<h2 id="Renyi-Differential-Privacy"><a href="#Renyi-Differential-Privacy" class="headerlink" title="Rényi Differential Privacy"></a>Rényi Differential Privacy</h2><p><a class="link"   href="https://doi.org/10.1145/1250790.1250803" > [Rényi differential privacy (RDP] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/02/BjtDiQb6c3vhWUY.png"
                      alt="image.png"
                ></p>
<p>Rényi 差分隐私的一个关键特性是，满足 RDP 的机制也满足(<em>ϵ</em>，<em>δ</em>)-DP。RDP要求阶数为α的Rényi散度在Y和X之间的取值应该受到ε的限制。这个要求确保了差分隐私的一种变种，其中隐私参数被定义为Rényi散度的上限</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/02/Qa2Zq1ktcrmobdM.png"
                      alt="image.png"
                > </p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_mech_RDP_vec</span>(<span class="params">vec, sensitivity, alpha, epsilon_bar</span>):</span><br><span class="line">    sigma = np.sqrt((sensitivity**<span class="number">2</span> * alpha) / (<span class="number">2</span> * epsilon_bar))</span><br><span class="line">    <span class="keyword">return</span> [v + np.random.normal(loc=<span class="number">0</span>, scale=sigma) <span class="keyword">for</span> v <span class="keyword">in</span> vec]</span><br></pre></td></tr></table></figure></div>

<p>对于给定水平的噪声，使用RDP的顺序组合来限制高斯机制的重复应用的隐私代价，然后转换为(ϵ，δ)-差分隐私，通常会产生比在(ϵ，δ)世界中直接执行组合（即使使用高级组合）更低的隐私代价</p>
<h2 id="Zero-Concentrated-Differential-Privacy"><a href="#Zero-Concentrated-Differential-Privacy" class="headerlink" title="Zero-Concentrated Differential Privacy"></a>Zero-Concentrated Differential Privacy</h2><p>零集中差分隐私（Zero-Concentrated Differential Privacy，zCDP）是一种用于量化差分隐私中隐私级别的框架。它扩展了传统的差分隐私（DP），提供了更紧密的隐私保证，特别是在处理具有较小灵敏度的查询时。在传统的差分隐私中，隐私级别是通过限制两个相邻数据集导致查询结果显着不同的概率来衡量的。然而，在许多实际情况下，发生这种显着差异的可能性可能微乎其微。零集中差分隐私考虑到了这一点，并提供了更准确和细化的隐私保证。在zCDP中，隐私级别是通过分析围绕零点的隐私损失值的集中程度来量化的。它测量了小隐私损失值的可能性，这意味着当隐私损失接近零时，它提供了更准确的隐私界限。这个框架特别适用于处理具有低灵敏度的查询，例如涉及小规模个体群体或相对温和数据变换的查询。它有助于在传统的差分隐私可能会高估隐私风险的情况下提供更准确的隐私保证。总的来说，零集中差分隐私是一种更精确的隐私分析框架，确保隐私保证更符合特定情景中的实际风险。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20231102174428912.png"
                      alt="image-20231102174428912" style="zoom:67%;" 
                > 

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_mech_zCDP_vec</span>(<span class="params">vec, sensitivity, rho</span>):</span><br><span class="line">    sigma = np.sqrt((sensitivity**<span class="number">2</span>) / (<span class="number">2</span> * rho))</span><br><span class="line">    <span class="keyword">return</span> [v + np.random.normal(loc=<span class="number">0</span>, scale=sigma) <span class="keyword">for</span> v <span class="keyword">in</span> vec]</span><br></pre></td></tr></table></figure></div>

<h2 id="Composition-under-Variants-of-Differential-Privacy"><a href="#Composition-under-Variants-of-Differential-Privacy" class="headerlink" title="Composition under Variants of Differential Privacy"></a>Composition under Variants of Differential Privacy</h2><h1 id="The-Exponential-Mechanism-指数机制"><a href="#The-Exponential-Mechanism-指数机制" class="headerlink" title="The Exponential Mechanism-指数机制"></a>The Exponential Mechanism-指数机制</h1><p>指数机制是一种机制，它允许在不直接添加噪声到答案的情况下，返回一个“最佳”元素，同时仍保持差分隐私。这个机制通过评分函数来定义什么元素被认为是“最佳”的，该函数为集合中的每个元素分配一个分数，并定义要从中进行选择的元素集。机制的目标是近似返回具有最高分数的元素，同时满足差分隐私的要求。也就是说，为了保护隐私，指数机制有时会从集合中返回一个具有较低分数的元素，而不是最高分数的元素。这种机制在差分隐私领域中有很多应用，允许在保护隐私的同时提供有关数据的有用信息。</p>
<hr>
<p>待补充</p>
<hr>
]]></content>
  </entry>
  <entry>
    <title>图神经网络(二)</title>
    <url>/2023/10/23/%E5%9B%BE%E8%81%94%E9%82%A6/</url>
    <content><![CDATA[<h1 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h1><h2 id="什么是图"><a href="#什么是图" class="headerlink" title="什么是图"></a>什么是图</h2><h3 id="图基本模块定义"><a href="#图基本模块定义" class="headerlink" title="图基本模块定义"></a>图基本模块定义</h3><p><strong>V</strong>：点，每个点都有自己的特征向量（特征举例：邻居点数量、一阶二阶相似度）<br><strong>E</strong>：边，每个边都有自己的特征向量（特征举例：边的权重值、边的定义）<br><strong>U</strong>：整个图，每个图都有自己的特征向量（特征举例：节点数量、图直径）</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/N3L9b5XmxqAulwQ.png"
                      alt="image.png" style="zoom:50%;" 
                >

<h3 id="图神经网络要做的事情"><a href="#图神经网络要做的事情" class="headerlink" title="图神经网络要做的事情"></a>图神经网络要做的事情</h3><ul>
<li>为每个节点整合特征向量，根据其对节点做分类或者回归</li>
<li>为每条边整合特征向量，根据其对边做分类或者回归</li>
<li>为每张图整合特征向量，根据其对图做分类或者回归</li>
</ul>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/WkdzsvblxDIr6KP.png"
                      alt="image.png" style="zoom:50%;" 
                >

<p>每个顶点、边和整张图都可以用一个向量来表示，在这个例子中，顶点的向量有六个值，柱体的高矮就表示该值的大小，每条边用一个长为8的向量来表示，全局用一个长为5的向量来表示</p>
<p>图分为两种，一种是有向图，一种是无向图。有向图就是单边关系图，比如A暗恋B，而B并没有暗恋A，这就是一个单边关系；无向图就是互为这种关系，比如说情侣，双方互相喜欢。</p>
<h2 id="怎么把一些内容表示成图"><a href="#怎么把一些内容表示成图" class="headerlink" title="怎么把一些内容表示成图"></a>怎么把一些内容表示成图</h2><p>比如说一张图片可以表示为一个244*244*3的tensor，244*244个像素，3个rgb通道。就可以像下图这样表示，点表示的是像素，边表示的是像素间的邻接关系，<a class="link"   href="https://distill.pub/2021/gnn-intro/" >建议大家去博客看一看 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，可以互动，更为直观。用数组（如 244x244x3 浮点数）表示。另一种将图像视为具有规则结构的图的方法是，每个像素代表一个节点，并通过边与相邻像素相连。每个无边框的像素正好有 8 个邻居，每个节点存储的信息是一个三维向量，代表像素的 RGB 值。</p>
<p>通过邻接矩阵可以直观地了解图形的连通性。我们对节点进行排序、</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/faQOMBTdotEG6ei.png"
                      alt="image.png" style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20231023092312097.png"
                      alt="image-20231023092312097" style="zoom:50%;" 
                >

<h3 id="将一句话表示成图"><a href="#将一句话表示成图" class="headerlink" title="将一句话表示成图"></a>将一句话表示成图</h3><p>句子中的每个单词可以表示成一个节点，有向边表示这些单词的链接关系.</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/J2dtcVfqBuk14Zv.png"
                      alt="image.png" style="zoom:50%;" 
                >

<h3 id="其他可以表示成图的信息"><a href="#其他可以表示成图的信息" class="headerlink" title="其他可以表示成图的信息"></a>其他可以表示成图的信息</h3><h2 id="哪些类型的问题有图结构数据-图形结构化数据有哪些类型的问题"><a href="#哪些类型的问题有图结构数据-图形结构化数据有哪些类型的问题" class="headerlink" title="哪些类型的问题有图结构数据,图形结构化数据有哪些类型的问题"></a>哪些类型的问题有图结构数据,图形结构化数据有哪些类型的问题</h2><p>图上的预测任务一般有三种类型：图级、节点级和边。</p>
<p>在图层面的任务中，我们预测整个图的单一属性。在节点级任务中，我们要预测图中每个节点的某些属性。在边缘级任务中，我们要预测图中边缘的属性或存在。</p>
<h3 id="图层面的任务"><a href="#图层面的任务" class="headerlink" title="图层面的任务"></a>图层面的任务</h3><p>基于整个图，做分类和回归。<br>例如，给定一个分子结构图，判断它里面存在几个环 或者 判断该分子结构属于哪一类</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/5dVB2bUvL8PytH4.png"
                      alt="判断有两个环" style="zoom:50%;" 
                >

<p>这类似于 MNIST 和 CIFAR10 的图像分类问题，我们希望将标签与整幅图像关联起来。对于文本，类似的问题是情感分析，我们希望一次性识别整个句子的情绪或情感。</p>
<h3 id="Node与Edge级别任务"><a href="#Node与Edge级别任务" class="headerlink" title="Node与Edge级别任务"></a>Node与Edge级别任务</h3><p>预测图中每个节点的身份或角色，即预测点<br>预测两个点之间的关系（是打架关系还是观看关系），即预测边</p>
<p>根据图像类比，节点级预测问题类似于图像分割，我们试图标记图像中每个像素的角色。对于文本，类似的任务是预测句子中每个单词的语音部分（如名词、动词、副词等）</p>
<p>边级别推理的一个例子是图像场景理解。除了识别图像中的物体，深度学习模型还可用于预测它们之间的关系。我们可以将其表述为边缘级分类：给定代表图像中物体的节点，我们希望预测这些节点中哪些共享一条边缘，或者这条边缘的值是多少。如果我们希望发现实体之间的联系，我们可以考虑完全连接的图，并根据预测值修剪边，从而得到一个稀疏的图。</p>
<h2 id="在机器学习中使用图的挑战"><a href="#在机器学习中使用图的挑战" class="headerlink" title="在机器学习中使用图的挑战"></a>在机器学习中使用图的挑战</h2><p>核心问题是怎样表示图才能是和神经网络是兼容的。图上有四种信息：顶点的属性，边的属性，全局信息以及连接性（即为每条边连接的是哪两个顶点）。前三个信息都能用向量来表示，怎么表示连接性呢？</p>
<p>我们可以用邻接矩阵来表示，该矩阵会是一个方阵，但是有一些问题。这个矩阵可能会非常大而且很稀疏，在空间上效率低下，并且计算比较困难。另外将邻接矩阵的行或列的顺序进行交换不会改变其属性的。比如下面两张图都是前面“Othello”的人物关系图，看着不一样只是因为行和列的顺序不同，但是表示的信息是一样的。这就意味着如果你设计一个神经网络，无论你用下面两张图中的哪一张，都要保证得到的结果是一样的。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/TZfvUw9h6DnXkRa.png"
                      alt="image.png" style="zoom:50%;" 
                >

<p>之前学过，邻接矩阵的大小为N*N，当节点很多的时候，邻接矩阵的大小也会特别大</p>
<p> 如果既想高效的存储邻接矩阵，又想这个顺序不会影响神经网络的结果，就可以用邻接链表的方式来表示邻接矩阵。</p>
<p>比如下方这个，顶点，边和全局信息都用标量来表示，也可以用向量，连接性用邻接链表来表示，邻接链表的数量和边的数量是一致的，第i项表示的是第i条边连接的两个顶点；这样表示就很高效，而且不会受到顺序的影响。博客里面是可以改变数值和边的数量的，建议自己去博客玩一下。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/uO61Bq4l3NcgoaV.png"
                      alt="image.png" style="zoom:50%;" 
                >

<p><strong>汇总 &#x3D; 自身的信息 + 所有邻居点的信息</strong></p>
<p><strong>所有邻居点信息的表达有几种：</strong></p>
<ul>
<li><strong>求解Sum</strong></li>
<li><strong>求平均Mean</strong></li>
<li><strong>求最大Max</strong></li>
<li><strong>求最小Min</strong></li>
</ul>
<h1 id="Graph-Neural-Networks图神经网络"><a href="#Graph-Neural-Networks图神经网络" class="headerlink" title="Graph Neural Networks图神经网络"></a>Graph Neural Networks图神经网络</h1><p><strong>A GNN is an optimizable transformation on all attributes of the graph (nodes, edges, global-context) that preserves graph symmetries (permutation invariances).</strong></p>
<p>GNN是对保持图对称性(排列不变性)的图的所有属性(节点、边、全局上下文)的可优化转换。对称信息指的是把这个顶点进行另外一个排序后，整个结果是不会变的。</p>
<p>这篇博客的GNN是用“信息传递神经网络”框架来搭建的，GNN的输入是一个图，输出也是一个图，它会对你的图的属性（点，边，全局信息）进行变换，但不会改变图的连接性，就是哪条边连接哪条顶点，这个信息是不会改变的</p>
<h3 id="最简单的GNN层"><a href="#最简单的GNN层" class="headerlink" title="最简单的GNN层"></a>最简单的GNN层</h3><p>对顶点向量、边向量和全局向量分别构造一个多层感知机（MLP），输入的大小和输出的大小是相同的，这三个MLP就组成了一个GNN的层，输入是一个图，输出也是一个图，并且连接性不变。</p>
<p>满足了上文中对GNN的第一个要求，只对属性进行变换，并不改变图的结构；并且MLP是对每个向量独自作用，对样本前后顺序没有要求，所以也就满足了图的排列不变性，满足了第二个要求。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/23/XvRps8DfrwK7iTH.png"
                      alt="image.png"
                ></p>
<h3 id="通过池化信息对GNN预测"><a href="#通过池化信息对GNN预测" class="headerlink" title="通过池化信息对GNN预测"></a>通过<a class="link"   href="https://so.csdn.net/so/search?q=%E6%B1%A0%E5%8C%96&spm=1001.2101.3001.7020" >池化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>信息对GNN预测</h3>]]></content>
  </entry>
  <entry>
    <title>数据的读取与处理</title>
    <url>/2023/10/18/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/</url>
    <content><![CDATA[<h1 id="数据预处理、数据增强"><a href="#数据预处理、数据增强" class="headerlink" title="数据预处理、数据增强"></a>数据预处理、数据增强</h1><h2 id="1-数据增强"><a href="#1-数据增强" class="headerlink" title="1. 数据增强"></a>1. 数据增强</h2><p>数据增强可以增加训练集的样本数量，缓解过拟合，并提高模型的泛化能力，从而有效提升算法的性能。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://p.ipic.vip/a161sy.png"
                      alt="数据增强"
                ></p>
<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h2><p>1）将图像转换成 tensor 的数据格式</p>
<p>2）将图像的 像素值范围 由 0～255 转换到 0～1</p>
<p>3）(height, width, channel) &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;&gt;&gt; (channel, height, width)</p>
<p>4）归一化图像</p>
<h2 id="3-使用节点"><a href="#3-使用节点" class="headerlink" title="3. 使用节点"></a>3. 使用节点</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">trans = transforms.Compose([transforms.RandomResizedCrop((<span class="number">640</span>, <span class="number">640</span>)),</span><br><span class="line">                            transforms.RandomHorizontalFlip(<span class="number">0.5</span>),</span><br><span class="line">                            transforms.ColorJitter(<span class="number">0.5</span>),</span><br><span class="line">                            transforms.ToTensor(),</span><br><span class="line">                            transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://p.ipic.vip/iiqcob.png"
                     
                ></p>
<h1 id="torchvision-transforms-的使用"><a href="#torchvision-transforms-的使用" class="headerlink" title="torchvision.transforms 的使用"></a>torchvision.transforms 的使用</h1><p>官方文档地址： <a class="link"   href="https://pytorch.org/vision/stable/transforms.html" >https://pytorch.org/vision/stable/transforms.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h2 id="1-torchvision-transforms-ToTensor"><a href="#1-torchvision-transforms-ToTensor" class="headerlink" title="1. torchvision.transforms.ToTensor()"></a>1. torchvision.transforms.ToTensor()</h2><p><code>torchvision.transforms.ToTensor()</code> 做了三件事：</p>
<p> 1）将图像的数据格式由 nump.ndarray 或 PIL.Image 转为 tensor，数据类型为 torch.FloatTensor</p>
<p> 2）将像素值范围从 0-255 转换到 0-1之间， 处理方式 ：直接除以255</p>
<p> 3）将 shape&#x3D;(H,W, C) 转换为 shape&#x3D; (C, H, W)</p>
<p>🌼原始的data的shape为（5，5，3），则其表示有5个（5 ， 3）的二维数组，即我们把最外层的[]去掉就得到了5个五行三列的数据。</p>
<p>🌼同样的，变换后data的shape为（3，5，5），则其表示有3个（5 ， 5）的二维数组，即我们把最外层的[]去掉就得到了3个五行五列的数据。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://p.ipic.vip/xksmgr.png"
                     
                ></p>
<h2 id="2-torchvision-transforms-Normalize"><a href="#2-torchvision-transforms-Normalize" class="headerlink" title="2. torchvision.transforms.Normalize()"></a>2. torchvision.transforms.Normalize()</h2><p>作用：用均值和标准差对张量图像进行归一化，一般在 <code>torchvision.transforms.ToTensor()</code> 之后使用</p>
<p>在使用 <code>torchvision.transforms.ToTensor()</code> 之后，像素值取值范围会被转换到 [0, 1]之间，再使用 <code>transforms.Normalize(mean, std)</code> 进行归一化后，原像素值就被分布到了 [-1, 1] 之间：</p>
<p>公式：</p>
<ul>
<li>原来的 0~1 最小值 0 则变成 (0 - mean) &#x2F; std &#x3D; -1</li>
</ul>
<ul>
<li>最大值1则变成 (1 - mean) &#x2F; std &#x3D; 1</li>
</ul>
<p>一般 mean 和 std 会分别指定3个值，代表图像3个通道的均值和方差，比如<code>torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])</code></p>
<p>如果是<strong>单通道的灰度图</strong>，均值为0.5，方差为0.5，可以写成 <code>transforms.Normalize(mean=[0.5], std=[0.5])</code></p>
<p>因为 ImageNet数据集 是一个大型数据集，由一个大型数据集统计出来的均值和方差，基本符合所有数据集的像素值分布，所以，一般直接使用 <code>mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]</code></p>
<h2 id="3-transforms-Compose"><a href="#3-transforms-Compose" class="headerlink" title="3.transforms.Compose()"></a>3.transforms.Compose()</h2><p><strong>训练阶段</strong></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">trans = transforms.Compose([transforms.RandomResizedCrop((<span class="number">640</span>, <span class="number">640</span>)),</span><br><span class="line">                            transforms.RandomHorizontalFlip(<span class="number">0.5</span>),</span><br><span class="line">                            transforms.ColorJitter(<span class="number">0.5</span>),</span><br><span class="line">                            transforms.ToTensor(),</span><br><span class="line">                            transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br></pre></td></tr></table></figure></div>



<p><strong>推理阶段(test)</strong></p>
<p>推理阶段不会再对数据进行增强，只会做基础的预处理，比如：将尺寸处理到固定尺寸 ；使用 ToTensor 处理数据； Normalize 归一化</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">trans = transforms.Compose([transforms.RE((<span class="number">640</span>, <span class="number">640</span>)),</span><br><span class="line">                            transforms.ToTensor(),</span><br><span class="line">                            transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br></pre></td></tr></table></figure></div>



<h2 id="4-transforms-RandomResizedCrop随机尺寸裁剪"><a href="#4-transforms-RandomResizedCrop随机尺寸裁剪" class="headerlink" title="4.transforms.RandomResizedCrop随机尺寸裁剪"></a>4.transforms.RandomResizedCrop随机尺寸裁剪</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">resized_crop = transforms.RandomResizedCrop(size=(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">                                            scale=(<span class="number">0.08</span>, <span class="number">1.0</span>), </span><br><span class="line">                                            ratio=(<span class="number">0.75</span>, <span class="number">1.3333333333333333</span>), </span><br><span class="line">                                            interpolation=transforms.InterpolationMode.BILINEAR)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">上方代码解释：</span></span><br><span class="line"><span class="string"> 1、将图像进行随机裁剪，裁剪满足以下条件:</span></span><br><span class="line"><span class="string"> 裁剪后的图像 面积 与原图像的面积的比例 在 0.08 ～ 1</span></span><br><span class="line"><span class="string"> 裁剪后的图像高宽比范围在 0.75 ～ 1.33之间</span></span><br><span class="line"><span class="string"> 2、按照指定的插值方式， 将图像尺寸缩放到 （224， 224）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div>

<p>参数：</p>
<ul>
<li>size：期望的输出图像尺寸， 可以是 int值，也可可以是元组（H, W）</li>
<li>scale ：在调整大小之前指定裁剪的随机区域的下界和上界。尺度是根据原始图像的面积来定义的。</li>
<li>ratio：在调整大小之前，裁剪的随机纵横比的下限和上限。</li>
<li>InterpolationMode ： 插值方式<ul>
<li>InterpolationMode.NEAREST：最近邻插值。</li>
<li>InterpolationMode.BILINEAR：双线性插值 (默认)</li>
<li>InterpolationMode.BICUBIC：双三次插值。</li>
</ul>
</li>
</ul>
<h2 id="5-水平翻转与垂直翻转"><a href="#5-水平翻转与垂直翻转" class="headerlink" title="5.水平翻转与垂直翻转"></a>5.水平翻转与垂直翻转</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">horizontal_flip = transforms. RandomHorizontalFlip(<span class="number">0.5</span>)</span><br><span class="line">vertical_flip = transforms. RandomVerticalFlip(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://p.ipic.vip/wh6b5i.png"
                     
                ></p>
<h2 id="6-ColorJitter"><a href="#6-ColorJitter" class="headerlink" title="6. ColorJitter"></a>6. ColorJitter</h2>]]></content>
  </entry>
  <entry>
    <title>联邦学习实战</title>
    <url>/2023/10/21/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<p>前言</p>
<p>GitHub网站资源：</p>
<p><a class="link"   href="https://github.com/FederatedAI/Practicing-Federated-Learning" >https://github.com/FederatedAI/Practicing-Federated-Learning <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接0-1：教学资源</p>
<p><a class="link"   href="https://ising.cse.ust.hk/fl/index.html" > https://ising.cse.ust.hk/fl/index.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第3章</p>
<p>链接3-1：Anaconda下载地址 <a class="link"   href="https://www.anaconda.com/products/individual" >https://www.anaconda.com/products/individual <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接3-2：CUDA下载地址 <a class="link"   href="https://developer.nvidia.com/cuda-downloads" >https://developer.nvidia.com/cuda-downloads <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接3-3：cuDNN下载地址 <a class="link"   href="https://developer.nvidia.com/rdp/cudnn-archive" >https://developer.nvidia.com/rdp/cudnn-archive <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接3-4：PyTorch官方文档 <a class="link"   href="https://pytorch.org/tutorials/" >https://pytorch.org/tutorials/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接3-5：torchvision内置模型 </p>
<p><a class="link"   href="https://pytorch.org/vision/stable/models.html" >https://pytorch.org/vision/stable/models.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第4章</p>
<p>链接4-1：FATE项目地址 <a class="link"   href="https://github.com/FederatedAI/FATE" >https://github.com/FederatedAI/FATE <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接4-2：LINUX基金会与FATE平台合作新闻稿 </p>
<p><a class="link"   href="https://www.linuxfoundation.org/press-release/2019/06/the-linux-foundation-will-host-the-federated-ai-enabler-to-responsibly-advance-data-modeling/" >https://www.linuxfoundation.org/press-release/2019/06/the-linux-foundation-will-host-the-federated-ai-enabler-to-responsibly-advance-data-modeling/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接4-3：FATE中文文档 <a class="link"   href="https://github.com/FederatedAI/DOC-CHN" >https://github.com/FederatedAI/DOC-CHN <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接4-4：FATE单机版本 </p>
<p><a class="link"   href="https://github.com/FederatedAI/DOC-CHN/tree/master/%E9%83%A8%E7%BD%B2" >https://github.com/FederatedAI/DOC-CHN/tree/master/%E9%83%A8%E7%BD%B2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接4-5：FATE集群版本部署 </p>
<p><a class="link"   href="https://github.com/FederatedAI/DOC-CHN/tree/master/%E9%83%A8%E7%BD%B2" >https://github.com/FederatedAI/DOC-CHN/tree/master/%E9%83%A8%E7%BD%B2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接4-6：KubeFATE部署</p>
<p><a class="link"   href="https://github.com/FederatedAI/KubeFATE/tree/master/docker-deploy" >https://github.com/FederatedAI/KubeFATE/tree/master/docker-deploy <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接4-7：FedAI官方网站 <a class="link"   href="https://cn.fedai.org/cases/" >https://cn.fedai.org/cases/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第5章</p>
<p>链接5-1：第五章对应代码</p>
<p><a class="link"   href="https://github.com/FederatedAI/federated_learning_in_action/tree/master/chapter05_FATE_HFL" >https://github.com/FederatedAI/Practicing-Federated-Learning/tree/master/chapter05_FATE_HFL  <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接5-2：乳腺癌数据集 </p>
<p><a class="link"   href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)" >https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第6章</p>
<p>链接6-1：第六章对应代码</p>
<p><a class="link"   href="https://github.com/FederatedAI/Practicing-Federated-Learning/tree/master/chapter06_FATE_VFL" >https://github.com/FederatedAI/Practicing-Federated-Learning/tree/master/chapter06_FATE_VFL <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> </p>
<p>链接6-2：Boston Housing数据集地址</p>
<p><a class="link"   href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" >https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第7章</p>
<p>链接7-1：FATE项目地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/FATE" >https://github.com/FederatedAI/FATE <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-2：FATE帮助文档</p>
<p><a class="link"   href="https://github.com/FederatedAI/DOC-CHN" >https://github.com/FederatedAI/DOC-CHN <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-3：本书配套代码</p>
<p><a class="link"   href="https://github.com/FederatedAI/federated_learning_in_action" >https://github.com/FederatedAI/Practicing-Federated-Learning <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-4：TFF的项目地址 <a class="link"   href="https://github.com/tensorflow/federated" >https://github.com/tensorflow/federated <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-5：TFF的官方网站 <a class="link"   href="https://www.tensorflow.org/federated?hl=zh-cn" >https://www.tensorflow.org/federated?hl=zh-cn <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-6： PySyft的项目地址  <a class="link"   href="https://github.com/OpenMined/PySyft" >https://github.com/OpenMined/PySyft <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-7： PySyft的官方网站  <a class="link"   href="https://www.openmined.org/" >https://www.openmined.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-8：医疗场景联邦学习介绍  <a class="link"   href="https://www.youtube.com/watch?v=bVU-Ea6hc0k" >https://www.youtube.com/watch?v=bVU-Ea6hc0k <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-9：Clara联邦学习平台 <a class="link"   href="https://devblogs.nvidia.com/federated-learning-clara/" >https://devblogs.nvidia.com/federated-learning-clara/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-10：paddleFL官方文档 <a class="link"   href="https://github.com/PaddlePaddle/PaddleFL" >https://github.com/PaddlePaddle/PaddleFL <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-11：paddleFL项目地址  <a class="link"   href="https://github.com/PaddlePaddle/PaddleFL" >https://github.com/PaddlePaddle/PaddleFL <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-12：Angel项目地址 <a class="link"   href="https://github.com/Angel-ML/angel" >https://github.com/Angel-ML/angel <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接7-13：同盾iBond平台官网 <a class="link"   href="https://www.tongdun.cn/ai/solution/aiknowledge" >https://www.tongdun.cn/ai/solution/aiknowledge <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第9章</p>
<p>链接9-1：联邦矩阵分解的项目地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/FedRec/tree/master/federatedrec/matrix_factorization/hetero_matrixfactor" >https://github.com/FederatedAI/FedRec/tree/master/federatedrec/matrix_factorization/hetero_matrixfactor <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接9-2：联邦因子分解机项目地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/FedRec/tree/master/federatedrec/factorization_machine/hetero_factorization_machine" >https://github.com/FederatedAI/FedRec/tree/master/federatedrec/factorization_machine/hetero_factorization_machine <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接9-3：联邦推荐项目地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/FedRec/tree/master/federatedrec" >https://github.com/FederatedAI/FedRec/tree/master/federatedrec <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接9-4：联邦推荐云服务</p>
<p><a class="link"   href="https://market.cloud.tencent.com/products/19083" >https://market.cloud.tencent.com/products/19083 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第10章</p>
<p>链接10-1：联邦视觉论文地址</p>
<p><a class="link"   href="https://arxiv.org/abs/2001.06202" >https://arxiv.org/abs/2001.06202 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接10-2：视觉案例基于Flask-SocketIO的Python实现地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/federated_learning_in_action/blob/master/chapter10_FL_Computer-Vision" >https://github.com/FederatedAI/Practicing-Federated-Learning/blob/master/chapter10_Computer_Vision <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接10-3：视觉案例在PaddleFL上的实现地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/FedVision" >https://github.com/FederatedAI/FedVision <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接10-4：Flask-SocketIO官方文档</p>
<p><a class="link"   href="https://github.com/miguelgrinberg/Flask-SocketIO" >https://github.com/miguelgrinberg/Flask-SocketIO <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接10-5：FATE数据集官网</p>
<p><a class="link"   href="https://dataset.fedai.org/" >https://dataset.fedai.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第12章</p>
<p>链接12-1：医疗案例论文网址  <a class="link"   href="https://arxiv.org/abs/2006.10517" >https://arxiv.org/abs/2006.10517 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接12-2： LIDC-IDRI肺结节公开数据集</p>
<p><a class="link"   href="https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI" >https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第13章</p>
<p>链接13-1：微众银行AI赋能灵活用工研究论文荣获IJCAI 2019“创新奖”</p>
<p><a class="link"   href="http://www.geekpark.net/news/246406" >http://www.geekpark.net/news/246406 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接13-2：Zhiyouren应用程序  <a class="link"   href="http://www.zyrwork.com/" >http://www.zyrwork.com/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接13-3：FedGame视频 <a class="link"   href="https://youtu.be/4qd48QfcsXI" >https://youtu.be/4qd48QfcsXI <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第14章</p>
<p>链接14-1：贵州大数据交易所官网 <a class="link"   href="http://www.gbdex.com/website/" >http://www.gbdex.com/website/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接14-2：贵阳大数据交易所数据定价</p>
<p><a class="link"   href="http://trade.gbdex.com/trade.web/userMessage/dataServer?type=5" >http://trade.gbdex.com/trade.web/userMessage/dataServer?type=5 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接14-3：FedCoin文献地址 <a class="link"   href="https://arxiv.org/abs/2002.11711" >https://arxiv.org/abs/2002.11711 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接14-4：FedCoin Demo页面  <a class="link"   href="http://demo.blockchain-neu.com/" >http://demo.blockchain-neu.com <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接14-5：FedCoin视频展示  <a class="link"   href="https://youtu.be/u5LPLdZvd0g" >https://youtu.be/u5LPLdZvd0g <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第15章</p>
<p>链接15-1：后门攻击代码地址</p>
<p><a class="link"   href="https://github.com/FederatedAI/federated_learning_in_action/blob/master/chapter15_Attack_and_Defense" >https://github.com/FederatedAI/Practicing-Federated-Learning/blob/master/chapter15_Attack_and_Defense <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第16章</p>
<p>链接16-1：python socket使用文档 </p>
<p><a class="link"   href="https://docs.python.org/3/library/socket.html" >https://docs.python.org/3/library/socket.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接16-2： python-socketio使用文档 </p>
<p><a class="link"   href="https://python-socketio.readthedocs.io/en/latest/index.html" >https://python-socketio.readthedocs.io/en/latest/index.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接16-3： Flask-socketio使用文档 <a class="link"   href="https://flask-socketio.readthedocs.io/en/latest/" >https://flask-socketio.readthedocs.io/en/latest/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接16-4：gRPC官方网站  <a class="link"   href="https://grpc.io/" >https://grpc.io/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接16-5：ICE官网 <a class="link"   href="https://zeroc.com/" >https://zeroc.com/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接16-6：ICE下载页面 <a class="link"   href="https://zeroc.com/downloads/ice" >https://zeroc.com/downloads/ice <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接16-7：ICE使用文档 <a class="link"   href="https://doc.zeroc.com/" >https://doc.zeroc.com/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第18章</p>
<p>链接18-1：Split Learning项目地址 <a class="link"   href="https://splitlearning.github.io/" >https://splitlearning.github.io/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接18-2：AWS Greengrass  <a class="link"   href="https://aws.amazon.com/cn/greengrass/" >https://aws.amazon.com/cn/greengrass/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接18-3：Azure IOT edge <a class="link"   href="https://azure.microsoft.com/en-us/services/iot-edge/" >https://azure.microsoft.com/en-us/services/iot-edge/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接18-4：Edge TPU  <a class="link"   href="https://cloud.google.com/edge-tpu" >https://cloud.google.com/edge-tpu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接18-5：Google Cloud IoT Core  <a class="link"   href="https://cloud.google.com/iot-core" >https://cloud.google.com/iot-core <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>第19章</p>
<p>链接19-1：联邦机器学习IEEE标准项目 </p>
<p><a class="link"   href="https://standards.ieee.org/project/3652_1.html" >https://standards.ieee.org/project/3652_1.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接19-2：联邦机器学习工作组  <a class="link"   href="https://sagroups.ieee.org/3652-1/" >https://sagroups.ieee.org/3652-1/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接19-3：Clara联邦学习医疗平台</p>
<p><a class="link"   href="https://devblogs.nvidia.com/federated-learning-clara/" >https://devblogs.nvidia.com/federated-learning-clara/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接19-4：GBoard输入法模型</p>
<p><a class="link"   href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" >https://ai.googleblog.com/2017/04/federated-learning-collaborative.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>链接19-5：可解析性AI标准  <a class="link"   href="https://sagroups.ieee.org/2894/" >https://sagroups.ieee.org/2894/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
  </entry>
  <entry>
    <title>论文笔记Towards Personalized Federated Learning</title>
    <url>/2023/10/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0Towards-Personalized-Federated-Learning/</url>
    <content><![CDATA[<h2 id="为什么需要联邦学习"><a href="#为什么需要联邦学习" class="headerlink" title="为什么需要联邦学习"></a>为什么需要联邦学习</h2><p>在这个数字时代，公司和机构正在使用大数据和人工智能(AI)来优化他们的流程和性能。虽然丰富的数据为人工智能应用提供了巨大的机会，但这些<strong>数据</strong>中的大多数本质上都是<strong>高度敏感</strong>的，它们以<strong>孤立</strong>的形式存在。这在医疗保健行业尤其如此，<strong>因为医疗数据高度敏感，而且它们通常被收集并驻留在不同的医疗机构</strong>。这种情况给人工智能的应用带来了巨大的挑战，因为传统的人工智能方法不能很好地解决数据隐私问题。随着最近出台的<strong>数据隐私保护法律</strong>，如通用数据保护条例(GDPR)，为了遵从法律需求，对隐私保护的人工智能的需求越来越大。</p>
<h2 id="为什么需要个性化联邦学习"><a href="#为什么需要个性化联邦学习" class="headerlink" title="为什么需要个性化联邦学习"></a>为什么需要个性化联邦学习</h2><p>一般的FL方法面临几个基本挑战：</p>
<ol>
<li>在高度异构的数据上收敛性差；</li>
<li>缺乏解决方案个性化。</li>
</ol>
<p><strong>1. 在高度异质性的数据上收敛性差。</strong>当在非独立同分布（non I.I.D.）的数据上学习时，FedAvg的准确性会大大降低。这种性能下降归因于客户端漂移（client drift）的现象，因为在非IID的本地数据分布上进行了多轮本地训练和同步。下图2显示了客户端漂移对IID和非IID数据的影响。在FedAvg中，服务器模型参数的更新向客户端模型参数的平均值移动。当数据为IID时，平均模型接近于全局最优值 �∗ ，因为它与局部最优值 和 �2∗ 的距离相等。然而，当数据为非IID时，全局最优的�∗与局部最优的距离并不相等。在这个例子中，�∗更接近�2∗。因此，平均后的模型��+1将远离全局最优�∗，全局模型不会收敛到真正的全局最优。由于FedAvg算法在非IID数据上遇到收敛问题，需要仔细调整超参数（例如，学习率衰减）以提高学习稳定性。</p>
<p><strong>缺乏个性化的解决方案。</strong>在原始联邦学习的设定中，一个单一的全局共享模型被训练来适应 “平均化的客户端”。在各客户端的数据分布存在明显差异的情形下，单一全局模型难以应对与全局分布截然不同的局部分布情况。对于经常面临非独立同分布本地数据集的实际应用，仅有一个单一的模型往往是不够的。以为移动键盘开发语言模型为例，来自不同人群的用户可能会因为不同的代际、语言和文化上的细微差别而有不同的使用模式，比如，某些单词或表情符号可能会被特定的用户群体所使用。在这种情况下，需要对每个用户进行更有针对性的预测，将使词语的建议更有意义。</p>
<h2 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a><strong>Contributions</strong></h2><p>我们的调查聚焦于PFL，它研究在FL设置下学习个性化模型以处理统计异质性的问题。缺乏对PFL的全面调查，为新的研究人员提供了关于这一重要课题的系统视角。在本文中，我们弥补了当前FL文献中的这一空白。我们的主要贡献总结如下。</p>
<ol>
<li>我们简要概述了FL及其分类。本文还详细分析了当前外语学习环境下外语学习的关键动机。</li>
<li>我们确定了个性化策略来解决关键的FL挑战，并提供了一个独特的基于数据、基于模型、基于架构和基于相似性的视角来指导PFL文献的审查。基于这一视角，我们提出了一个层次分类法来展示现有的关于PFL的工作，突出了他们面临的挑战，他们的主要想法，以及他们提出的可能引入潜在局限性的假设。</li>
<li>我们讨论了当前文献中用于PFL基准测试的常用公共数据集和评估指标，并提出了增强PFL实验评估技术的建议。</li>
</ol>
<h2 id="个性化联邦学习的两种策略"><a href="#个性化联邦学习的两种策略" class="headerlink" title="个性化联邦学习的两种策略"></a>个性化联邦学习的两种策略</h2><h3 id="策略一：全局模型个性化，意在提升在异质数据上联邦训练的全局共享模型的性能。"><a href="#策略一：全局模型个性化，意在提升在异质数据上联邦训练的全局共享模型的性能。" class="headerlink" title="策略一：全局模型个性化，意在提升在异质数据上联邦训练的全局共享模型的性能。"></a>策略一：<strong>全局模型个性化，意在提升在异质数据上联邦训练的全局共享模型的性能</strong>。</h3><p>训练好全局FL模型，然后通过本地适应步骤为每个FL客户端进行个性化处理（包括在每个本地数据集上进行额外的训练）。这种两步走的 <strong>“联邦训练+本地适应 “方法（FL training + local adaptation）</strong>是一种重要的联邦个性化策略。由于个性化性能直接取决于全局模型的泛化性能，许多PFL方法旨在先提高全局模型在数据异质性下的性能，以提高随后在本地数据上的个性化性能。</p>
<p>这一类的个性化技术被分为基于数据和基于模型的方法。<strong>基于数据的方法旨在通过减少客户数据集之间的统计异质性来缓解客户漂移问题，而基于模型的方法旨在学习一个强大的全局模型，以便在未来对单个客户进行个性化定制或提高本地模型的适应性</strong>.</p>
<h3 id="策略二：学习个性化的模型，意在提供个性化解决方案。"><a href="#策略二：学习个性化的模型，意在提供个性化解决方案。" class="headerlink" title="策略二：学习个性化的模型，意在提供个性化解决方案。"></a>策略二：学习个性化的模型，意在提供个性化解决方案。</h3><p>与训练单一全局模型的全局模型个性化策略不同，这类的方法在每个客户端上<strong>训练单个的个性化模型</strong>。其目标是通过修改FL模型的聚合过程来建立个性化的模型。这是通过在FL环境中应用不同的学习范式实现的。</p>
<p><strong>个性化技术被分为基于架构和基于相似性的方法。基于架构的方法旨在为每个客户提供量身定制的个性化模型架构，而基于相似性的方法旨在利用客户关系来提高个性化模型的性能，即为相关客户建立类似的个性化模型。</strong></p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic2.zhimg.com/80/v2-aa0e4e1b0311cad2eedca3c18aed3a4d_1440w.webp"
                      alt="图片" style="zoom:50%;" 
                >

<p>这篇论文将个性化联邦学习分为前述两种策略，然后又在策略之下介绍了四大类十小类解决方案。</p>
<h2 id="Ⅲ-策略一：全局模型个性化"><a href="#Ⅲ-策略一：全局模型个性化" class="headerlink" title="Ⅲ.策略一：全局模型个性化"></a>Ⅲ.策略一：全局模型个性化</h2><p>在这一部分，我们回顾了遵循全局模型个性化策略的PFL方法。这些方法的主要设置和配置如图3所示。基于我们提出的分类方法，它们被分为基于数据的方法和基于模型的方法。</p>
<h3 id="基于数据的方法"><a href="#基于数据的方法" class="headerlink" title="基于数据的方法"></a>基于数据的方法</h3><p>受异质数据上的联合训练所产生的客户端漂移问题的启发，<strong>基于数据的方法旨在减少客户端数据分布的统计异质性。</strong></p>
<p><strong>数据增强 Data Augmentation</strong></p>
<p>由于训练数据的IID属性是统计学习理论中的一个基本假设，因此在机器学习领域中已经广泛地研究了提高数据统计同质性的数据扩充方法。涉及协同数据生成的过采样技术（如SMOTE和ADASYN）和欠采样技术（如Tomek links）已被提出，以减少数据的不平衡。但用于传统机器学习场景的数据增强方法不能直接用于联邦学习场景。</p>
<p><strong>联邦学习场景下通常需要某种形式的数据共享，或者需要获取依赖于代表整体数据分布的代理数据集。</strong></p>
<blockquote>
<p>Zhao等人提出了一种数据共享策略，将少量的全局数据按类别平衡分配给每个客户端。他们的实验表明，在增加少量数据的情况下，有可能获得显著的准确性提高（30%∼）。<br>Jeong等人提出了FAug，一种联合增强方法，在FL服务器中训练生成对抗网络（GAN）模型。一些少数群体的数据样本被上传至服务器以训练GAN模型。然后，训练好的GAN模型被分发到每个客户端，以产生更多的数据来增加其本地数据，从而产生一个IID数据集。<br>Duan等人提出了Astraea，一个自我平衡的FL框架，通过使用基于Z-score的数据增强和本地数据的下采样来处理类不平衡。FLserver需要关于客户本地数据分布的统计信息（例如，类大小、平均值和标准差值）。<br>Wu等人提出了FedHome算法，该算法使用FL训练生成卷积自动编码器（GCAE）模型。在FL程序结束时，每个客户在一个本地增强的类平衡数据集上执行进一步的个性化操作。这个数据集是通过在基于本地数据的编码网络的低维特征上执行SMOTE算法而产生的。</p>
</blockquote>
<p> <strong>挑选客户端 Client Selection</strong></p>
<p><strong>数据增强方法是将异质数据变得更加均质</strong>，挑选客户端的方法希望<strong>在优化过程中基于一些准则挑选客户端，以便得到更均匀的数据分布，提高模型的泛化性能。</strong></p>
<blockquote>
<p>Wang等人提出了FAVOR，为每轮训练选择一个参与客户的子集，以减轻非IID数据带来的偏差。他们设计了一个用于客户选择的深度Q-learning公式，目的是在最小化通信轮数的同时实现最大的准确性。<br>另有人提出了一个基于多臂老虎机公式的客户选择算法，以选择具有最小类别不平衡的客户子集。通过比较提交给FL服务器的本地梯度更新与驻留在服务器上的平衡代理数据集推断出的梯度之间的相似性来估计本地类分布。对于跨设备的FL，在计算和通信能力方面，硬件能力往往有很大的差异。数据中也存在异质性，即数据的数量和分布在客户之间存在差异。<br>Chai等人提出了一个基于层级的FL系统（TiFL），该系统根据训练性能将客户分成不同的层级，该算法通过优化准确性和训练时间从同一层级中选择参与训练的客户。这有助于缓解由数据和资源异质性造成的性能问题。<br>Li等人提出了FedSAE，一个自适应的FL系统，在每个训练场中自适应地选择局部训练损失较大的客户，以加速全局模型的收敛。还提出了一个预测每个客户可承受的工作量的机制，以便动态调整每个客户的局部训练纪元的数量，以提高设备的可靠性。</p>
</blockquote>
<h3 id="基于模型的方法"><a href="#基于模型的方法" class="headerlink" title="基于模型的方法"></a>基于模型的方法</h3><p>尽管<strong>基于数据的方法</strong>通过缓解客户漂移问题改善了全局FL模型的收敛性，但它们<strong>通常需要修改局部数据分布</strong>。这可能会导致与客户行为的固有多样性相关的宝贵信息的损失。这些信息对于为每个客户建立个性化的全局模型非常有用。</p>
<p><strong>基于模型的全局模型个性化</strong>的FL方法，其目的是<strong>学习一个强大的全局FL模型，以便将来对每个客户进行个性化处理，或者提高局部模型的适应性</strong>。</p>
<p><strong>1.2.1 增加模型局部损失正则项 Regularized Local Loss</strong></p>
<p>模型正则化是一种常见的策略，用于防止机器学习模型训练时的过度拟合和提高一致性。在FL中，正则化技术可以被用来限制局部更新的影响。这提高了收敛的稳定性和全局模型的概括性，反过来，它可以被用来产生更好的个性化模型。</p>
<p><strong>全局和局部模型之间比较。</strong>有几项工作在全局和局部模型之间实现了正则化，以解决FL中由于统计数据的异质性而普遍存在的客户端漂移问题。</p>
<blockquote>
<p>FedProx为本地子问题引入了一个近似项，考虑到全局FL模型和本地模型之间的不相似性来调整本地更新的影响。<br>FedCL进一步考虑了使用持续学习领域的弹性权重整合（EWC）的正则化局部损失函数中的参数重要性。然后，它们被转移到客户端，在那里进行惩罚步骤，以防止全局模型的重要参数在适应全局模型和客户的本地数据时被改变。这样做可以减轻本地和全局模型之间的权重差异，同时保留全局模型的知识以提高泛化能力。</p>
</blockquote>
<p><strong>历史局部模型快照之间比较。</strong>基于对比学习的FL-MOON被提出，MOON的目标是减少由局部模型和全局模型学习的表征之间的距离（即减轻权重分歧），并增加一个给定的局部模型和它的前一个局部模型之间学习的表征之间的距离（即加快融合）。这种新兴的方法使每个客户都能学习到接近全局模型的表征，以尽量减少局部模型的分歧。它还通过鼓励本地模型在前一版本的基础上进行改进来加速学习。</p>
<p><strong>元学习 Meta-learning</strong></p>
<p>元学习俗称 “学会学习”，元学习的目的是通过接触各种任务（即数据集）来改进学习算法。基于优化的元学习算法，如模型无关的元学习（MAML）和Reptile，因其在新的异质任务上的良好泛化和快速适应而闻名。它们也是模型不可知的，可以应用于任何基于梯度下降的方法，使其能够应用于监督学习和强化学习。</p>
<p>元学习算法的运行分为两个阶段：元训练和元测试。</p>
<blockquote>
<p>Jiang等作者将MAML中的元训练步骤映射到FL全局模型训练过程中，将元测试步骤映射到FL个性化过程中，其中在局部适应过程中对局部数据进行了几步梯度下降。他们还表明，FedAvg与Reptile算法类似，当所有客户拥有同等数量的本地数据时，实际上是等价的。鉴于元学习和FL算法表述的相似性，元学习技术可以应用于改善全局FL模型，同时在客户端上实现快速个性化.</p>
</blockquote>
<p>**</p>
<p> 迁移学习 Transfer learning**</p>
<p>迁移学习通常用于非联邦环境中的模型个性化。它的目的是将知识从源域转移到目标域，而这两个域往往是不同的，但又是相关的。TL是一种高效的方法，它利用了来自训练过的模型的知识转移，从而避免了从头建立模型的需要。</p>
<blockquote>
<p>FedMD是一个基于TL和知识转移（KD）的FL框架，供客户使用他们自己的私人数据设计独立的模型。在FL训练和KD阶段之前，首先使用一个在公共数据集上预训练的模型进行TL。然后，每个客户在其私人数据上微调该模型。</p>
</blockquote>
<p>为了实现PFL，通常采用领域适应性TL技术。这些技术旨在减少训练好的全局FL模型（即源域）和给定的局部模型（即目标域）之间的域差异，以提高个性化程度。在FL领域有几项研究，在医疗领域使用TL进行模型个性化（例如FedHealth和FedSteg）。</p>
<p><strong>训练过程一般包括三个步骤。1）通过FL训练全局模型；2）通过在本地数据上适应全局模型来训练本地模型；3）通过TL使用全局模型完善本地模型来训练个性化模型</strong>。为了实现领域适应性，通常<strong>在softmax层之前添加一个对齐层</strong>，如相关对齐（CORAL）层，以适应源域和目标域的二阶统计数据。</p>
<h3 id="基于架构的方法"><a href="#基于架构的方法" class="headerlink" title="基于架构的方法"></a>基于架构的方法</h3><p>基于架构的方法旨在通过为每个客户定制模型设计来实现个性化。</p>
<p>参数解耦方法为每个客户实现了每个个性化层，而知识蒸馏方法为每个客户支持个性化的模型架构。</p>
<p><strong>2.1.1 参数解耦</strong></p>
<p><strong>参数解耦的目的是通过将本地私有模型参数与全局FL模型参数解耦来实现PFL。私有参数在客户机上进行训练，不与FL服务器共享。这使得特定任务的表征可以被学习，以加强个性化。</strong></p>
<p>通常有两种配置用于深度学习的参数解耦。</p>
<p>第一种是**”基础层+个性化层**”设计。在这种设置中，个性化的深层被客户保留在本地训练中，以学习个性化的特定任务表征，而基础层则与FL客户端共享，以学习低层次的通用特征。</p>
<p>第二种设计考虑了<strong>每个客户端的个性化数据特征表征</strong>。</p>
<blockquote>
<p>局部全局联合训练（LG-FedAvg）被提出来结合局部表征学习和全局联合训练。学习低维的局部表征可以提高联合全球模型训练的通信和计算效率。它还提供了灵活性，因为可以根据源数据的模式（如图像和文本）设计专门的编码器。作者还展示了如何通过将对抗性学习纳入FL模型训练来学习对受保护属性（如种族和性别）不变的公平和无偏见的表征。</p>
</blockquote>
<p>参数解耦与另一种分布式和私有的机器学习范式——分割学习（SL, split learning）有一些相似之处。</p>
<p>在SL中，深度网络在服务器和客户端之间被分层。与参数解耦不同，SL中的服务器模型不会被转移到客户端进行模型训练。相反，在前向传播过程中，只有客户端模型分割层的权重是共享的，在反向传播过程中，分割层的梯度与客户端共享。因此，SL比FL有隐私优势，因为服务器和客户端不能完全访问全球和本地模型。然而，由于客户端的顺序训练过程，训练的效率较低。SL在非IID数据上的表现也比FL差，并且有更高的通信开销。</p>
<p><strong>2.1.2 知识蒸馏</strong></p>
<p>知识蒸馏。在基于服务器的横向联邦中，FL服务器和FL客户端都采用相同的模型结构。其基本假设是，客户有足够的通信带宽和计算能力。然而，对于有大量边缘设备作为FL客户端的实际应用，它们往往受到资源的限制。客户端也可能因为不同的训练目标而选择不同的模型架构。FL中知识蒸馏的关键动机是其具有更大的灵活性，以适应客户的个性化模型架构。同时，它还试图通过减少资源需求来解决通信和计算能力的挑战。</p>
<p>神经网络的知识蒸馏是一种将知识从教师模型集合转移到轻量级学生模型的准范式。在现有的蒸馏方法中，知识通常表示为类分数或Logit输出。一般来说，<strong>基于蒸馏的FL架构有四种主要类型。1）将知识蒸馏到每个FL客户端以学习更强的个人化模型；2）将知识蒸馏到FL服务器以学习更强的服务器模型；3）双向蒸馏到FL客户端和FL服务器；4）客户端之间的蒸馏。</strong></p>
<h3 id="2-2-基于相似性的方法"><a href="#2-2-基于相似性的方法" class="headerlink" title="2.2 基于相似性的方法"></a>2.2 基于相似性的方法</h3><p>基于相似性的方法旨在通过对客户关系建模来实现个性化。为每个客户学习一个个性化的模型，相似的客户学习类似的模型。</p>
<p>多任务学习（MTL）和模型插值考虑的是成对的客户关系，而聚类考虑的是群组级别客户关系。</p>
<p><strong>2.2.1 多任务学习 Multitask learning (MTL)</strong></p>
<p>多任务学习的目标是训练一个联合执行几个相关任务的模型。这可以通过利用特定领域的知识来提高学习任务的泛化性。在MTL中，通过将每个FL客户视为一个任务，有可能学习和捕捉客户之间由其异质的本地数据表现出来的关系。</p>
<blockquote>
<p>MOCHA算法将分布式MTL扩展到FL环境中。MOCHA使用原始-对偶公式来优化所学模型。该算法解决了FL中普遍存在的通信和系统挑战，而这些挑战在MTL领域是没有考虑的。与传统的FL设计不同，MOCHA学习的是单一的全局模型，它为每个FL客户端学习了一个个性化的模型。虽然MOCHA提高了个性化程度，但它并不适合于跨设备的FL应用，因为所有的客户端都需要参与每一轮的FL模型训练。MOCHA的另一个缺点是，它只适用于凸模型，因此不适合深度学习。<br>FedCurv使用EWC来防止在学习任务之间移动时出现灾难性的遗忘。参数的重要性用Fisher信息矩阵来估计，并进行惩罚步骤以保留重要的参数。在每个通信回合结束时，每个客户端将其更新的本地参数和Fisher信息矩阵的对角线发送给服务器。这些参数将在所有客户端之间共享，以便在下一轮中进行本地训练。</p>
</blockquote>
<p><strong>2.2.2 模型插值 model interpolation</strong></p>
<p>模型插值。</p>
<blockquote>
<p>filip等人提出使用全局和局部模型的混合来学习个性化的模型，以平衡泛化和个性化。每个FL客户学习一个单独的本地模型。惩罚参数λ被用来阻止局部模型与平均模型太不相似。当λ被设置为零时，发生纯局部模型学习。这相当完全PFL设置，其中每个客户端在本地训练自己的模型，而不与其他客户端进行任何通信。随着λ的增加，出现了混合模型学习，局部模型变得越来越相似。设置近似全局模型学习，当λ趋于无穷大时，强制所有局部模型相同。通过这种方式，可以控制个性化的程度。此外，作者还提出了一种沟通效率高的SGD变体，称为无环局部梯度下降(L2GD)。通过确定是执行局部GD步骤还是执行模型聚合步骤的概率框架，显著减少了通信轮数。<br>Deng等人提出了APFL算法，目标是以通信高效的方式找到全局和局部模型的最优组合。他们为每个客户端引入一个混合参数，该参数在FL训练过程中自适应学习，以控制全局和局部模型的权重。如果局部和全局数据分布不是网格对齐的，则特定局部模型上的权重因子预计会更大，反之亦然。mansour等人提出了一种类似的公式，涉及局部和全局模型的联合优化以确定最优插值权重。<br>Diao等人提出了基于单一全局模型的HeteroFL框架，该框架训练具有不同计算复杂性的局部模型。通过根据每个客户端的计算和通信能力自适应地分配不同复杂程度的本地模型，实现了PFL，以解决边缘计算场景中的系统异构性。</p>
</blockquote>
<p><strong>2.2.3 聚类 clustering</strong></p>
<p>对于客户端之间存在固有分区或数据分布明显不同的应用，采用“客户端-服务器”FL架构来训练一个共享的全局模型并不是最佳选择。一个多模型的方法，即<strong>为每个同质的客户群训练一个FL模型</strong>，是比较合适的。最近的一些工作集中在FL个性化的聚类上。<strong>基于聚类的FL的基本假设是存在一个基于其本地数据分布的客户自然分组</strong>。</p>
<hr>
<ol>
<li>在分类法的第一层，按照论文作者的说明，他们为了解决数据异质性提出了将全局模型进行个性化适应的策略，为了解决个性化方案提出了在客户端上学习个性化模型的方法。但小鱼觉得这个地方有些别扭，好像并不能这样一一对应。</li>
<li>在分类法的第二层，两种策略和四大类解决方案的对应关系我也觉得有些奇怪。</li>
<li>在分类法的第三层，针对基于模型的方法，这里论文正式版的分级方法是：</li>
</ol>
<blockquote>
<p>\1) Regularized Local Loss<br>\2) Between Global and Local Model<br>\3) Between Historical Local Model Snapshots a) Meta-learning b) Transfer learning</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>差分隐私（二）</title>
    <url>/2023/11/02/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<p>阅读本章后，您将能够：</p>
<ul>
<li>描述并实现梯度下降的基本算法</li>
<li>使用高斯机制实现差分私有梯度下降</li>
<li>裁剪梯度，为任意损失函数实施差分隐私</li>
<li>描述噪声对训练过程的影响</li>
</ul>
<h3 id="梯度下降的单步"><a href="#梯度下降的单步" class="headerlink" title="梯度下降的单步"></a>梯度下降的单步</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prediction: take a model (theta) and a single example (xi) and return its predicted label</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">xi, theta, bias=<span class="number">0</span></span>):</span><br><span class="line">    label = np.sign(xi @ theta + bias)</span><br><span class="line">    <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is the gradient of the logistic loss</span></span><br><span class="line"><span class="comment"># The gradient is a vector that indicates the rate of change of the loss in each direction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">theta, xi, yi</span>):</span><br><span class="line">    exponent = yi * (xi.dot(theta))</span><br><span class="line">    <span class="keyword">return</span> - (yi*xi) / (<span class="number">1</span>+np.exp(exponent))</span><br><span class="line">    </span><br><span class="line">theta = theta - gradient(theta, X_train[<span class="number">0</span>], y_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></div>



<h3 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h3><p>首先，我们上面的单个步骤仅使用了训练数据中的一个示例;我们希望在更新模型时考虑<em>整个</em>训练集，以便改进<em>所有</em>示例的模型。其次，我们需要执行多次迭代，以尽可能接近最小化损失。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">avg_grad</span>(<span class="params">theta, X, y</span>):</span><br><span class="line">    grads = [gradient(theta, xi, yi) <span class="keyword">for</span> xi, yi <span class="keyword">in</span> <span class="built_in">zip</span>(X, y)]</span><br><span class="line">    <span class="keyword">return</span> np.mean(grads, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">avg_grad(theta, X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">iterations</span>):</span><br><span class="line">    <span class="comment"># Start by &quot;guessing&quot; what the model should be (all zeros)</span></span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform `iterations` steps of gradient descent using training data</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        theta = theta - avg_grad(theta, X_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure></div>



<h1 id="具有差分隐私的梯度下降"><a href="#具有差分隐私的梯度下降" class="headerlink" title="具有差分隐私的梯度下降"></a>具有差分隐私的梯度下降</h1><p>使用训练数据的算法的唯一部分是梯度计算。使算法具有差分隐私的一种方法是在每次迭代之前向梯度本身添加噪声，然后再更新模型。这种方法通常称为噪声梯<em>度下降</em>，因为我们直接向梯度添加噪声。</p>
<p>我们的梯度函数是一个向量值函数，因此我们可以用<em>gaussian_mech_vec</em>来向其输出添加噪声</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">noisy_gradient_descent</span>(<span class="params">iterations, epsilon, delta</span>):</span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line">    sensitivity = <span class="string">&#x27;???&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        grad = avg_grad(theta, X_train, y_train)</span><br><span class="line">        noisy_grad = gaussian_mech_vec(grad, sensitivity, epsilon, delta)</span><br><span class="line">        theta = theta - noisy_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure></div>

<p>梯度函数的敏感性是什么？回答这个问题是使算法成功运行的核心难点。</p>
<p>首先，梯度是一个平均查询的结果 - 它是许多单个样本梯度的平均值。正如我们之前所看到的，最好将这类查询拆分为求和查询和计数查询。这并不难做到 - 我们可以计算<strong>每个单个样本梯度的带噪声的求和，而不是它们的平均值，然后稍后再除以一个嘈杂计数</strong>。其次，<strong>我们需要限定每个单个样本梯度的敏感性</strong>。</p>
<p>有两种基本方法可以做到这一点：我们可以分析梯度函数本身（就像我们之前处理其他查询一样）以确定其最坏情况下的全局敏感性，或者我们可以通过截断梯度函数的输出来强制实施敏感性（就像我们在采样和聚合中所做的那样）。</p>
<p>我们将从第二种方法开始 - 通常称为梯度剪切 - 因为在概念上更简单，而且在应用中更具通用性。</p>
<h3 id="Gradient-Clipping"><a href="#Gradient-Clipping" class="headerlink" title="Gradient Clipping"></a>Gradient Clipping</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/03/Nh9mJXlBAQb8vpV.png"
                      alt="image.png"
                > </p>
<p>我们可以使用相同的技巧来限制梯度函数的 L2 敏感性。我们需要定义一个函数，用于将一个向量“剪裁”，使其具有所需范围内的 L2 范数。我们可以通过对向量进行按元素除以其 L2 范数来实现这一目标，这样得到的向量将具有 L2 范数为1。如果我们希望定位到特定的剪裁参数 b，我们可以将缩放后的向量乘以 b，以将其重新缩放为具有 L2 范数 b。我们希望避免修改那些已经具有 L2 范数小于 b 的向量；在这种情况下，我们只返回原始向量。我们可以使用 <code>np.linalg.norm</code> 函数，参数 <code>ord=2</code>，来计算一个向量的 L2 范数。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">L2_clip</span>(<span class="params">v, b</span>):</span><br><span class="line">    norm = np.linalg.norm(v, <span class="built_in">ord</span>=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> norm &gt; b:</span><br><span class="line">        <span class="keyword">return</span> b * (v / norm)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure></div>

<p>现在，我们可以继续计算剪切梯度的和，并根据我们通过剪切所强制实施的 L2 敏感性 b 来添加噪声。        </p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_sum</span>(<span class="params">theta, X, y, b</span>):</span><br><span class="line">    gradients = [L2_clip(gradient(theta, x_i, y_i), b) <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> <span class="built_in">zip</span>(X,y)]<span class="comment">#####L2_clip裁剪</span></span><br><span class="line"><span class="comment"># sum query</span></span><br><span class="line"><span class="comment"># L2 sensitivity is b (by clipping performed above)</span></span><br><span class="line"><span class="keyword">return</span> np.<span class="built_in">sum</span>(gradients, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></div>

<p>现在，我们已准备好完成嘈杂梯度下降算法。要计算噪声平均梯度，我们需要：</p>
<ol>
<li>根据灵敏度b将噪声添加到梯度总和中</li>
<li>计算训练样本数的噪声计数（<strong>灵敏度 1</strong>）</li>
<li>将 （1） 的噪声总和除以 （2） 的噪声计数</li>
</ol>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">noisy_gradient_descent</span>(<span class="params">iterations, epsilon, delta</span>):</span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line">    sensitivity = <span class="number">1.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Laplace</span></span><br><span class="line">    noisy_count = laplace_mech(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, epsilon)  <span class="comment">####样本个数  灵敏度1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        grad_sum        = gradient_sum(theta, X_train, y_train, sensitivity)</span><br><span class="line">        noisy_grad_sum  = gaussian_mech_vec(grad_sum, sensitivity, epsilon, delta)</span><br><span class="line">        noisy_avg_grad  = noisy_grad_sum / noisy_count</span><br><span class="line">        theta           = theta - noisy_avg_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta	</span><br></pre></td></tr></table></figure></div>

<p>该算法的每次迭代都满足 (ϵ, δ)-差分隐私，并且我们执行一次额外的查询来确定满足 ϵ-差分隐私的嘈杂计数。如果我们执行了 K 次迭代，那么根据序列组合，该算法满足 (kϵ, kδ)-差分隐私。我们还可以使用高级组合来分析总隐私成本；更好的是，我们可以将算法转化为 Rényi 差分隐私或零浓缩差分隐私，并获得有关组合的严格边界。</p>
<h3 id="Sensitivity-of-the-Gradient"><a href="#Sensitivity-of-the-Gradient" class="headerlink" title="Sensitivity of the Gradient"></a>Sensitivity of the Gradient</h3><p>裁剪训练样本而不是梯度有两个优点。首先，估计训练数据的规模（从而选择一个好的裁剪参数）通常比估计训练期间计算的梯度的规模更容易。其次，它在计算效率更高：我们可以对训练样本进行一次裁剪，并在每次训练模型时重复使用裁剪后的训练数据;使用梯度裁剪时，我们需要在训练过程中裁剪每个梯度。此外，我们不再被迫计算每个样本的梯度，以便我们可以裁剪它们;相反，我们可以一次计算所有梯度，这可以非常有效地完成（这是机器学习中常用的技巧，但我们不会在这里讨论）</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/03/ukLiGKXFNHDvjbO.png"
                      alt="image.png"
                ></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_sum</span>(<span class="params">theta, X, y, b</span>):</span><br><span class="line">    gradients = [gradient(theta, x_i, y_i) <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> <span class="built_in">zip</span>(X,y)]   <span class="comment">#####不需要裁剪</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># sum query</span></span><br><span class="line">    <span class="comment"># L2 sensitivity is b (by sensitivity of the gradient)</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(gradients, axis=<span class="number">0</span>)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">noisy_gradient_descent</span>(<span class="params">iterations, epsilon, delta</span>):</span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line">    sensitivity = <span class="number">5.0</span></span><br><span class="line">    </span><br><span class="line">    noisy_count = laplace_mech(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, epsilon)</span><br><span class="line">    clipped_X = [L2_clip(x_i, sensitivity) <span class="keyword">for</span> x_i <span class="keyword">in</span> X_train]    <span class="comment">#####裁剪样本</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        grad_sum        = gradient_sum(theta, clipped_X, y_train, sensitivity)</span><br><span class="line">        noisy_grad_sum  = gaussian_mech_vec(grad_sum, sensitivity, epsilon, delta)</span><br><span class="line">        noisy_avg_grad  = noisy_grad_sum / noisy_count   <span class="comment">####带噪声的总和除以带噪声的计数</span></span><br><span class="line">        theta           = theta - noisy_avg_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h2><ol>
<li>裁剪梯度，求和。</li>
<li>根据灵敏度b来对和加噪          <em>noisy_grad_sum  &#x3D; gaussian_mech_vec(grad_sum, sensitivity, epsilon, delta)</em></li>
<li>获取带噪声的数量<em>noisy_count &#x3D; laplace_mech(X_train.shape[0], 1, epsilon)</em>  </li>
<li>差分隐私总和除以差分隐私计数，就是</li>
</ol>
<p>我们通过将查询拆分为两个查询来计算差分隐私均值：差分隐私总和（分子）和差分隐私计数（分母）。</p>
<h2 id="裁剪训练样本"><a href="#裁剪训练样本" class="headerlink" title="裁剪训练样本"></a>裁剪训练样本</h2><ol>
<li>首先，估计训练数据的规模（从而选择一个好的裁剪参数）通常比估计训练期间计算的梯度的规模更容易。</li>
<li>其次，它在计算效率更高：我们可以对训练样本进行一次裁剪，并在每次训练模型时重复使用裁剪后的训练数据;使用梯度裁剪时，我们需要在训练过程中裁剪每个梯度。</li>
<li>此外，我们不再被迫计算每个样本的梯度，以便我们可以裁剪它们;相反，我们可以一次计算所有梯度</li>
</ol>
<h2 id="Sensitivity-of-the-Gradient-1"><a href="#Sensitivity-of-the-Gradient-1" class="headerlink" title="Sensitivity of the Gradient"></a>Sensitivity of the Gradient</h2><p>样本的二范数小于b，那么那该样本的梯队也小于b，即灵敏度是   b</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>但是在一些代码中看到  ，裁剪的阀门是b，但是样本或者梯度的二范数可能是-b，灵敏度是2b？？？？？</p>
<p>为什么这里这么写呢</p>
<hr>
<h1 id="本地化差分隐私"><a href="#本地化差分隐私" class="headerlink" title="本地化差分隐私"></a>本地化差分隐私</h1><p>与差分隐私的中心模型相对，另一种模型是差分隐私的本地模型，其中数据在离开数据主体的控制之前被使成差分隐私的状态。例如，您可以在将数据发送给数据管理员之前在您的设备上向数据添加噪声。在本地模型中，数据管理员不需要被信任，因为他们收集的数据已经满足差分隐私的要求。</p>
<p>因此，本地模型相对于中心模型具有一个巨大的优势：数据主体不需要信任除了自己以外的任何人。这个优势使得它在实际部署中变得流行，包括谷歌和苹果等公司的应用。</p>
<p>不幸的是，本地模型也有一个重要的缺点：在本地模型下，相同的隐私成本下，查询结果的准确性通常比中心差分隐私下的相同查询低几个数量级。这种巨大的准确性损失意味着只有少数查询类型适合本地差分隐私，即使对于这些查询类型，也需要大量的参与者。</p>
<h2 id="Randomized-Response"><a href="#Randomized-Response" class="headerlink" title="Randomized Response"></a>Randomized Response</h2><p>随机响应（Randomized Response）是一种用于本地差分隐私的机制，最初由S. L. Warner于1965年提出。当时，这项技术旨在改进有关敏感问题的调查回答的偏见，最初并未提出作为差分隐私的机制（差分隐私在之后的40年才被发明）。之后，随着差分隐私的发展，统计学家们意识到这一现有技术已经满足了差分隐私的定义。</p>
<p>Dwork和Roth提出了随机响应的一个变种，其中数据主体回答一个“是”或“否”的问题，方法如下：</p>
<ol>
<li>抛一枚硬币。</li>
<li>如果硬币正面朝上，诚实回答问题。</li>
<li>如果硬币是反面朝上，再抛一枚硬币。</li>
<li>如果第二枚硬币正面朝上，回答“是”；如果是反面朝上，回答“否”。</li>
</ol>
<p>这种技术的核心思想是引入一定的不确定性，以便在不透露真实答案的情况下提供一定的信息。它在差分隐私的背景下被重新思考，并被认为是一种满足差分隐私定义的机制，用于保护数据主体的隐私。这种方法允许数据主体提供信息，同时保护其真实的、敏感的回答。</p>
<p>这个算法中的随机性来自两次硬币抛掷。与所有其他差分隐私算法一样，这种随机性引入了对真实答案的不确定性，这是隐私的来源。</p>
<p>事实证明，这个随机响应算法满足 <em>ϵ</em>-差分隐私，其中 <em>ϵ</em>&#x3D;log(3)&#x3D;1.09。   三种情况   取对数？</p>
<p>让我们为一个简单的“是”或“否”的问题实现这个算法： “你的职业是‘销售’吗？” 在Python中，我们可以使用 <code>np.random.randint(0, 2)</code> 来抛掷硬币；结果要么是0，要么是1。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rand_resp_sales</span>(<span class="params">response</span>):</span><br><span class="line">    truthful_response = response == <span class="string">&#x27;Sales&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># first coin flip</span></span><br><span class="line">    <span class="keyword">if</span> np.random.randint(<span class="number">0</span>, <span class="number">2</span>) == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># answer truthfully</span></span><br><span class="line">        <span class="keyword">return</span> truthful_response</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># answer randomly (second coin flip)</span></span><br><span class="line">        <span class="keyword">return</span> np.random.randint(<span class="number">0</span>, <span class="number">2</span>) == <span class="number">0</span></span><br></pre></td></tr></table></figure></div>

<hr>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn-whitegrid&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="comment"># Some useful utilities</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">laplace_mech</span>(<span class="params">v, sensitivity, epsilon</span>):</span><br><span class="line">    <span class="keyword">return</span> v + np.random.laplace(loc=<span class="number">0</span>, scale=sensitivity / epsilon)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_mech</span>(<span class="params">v, sensitivity, epsilon, delta</span>):</span><br><span class="line">    <span class="keyword">return</span> v + np.random.normal(loc=<span class="number">0</span>, scale=sensitivity * np.sqrt(<span class="number">2</span>*np.log(<span class="number">1.25</span>/delta)) / epsilon)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_mech_vec</span>(<span class="params">v, sensitivity, epsilon, delta</span>):</span><br><span class="line">    <span class="keyword">return</span> v + np.random.normal(loc=<span class="number">0</span>, scale=sensitivity * np.sqrt(<span class="number">2</span>*np.log(<span class="number">1.25</span>/delta)) / epsilon, size=<span class="built_in">len</span>(v))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pct_error</span>(<span class="params">orig, priv</span>):</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">abs</span>(orig - priv)/orig * <span class="number">100.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">z_clip</span>(<span class="params">xs, b</span>):</span><br><span class="line">    <span class="keyword">return</span> [<span class="built_in">min</span>(x, b) <span class="keyword">for</span> x <span class="keyword">in</span> xs]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">g_clip</span>(<span class="params">v</span>):</span><br><span class="line">    n = np.linalg.norm(v, <span class="built_in">ord</span>=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">if</span> n &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> v / n</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> v</span><br><span class="line">    </span><br><span class="line">X = np.load(<span class="string">&#x27;./adult_processed_x.npy&#x27;</span>)</span><br><span class="line">y = np.load(<span class="string">&#x27;./adult_processed_y.npy&#x27;</span>)</span><br><span class="line">training_size = <span class="built_in">int</span>(X.shape[<span class="number">0</span>] * <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">X_train = X[:training_size]</span><br><span class="line">X_test = X[training_size:]</span><br><span class="line"></span><br><span class="line">y_train = y[:training_size]</span><br><span class="line">y_test = y[training_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># The loss function measures how good our model is. The training goal is to minimize the loss.</span></span><br><span class="line"><span class="comment"># This is the logistic loss function.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">theta, xi, yi</span>):</span><br><span class="line">    exponent = - yi * (xi.dot(theta))</span><br><span class="line">    <span class="keyword">return</span> np.log(<span class="number">1</span> + np.exp(exponent))</span><br><span class="line"></span><br><span class="line">theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line">loss(theta, X_train[<span class="number">0</span>], y_train[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">theta, xi, yi</span>):</span><br><span class="line">    exponent = yi * (xi.dot(theta))</span><br><span class="line">    <span class="keyword">return</span> - (yi*xi) / (<span class="number">1</span>+np.exp(exponent))</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#A Single Step of Gradient Descent</span></span><br><span class="line">theta = theta - gradient(theta, X_train[<span class="number">0</span>], y_train[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">theta</span>):</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(predict(X_test, theta) == y_test)/X_test.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">accuracy(theta)</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#A Gradient Descent Algorithm</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">avg_grad</span>(<span class="params">theta, X, y</span>):</span><br><span class="line">    grads = [gradient(theta, xi, yi) <span class="keyword">for</span> xi, yi <span class="keyword">in</span> <span class="built_in">zip</span>(X, y)]</span><br><span class="line">    <span class="keyword">return</span> np.mean(grads, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">avg_grad(theta, X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">iterations</span>):</span><br><span class="line">    <span class="comment"># Start by &quot;guessing&quot; what the model should be (all zeros)</span></span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform `iterations` steps of gradient descent using training data</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        theta = theta - avg_grad(theta, X_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line">theta = gradient_descent(<span class="number">10</span>)</span><br><span class="line">accuracy(theta)</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#Gradient Descent with Differential Privacy</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;def noisy_gradient_descent(iterations, epsilon, delta):</span></span><br><span class="line"><span class="string">    theta = np.zeros(X_train.shape[1])</span></span><br><span class="line"><span class="string">    sensitivity = &#x27;???&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    for i in range(iterations):</span></span><br><span class="line"><span class="string">        grad = avg_grad(theta, X_train, y_train)</span></span><br><span class="line"><span class="string">        noisy_grad = gaussian_mech_vec(grad, sensitivity, epsilon, delta)</span></span><br><span class="line"><span class="string">        theta = theta - noisy_grad</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return theta&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##########Gradient Clipping</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">L2_clip</span>(<span class="params">v, b</span>):</span><br><span class="line">    norm = np.linalg.norm(v, <span class="built_in">ord</span>=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> norm &gt; b:</span><br><span class="line">        <span class="keyword">return</span> b * (v / norm)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_sum</span>(<span class="params">theta, X, y, b</span>):</span><br><span class="line">    gradients = [L2_clip(gradient(theta, x_i, y_i), b) <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> <span class="built_in">zip</span>(X,y)]</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># sum query</span></span><br><span class="line">    <span class="comment"># L2 sensitivity is b (by clipping performed above)</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(gradients, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">noisy_gradient_descent</span>(<span class="params">iterations, epsilon, delta</span>):</span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line">    sensitivity = <span class="number">5.0</span></span><br><span class="line">    </span><br><span class="line">    noisy_count = laplace_mech(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, epsilon)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        grad_sum        = gradient_sum(theta, X_train, y_train, sensitivity)</span><br><span class="line">        noisy_grad_sum  = gaussian_mech_vec(grad_sum, sensitivity, epsilon, delta)</span><br><span class="line">        noisy_avg_grad  = noisy_grad_sum / noisy_count</span><br><span class="line">        theta           = theta - noisy_avg_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#Sensitivity of the Gradient</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_sum</span>(<span class="params">theta, X, y, b</span>):</span><br><span class="line">    gradients = [gradient(theta, x_i, y_i) <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> <span class="built_in">zip</span>(X,y)]</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># sum query</span></span><br><span class="line">    <span class="comment"># L2 sensitivity is b (by sensitivity of the gradient)</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(gradients, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">noisy_gradient_descent</span>(<span class="params">iterations, epsilon, delta</span>):</span><br><span class="line">    theta = np.zeros(X_train.shape[<span class="number">1</span>])</span><br><span class="line">    sensitivity = <span class="number">5.0</span></span><br><span class="line">    </span><br><span class="line">    noisy_count = laplace_mech(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, epsilon)</span><br><span class="line">    clipped_X = [L2_clip(x_i, sensitivity) <span class="keyword">for</span> x_i <span class="keyword">in</span> X_train]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        grad_sum        = gradient_sum(theta, clipped_X, y_train, sensitivity)</span><br><span class="line">        noisy_grad_sum  = gaussian_mech_vec(grad_sum, sensitivity, epsilon, delta)</span><br><span class="line">        noisy_avg_grad  = noisy_grad_sum / noisy_count</span><br><span class="line">        theta           = theta - noisy_avg_grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure></div>



]]></content>
  </entry>
  <entry>
    <title>pandas数据分析数据预处理</title>
    <url>/2023/12/15/pandas%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>Pandas的数据结构为，DataFrame，一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔型值）。DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共同用一个索引）。而Series则 类似表格中的一个列（column），类似于一维数组，可以保存任何数据类型。我们把一个.csv文件读取进来就是一个DataFrame对象。DataFrame 构造方法如下</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">pandas.DataFrame( data, index, columns, dtype, copy)</span><br></pre></td></tr></table></figure></div>

<p>data：一组数据(ndarray、series, map, lists, dict 等类型)。<br>index：索引值，或者可以称为行标签。<br>columns：列标签，默认为 RangeIndex (0, 1, 2, …, n) 。<br>dtype：数据类型。<br>copy：拷贝数据，默认为 False。</p>
<h2 id="合并拆分"><a href="#合并拆分" class="headerlink" title="合并拆分"></a>合并拆分</h2><h3 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h3><p>例如，在<code>./MELD</code>路径下存在如下三个文件</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">dev_sent_emo.csv</span><br><span class="line">test_sent_emo.csv</span><br><span class="line">train_sent_emo.csv</span><br></pre></td></tr></table></figure></div>

<p>代码如下</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_csv_files</span>(<span class="params">re_encode_path, save_name, files, save_in</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;combine_csv_files</span></span><br><span class="line"><span class="string">    将指定路径下的所有csv文件合并为一个csv文件</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    使用示例：</span></span><br><span class="line"><span class="string">    file_names = os.listdir(&quot;./MELD/&quot;)</span></span><br><span class="line"><span class="string">    combine_csv_files(re_encode_path=&quot;./MELD/&quot;, </span></span><br><span class="line"><span class="string">                      save_name=&quot;MELD_total_text&quot;, </span></span><br><span class="line"><span class="string">                      files=file_names, </span></span><br><span class="line"><span class="string">                      save_in=&quot;./MELD/&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isfile(join(save_in, <span class="string">&quot;%s.csv&quot;</span>) % save_name): </span><br><span class="line">        <span class="comment"># 如果已经存在合并后的文件，则直接return 0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            main_list = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(files)):</span><br><span class="line">                content = pd.read_csv(join(re_encode_path, files[i]), encoding=<span class="string">&quot;UTF-8-SIG&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                    main_list.extend([<span class="built_in">list</span>(content.keys())])</span><br><span class="line">                main_list.extend(content.values.tolist())</span><br><span class="line"></span><br><span class="line">            main_dict = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(*main_list)):</span><br><span class="line">                main_dict[i[<span class="number">0</span>]] = <span class="built_in">list</span>(i[<span class="number">1</span>:])</span><br><span class="line">            data_df = pd.DataFrame(main_dict)</span><br><span class="line">            data_df.to_csv(join(save_in, <span class="string">&quot;%s.csv&quot;</span>) % save_name, encoding=<span class="string">&quot;UTF-8-SIG&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;合并[%s]时发生错误&quot;</span> % save_name)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h3 id="拆分"><a href="#拆分" class="headerlink" title="拆分"></a>拆分</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shuffle_total_data</span>(<span class="params">data_path=<span class="string">&quot;./MELD/MELD_total_text.csv&quot;</span>, </span></span><br><span class="line"><span class="params">                       save_path=<span class="string">&quot;./MELD/&quot;</span>, </span></span><br><span class="line"><span class="params">                       index_name=<span class="string">&quot;Dialogue_ID&quot;</span>,</span></span><br><span class="line"><span class="params">                       validation_split_percentage=<span class="number">0.1</span>, </span></span><br><span class="line"><span class="params">                       test_split_percentage=<span class="number">0.1</span>, </span></span><br><span class="line"><span class="params">                       regen=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;shuffle_total_data</span></span><br><span class="line"><span class="string">    将一个.csv文件(例如：CPED_total_text.csv)随机打乱，拆分为训练集、验证集、测试集，分别保存</span></span><br><span class="line"><span class="string">    使用示例：</span></span><br><span class="line"><span class="string">    shuffle_total_data(data_path=&quot;./MELD/MELD_total_text.csv&quot;, </span></span><br><span class="line"><span class="string">                       save_path=&quot;./MELD&quot;, </span></span><br><span class="line"><span class="string">                       index_name=&quot;Dialogue_ID&quot;,</span></span><br><span class="line"><span class="string">                       validation_split_percentage=0.1, </span></span><br><span class="line"><span class="string">                       test_split_percentage=0.1, </span></span><br><span class="line"><span class="string">                       regen=False)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> regen==<span class="literal">False</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;不进行重复生成！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Read dataset from &quot;</span>, data_path)</span><br><span class="line">        data = pd.read_csv(data_path, encoding=<span class="string">&quot;UTF-8-SIG&quot;</span>)</span><br><span class="line">                        </span><br><span class="line">        <span class="comment"># 划分为训练集、测试集</span></span><br><span class="line">        keys = <span class="built_in">list</span>(<span class="built_in">set</span>(data[index_name]))</span><br><span class="line">        random.shuffle(keys) <span class="comment"># 随机打乱</span></span><br><span class="line">        validation_split_id = <span class="built_in">int</span>(<span class="built_in">len</span>(keys)*(<span class="number">1</span>-validation_split_percentage-test_split_percentage))</span><br><span class="line">        test_split_id = <span class="built_in">int</span>(<span class="built_in">len</span>(keys)*(<span class="number">1</span>-test_split_percentage))</span><br><span class="line">        train_keys = keys[:validation_split_id] <span class="comment"># 训练集索引</span></span><br><span class="line">        valid_keys = keys[validation_split_id:test_split_id] <span class="comment"># 验证集索引</span></span><br><span class="line">        test_keys = keys[test_split_id:] <span class="comment"># 测试集索引</span></span><br><span class="line">        train_data = data[data[index_name].isin(train_keys)]</span><br><span class="line">        valid_data = data[data[index_name].isin(valid_keys)]</span><br><span class="line">        test_data = data[data[index_name].isin(test_keys)]</span><br><span class="line">        </span><br><span class="line">        train_data.to_csv(join(save_path,<span class="string">&quot;train_shuffle_split.csv&quot;</span>), encoding=<span class="string">&quot;UTF-8-SIG&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line">        valid_data.to_csv(join(save_path,<span class="string">&quot;valid_shuffle_split.csv&quot;</span>), encoding=<span class="string">&quot;UTF-8-SIG&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line">        test_data.to_csv(join(save_path,<span class="string">&quot;test_shuffle_split.csv&quot;</span>), encoding=<span class="string">&quot;UTF-8-SIG&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已经完成数据集生成！&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

]]></content>
  </entry>
  <entry>
    <title>“基础模型pytorch学习笔记”</title>
    <url>/2023/12/25/%E2%80%9C%E6%9D%8E%E6%B2%90%E8%8A%B1%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%9D/</url>
    <content><![CDATA[<h1 id="Resnet"><a href="#Resnet" class="headerlink" title="Resnet"></a>Resnet</h1><p><strong>问题：随着神经网络的不断加深，一定会带来好处吗？</strong></p>
<p>蓝色五角星表示最优值<br>标有Fi的闭合区域表示函数，闭合区域的面积代表函数的复杂程度，在这个区域中能够找到一个最优的模型（可以用区域中的一个点来表示，该点到最优值的距离可以用来衡量模型的好坏）<br>从上图中可以看出，随着函数的复杂度的不断增加，虽然函数的区域面积增大了，但是在该区域中所能找到的最优模型（该区域内的某一点）离最优值的距离可能会越来越远（也就是模型所在的区域随着函数复杂度的增加，逐渐偏离了原来的区域，离最优值越来越远）（非嵌套函数（non-nested function））<br>解决上述问题（模型走偏）的方法：每一次增加函数复杂度之后函数所覆盖的区域会包含原来函数所在的区域（嵌套函数（nested function）），只有当较复杂的函数类包含复杂度较小的函数类时，才能确保提高它的性能，如下图所示 </p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://i0.hdslb.com/bfs/note/c2e5b2e4475660b29a5166856b0c224e2ce52faf.png@1014w_!web-note.avif"
                      alt="残差块"
                ></p>
<p>之前增加模型深度的方法都是层层堆叠的方法，ResNet的思想是在堆叠层数的同时不会增加模型的复杂度<br>上图中左侧表示一个正常块，右侧表示一个残差块<br>x：原始输入<br>f(x)：理想映射（也是激活函数的输入）<br>对于正常块中来说，虚线框中的部分需要直接拟合出理想映射 f(x)；而对于残差块来说，同样的虚线框中的部分需要拟合出残差映射 f(x) - x<br>残差映射在现实中往往更容易优化<br>如果以恒等映射 f(x) &#x3D; x 作为所想要学出的理想映射 f(x)，则只需要将残差块中虚线框内加权运算的权重和偏置参数设置为 0，f(x) 就变成恒等映射了<br>在实际中，当理想映射 f(x) 极接近于恒等映射时，残差映射易于捕捉恒等映射的细微波动<br>在残差块中，输入可以通过跨层数据线路更快地向前传播  </p>
<p>残差块使得很深的网络更加容易训练（不管网络有多深，因为有跨层数据通路连接的存在，使得始终能够包含小的网络，因为跳转连接的存在，所以会先将下层的小型网络训练好再去训练更深层次的网络），甚至可以训练一千层的网络（只要内存足够，优化算法就能够实现）<br>学习嵌套函数是神经网络的理想情况，在深层神经网络中，学习另一层作为恒等映射比较容易<br>残差映射可以更容易地学习同一函数，例如将权重层中的参数近似为零<br>利用残差块可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播<br>残差网络对随后的深层神经网络的设计产生了深远影响，无论是卷积类网络还是全连接类网络，几乎现在所有的网络都会用到，因为只有这样才能够让网络搭建的更深</p>
<hr>
<p>残差块:</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, num_channels,</span></span><br><span class="line"><span class="params">                 use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides)</span><br><span class="line">        self.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        Y += X</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y)</span><br></pre></td></tr></table></figure></div>

<p>通俗的说就是如果加了conv3的效果好，loss小了  就用，不然就不用</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://zh-v2.d2l.ai/_images/resnet-block.svg"
                      alt="包含以及不包含 1×1 卷积层的残差块"
                ></p>
]]></content>
  </entry>
  <entry>
    <title>python调用大模型测试自己的文件输入</title>
    <url>/2023/12/20/python%E8%B0%83%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5/</url>
    <content><![CDATA[<h1 id="通义千问"><a href="#通义千问" class="headerlink" title="通义千问"></a>通义千问</h1><p><a class="link"   href="https://dashscope.console.aliyun.com/model" >模型服务灵积 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>获取api_key即可</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># For prerequisites running the following sample, visit https://help.aliyun.com/document_detail/611472.html</span></span><br><span class="line"><span class="keyword">from</span> http <span class="keyword">import</span> HTTPStatus</span><br><span class="line"><span class="keyword">import</span> dashscope</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> http <span class="keyword">import</span> HTTPStatus</span><br><span class="line"><span class="keyword">from</span> dashscope <span class="keyword">import</span> Generation</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> load_csv <span class="keyword">import</span> load_csv_with_pandas, extract_column_data_with_pandas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;模型用的是qwen_plus</span></span><br><span class="line"><span class="string">        qwen_v1 = &#x27;qwen-v1&#x27;</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;@deprecated, use qwen_plus instead&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        qwen_plus_v1 = &#x27;qwen-plus-v1&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        bailian_v1 = &#x27;bailian-v1&#x27;</span></span><br><span class="line"><span class="string">        dolly_12b_v2 = &#x27;dolly-12b-v2&#x27;</span></span><br><span class="line"><span class="string">        qwen_turbo = &#x27;qwen-turbo&#x27;</span></span><br><span class="line"><span class="string">        qwen_plus = &#x27;qwen-plus&#x27;</span></span><br><span class="line"><span class="string">        qwen_max = &#x27;qwen-max</span></span><br><span class="line"><span class="string">   </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_with_stream</span>(<span class="params">prompt</span>):</span><br><span class="line">    dashscope.api_key = <span class="string">&#x27;sk-e8bca551027e8&#x27;</span></span><br><span class="line"></span><br><span class="line">    responses = Generation.call(</span><br><span class="line">        dashscope.Generation.Models.qwen_plus,</span><br><span class="line">        messages=[&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;],</span><br><span class="line">        stream=<span class="literal">False</span>,</span><br><span class="line">        result_format=<span class="string">&#x27;message&#x27;</span>,</span><br><span class="line">        temperature=<span class="number">0</span></span><br><span class="line">        <span class="comment">#incremental_output=True  # get streaming output incrementally</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(responses)</span><br><span class="line">    content_value = responses[<span class="string">&#x27;output&#x27;</span>][<span class="string">&#x27;choices&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;message&#x27;</span>][<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> content_value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    sys.setrecursionlimit(<span class="number">10</span> ** <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    iteration = <span class="number">50</span>  <span class="comment"># How many questions do you want GPT to answer in CSV file.</span></span><br><span class="line">    file_path = <span class="string">&#x27;merge_all_res.csv&#x27;</span></span><br><span class="line">    column_name = <span class="string">&#x27;带prompt问题&#x27;</span></span><br><span class="line">    <span class="comment"># column_name = &#x27;原始问题&#x27;</span></span><br><span class="line">    response_name = <span class="string">&#x27;回答&#x27;</span></span><br><span class="line">    data = pd.read_csv(file_path)</span><br><span class="line">    data_copy = data.copy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;iteration starts&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, iteration):</span><br><span class="line">        question = data_copy[column_name][i]</span><br><span class="line">        result = call_with_stream(question)</span><br><span class="line">        data_copy[response_name][i] = result</span><br><span class="line">        data_copy.to_csv(file_path, index=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h1 id="文心一言"><a href="#文心一言" class="headerlink" title="文心一言"></a>文心一言</h1><p><a class="link"   href="https://console.bce.baidu.com/qianfan/modelcenter/model/buildIn/detail/9681" >千帆大模型平台 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application" >创建应用 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>获取API Key，Secret Key</p>
<p>然后access_token，</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_access_token</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用 API Key，Secret Key 获取access_token，替换下列示例中的应用API Key、应用Secret Key</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">    url = <span class="string">&quot;https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&amp;client_id=[应用API Key]&amp;client_secret=[应用Secret Key]&quot;</span></span><br><span class="line">    </span><br><span class="line">    payload = json.dumps(<span class="string">&quot;&quot;</span>)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    response = requests.request(<span class="string">&quot;POST&quot;</span>, url, headers=headers, data=payload)</span><br><span class="line">    <span class="keyword">return</span> response.json().get(<span class="string">&quot;access_token&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<p>然后替换下面的，下面的url选择模型</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># For prerequisites running the following sample, visit https://help.aliyun.com/document_detail/611472.html</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> load_csv <span class="keyword">import</span> load_csv_with_pandas, extract_column_data_with_pandas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_with_stream</span>(<span class="params">prompt</span>):</span><br><span class="line">    url = <span class="string">&quot;https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie_bot_8k?access_token=&quot;</span> + <span class="string">&quot;24.fd5c2c1ac5f.2592000.1705542561.282335-45212215&quot;</span></span><br><span class="line"></span><br><span class="line">    payload = json.dumps(&#123;</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">                <span class="string">&quot;content&quot;</span>: prompt</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    response = requests.request(<span class="string">&quot;POST&quot;</span>, url, headers=headers, data=payload)</span><br><span class="line">    a = response.text</span><br><span class="line">    response_dict = json.loads(a)</span><br><span class="line">    result_value = response_dict[<span class="string">&#x27;result&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(result_value)</span><br><span class="line">    <span class="keyword">return</span> result_value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    sys.setrecursionlimit(<span class="number">10</span> ** <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    iteration = <span class="number">50</span>  <span class="comment"># How many questions do you want GPT to answer in CSV file.</span></span><br><span class="line">    file_path = <span class="string">&#x27;merge_all_res.csv&#x27;</span></span><br><span class="line">    column_name = <span class="string">&#x27;带prompt问题&#x27;</span></span><br><span class="line">    <span class="comment"># column_name = &#x27;原始问题&#x27;</span></span><br><span class="line">    response_name = <span class="string">&#x27;回答&#x27;</span></span><br><span class="line">    data = pd.read_csv(file_path)</span><br><span class="line">    data_copy = data.copy()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;iteration starts&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, iteration):</span><br><span class="line">        question = data_copy[column_name][i]</span><br><span class="line">        result = call_with_stream(question)</span><br><span class="line">        data_copy[response_name][i] = result</span><br><span class="line">        data_copy.to_csv(file_path, index=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;finished&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h1 id="星火认知大模型"><a href="#星火认知大模型" class="headerlink" title="星火认知大模型"></a>星火认知大模型</h1><p><a class="link"   href="https://xinghuo.xfyun.cn/sparkapi" >免费的目前 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>然后从<a class="link"   href="https://console.xfyun.cn/services/bm3" >这里 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>获取</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">以下密钥信息从控制台获取</span><br><span class="line">appid = <span class="string">&quot;9f24a&quot;</span>     <span class="comment">#填写控制台中获取的 APPID 信息</span></span><br><span class="line">api_secret = <span class="string">&quot;ZDU1OTTg1ZDE0YjBjNjQ1&quot;</span>   <span class="comment">#填写控制台中获取的 APISecret 信息</span></span><br><span class="line">api_key =<span class="string">&quot;4b11dfd3d6a405ef69c89&quot;</span>    <span class="comment">#填写控制台中获取的 APIKey 信息</span></span><br></pre></td></tr></table></figure></div>

<p><a class="link"   href="https://xfyun-doc.cn-bj.ufileos.com/static%2F16974374635522820%2FSparkApi_Python.zip" >Python调用例子 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>如果报错  </p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">pip uninstall websocket</span><br><span class="line">pip install websocket-client</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<h1 id="智谱AI大模型MaaS开放平台"><a href="#智谱AI大模型MaaS开放平台" class="headerlink" title="智谱AI大模型MaaS开放平台"></a>智谱AI大模型MaaS开放平台</h1><p><a class="link"   href="https://open.bigmodel.cn/usercenter/apikeys" >API <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://open.bigmodel.cn/dev/api#auth" >写的非常详细 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>ChatGLM-Turbo</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> zhipuai</span><br><span class="line"></span><br><span class="line">zhipuai.api_key = <span class="string">&quot;your api key&quot;</span></span><br><span class="line">response = zhipuai.model_api.sse_invoke(</span><br><span class="line">    model=<span class="string">&quot;chatglm_turbo&quot;</span>,</span><br><span class="line">    prompt=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你好&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;我是人工智能助手&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你叫什么名字&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;我叫chatGLM&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>:<span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你都可以做些什么事&quot;</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    temperature=<span class="number">0.95</span>,</span><br><span class="line">    top_p=<span class="number">0.7</span>,</span><br><span class="line">    incremental=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> response.events():</span><br><span class="line">  <span class="keyword">if</span> event.event == <span class="string">&quot;add&quot;</span>:</span><br><span class="line">      <span class="built_in">print</span>(event.data)</span><br><span class="line">  <span class="keyword">elif</span> event.event == <span class="string">&quot;error&quot;</span> <span class="keyword">or</span> event.event == <span class="string">&quot;interrupted&quot;</span>:</span><br><span class="line">      <span class="built_in">print</span>(event.data)</span><br><span class="line">  <span class="keyword">elif</span> event.event == <span class="string">&quot;finish&quot;</span>:</span><br><span class="line">      <span class="built_in">print</span>(event.data)</span><br><span class="line">      <span class="built_in">print</span>(event.meta)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      <span class="built_in">print</span>(event.data)</span><br></pre></td></tr></table></figure></div>

<hr>
<h1 id="盘古AI"><a href="#盘古AI" class="headerlink" title="盘古AI"></a>盘古AI</h1><p>研究研究先。。。</p>
]]></content>
  </entry>
  <entry>
    <title>虚拟电厂与联邦学习(一)</title>
    <url>/2023/11/20/%E8%99%9A%E6%8B%9F%E7%94%B5%E5%8E%82%E4%B8%8E%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="虚拟电厂"><a href="#虚拟电厂" class="headerlink" title="虚拟电厂"></a>虚拟电厂</h1><p><strong>虚拟电厂</strong>（<strong>Virtual power plant</strong>）是以电网云为基础的<a class="link"   href="https://zh.wikipedia.org/wiki/%E5%88%86%E6%95%A3%E5%BC%8F%E7%99%BC%E9%9B%BB" >分散式电厂 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，可以聚集各种不同类型技术的<a class="link"   href="https://zh.wikipedia.org/wiki/%E9%9B%BB%E5%8A%9B" >电力 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。主要目的是增强电力调度能力、以及促进<a class="link"   href="https://zh.wikipedia.org/wiki/%E9%9B%BB%E5%8A%9B%E8%87%AA%E7%94%B1%E5%8C%96" >电力自由市场 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>交易的活络。目前虚拟电厂在<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%BE%8E%E5%9C%8B" >美国 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>、<a class="link"   href="https://zh.wikipedia.org/wiki/%E6%AD%90%E6%B4%B2" >欧洲 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>和<a class="link"   href="https://zh.wikipedia.org/wiki/%E6%BE%B3%E5%A4%A7%E5%88%A9%E4%BA%9E" >澳大利亚 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>均有相关案例。</p>
<p>虚拟电厂具有多样性、协同性、灵活性等技术特点，能够有效聚合多层级的分布式资源，满足新型电力系统绿色低碳、灵活高效、多元互动，高度市场化地运行需求，为实现“双碳”目标提供重要的技术支撑。国家层面政策大力支持，地方层面山西等地重要政策推动行业实现突破。以《“十四五”现代能源体系规划》为代表的多个政策鼓励虚拟电厂发展，北京、山西等地也已经发布具体政策支持虚拟电厂发展。从政策中可以看出，政策不仅鼓励虚拟电厂发展，而且有望推动虚拟电厂在电力交易等方面发挥更大作用。2022年6月，山西能源局印发《虚拟电厂建设与运营管理实施方案》，其中提到“负荷类”虚拟电厂参与中长期、现货及辅助服务市场，“一体化”虚拟电厂参与现货及辅助服务市场。同时，东北能源监管局会同省有关单位组织起草了《辽宁省电力市场运营基本规则及六项配套规则(征求意见稿》，提出将现阶段逐步将储能企业、虚拟电厂、负荷聚合商等纳入电力交易市场主体范围。</p>
<p><strong>虚拟电厂就是通过数字化手段将各类分散可调电源和负荷汇聚起来，等效于一个进行统一管理和调度的特殊电厂，同时作为主体参与电力市场。</strong></p>
<p><strong>虚拟电厂</strong>（Virtual Power Plant，VPP）是将<strong>分布式发电机组、可控负荷和分布式储能</strong>设施有机结合，通过配套的<strong>调控技术、通信技术</strong>实现对各类分布式能源进行<strong>整合调控的载体</strong>，是可以作为一个<strong>特殊电厂</strong>参与电力市场和电网运行的协调管理系统。它既可以作为<strong>“正电厂”</strong>向 系统供电调峰，又可作为<strong>“负电厂”</strong>加大负荷消纳配合系统填谷</p>
<h2 id="发电-编辑"><a href="#发电-编辑" class="headerlink" title="发电[编辑]"></a>发电[<a class="link"   href="https://zh.wikipedia.org/w/index.php?title=%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0&action=edit&section=1" >编辑 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>]</h2><p>虚拟电厂是一种汇集多种类型的电源，以提高电网可靠度的系统[<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0#cite_note-tudelft-1" >1] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。电力来源通常由不同类型、可调度和不可调度、可控制或灵活负载的分散式发电系统所组成的集合。这些系统由中央机构控制，并且可以包括微型<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%83%AD%E7%94%B5%E8%81%94%E4%BA%A7" >热电联产 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，天然气往复式发动机，小型<a class="link"   href="https://zh.wikipedia.org/wiki/%E9%A2%A8%E5%8A%9B%E7%99%BC%E9%9B%BB%E5%BB%A0" >风力发电厂 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，<a class="link"   href="https://zh.wikipedia.org/wiki/%E5%A4%AA%E9%99%BD%E8%83%BD%E7%99%BC%E9%9B%BB" >太阳能发电 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，河道水力发电厂，<a class="link"   href="https://zh.wikipedia.org/wiki/%E5%B0%8F%E5%9E%8B%E6%B0%B4%E5%8A%9B%E7%99%BC%E9%9B%BB" >小型水力发电 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%94%9F%E7%89%A9%E8%B3%AA%E8%83%BD" >生物质能 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，备用发电机和<a class="link"   href="https://zh.wikipedia.org/wiki/%E5%82%A8%E8%83%BD%E6%8A%80%E6%9C%AF" >储能系统 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>等。</p>
<p>虚拟电厂的优势包括能够在短时间内提供<a class="link"   href="https://zh.wikipedia.org/wiki/%E5%B0%96%E5%B3%B0%E8%B2%A0%E8%BC%89%E7%99%BC%E9%9B%BB%E5%BB%A0" >尖峰负载电力 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>或跟随负载的发电。相对于传统的发电厂，虚拟电厂可提供更高的效率和更大的灵活性。更大的灵活性可使系统对波动做出更好的反应，但是其要求较佳的系统优化、控制和安全的通信[<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0#cite_note-ieeexplore-2" >2] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>根据Pike Research 2012年的报告，虚拟电厂容量从2011年到2017年增长65%，从全球的55.6GW增至91.7GW，2017年全球收入将从53亿美元增至65亿美元[<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0#cite_note-businesswire-3" >3] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>另外，虚拟电厂代表着“能源互聯網”。这些系统利用现有的<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%94%B5%E7%BD%91" >电网 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>来为客户量身定制电力供需服务。 虚拟电厂使用一套复杂的基于<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E4%BB%B6" >软件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>的系统，为最终用户和分配实用程序最大化价值。它们是动态的，可以实时提供价值，并且可以对不断变化的客户负载状况做出快速反应。</p>
<p>从广义上来讲，虚拟电厂是需求侧响应的延伸。需求侧响应主要是削峰，主要针对用户负荷；虚拟电厂则是削峰和填谷兼顾，部分具有储能特征，源、网、荷、储都包括在内。与需求响应的调节方式相比，虚拟电厂由于接入了更多元化的用户，如储能、分布式发电、可控负荷等，在用户参与调节时，不仅负荷侧的用户可以调节自身用电增减，还可以召集储能测、电源侧的用户调节电能输出，具有丰富的调节方式和手段。</p>
<p>虚拟电厂由可控机组、不可控机组（如风、光等分布式能源）、储能、可控负荷、电动汽车、通信设备等聚合而成，并进一步考虑需求响应、不确定性等要素，通过与控制中心、云中心、电力交易中心等进行信息通信，实现与大电网的能量互换。</p>
<p>从本质讲，虚拟电厂就是虚拟化的发电厂，它并不具备实体发电厂的物理属性，而是一种管理模式或者是一套系统，通过配套的技术把分散在不同空间的小型太阳能、风能等新能源发电装置、储能电池和各类可控制、可调节的用电设备、负荷整合集成、协调控制，对外等效形成一个可控电源，辅助电力系统运行，并可参与电力市场交易，同时优化资源利用，维护区域内，甚至跨区域的用电稳定与用电安全。它既可以有计划地接受电力系统的电力，又可以向电力系统反向输出电力，更灵活高效地进行“削峰填谷”等作业，并获得客观的经济效益。</p>
<h2 id="辅助服务-编辑"><a href="#辅助服务-编辑" class="headerlink" title="辅助服务[编辑]"></a>辅助服务[<a class="link"   href="https://zh.wikipedia.org/w/index.php?title=%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0&action=edit&section=2" >编辑 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>]</h2><p>虚拟电厂还可用于为电网运营商提供辅助服务，以帮助维护<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%94%B5%E7%BD%91" >电网 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>稳定性。辅助服务包括频率调节、负载追踪和提供操作储备。这些服务主要用于维持电力供需的瞬时平衡。提供辅助服务的电厂必须回应电网运营商传来的信号，以响应用户需求水平的变化，在几秒钟到几分钟的时间内增加或减少负荷。</p>
<p>由于辅助服务通常由可控制的化石燃料发电机提供，因此，未来包含<a class="link"   href="https://zh.wikipedia.org/wiki/%E5%A4%AA%E9%99%BD%E8%83%BD" >太阳能 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>和<a class="link"   href="https://zh.wikipedia.org/wiki/%E9%A2%A8%E8%83%BD" >风能 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>比例很高的无碳电网必须依靠其他形式的可控制发电或消耗，<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%BB%8A%E8%BC%9B" >车辆 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>到<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E6%A0%BC%E8%A8%88%E7%AE%97" >网格技术 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>就是其中最著名的例子。在这种情况下，连接到电网的分散式电动车辆可充当单个虚拟电厂。通过有选择地控制每辆车的充电速度，电网可以看到净注入或能量消耗，就好像大型电池正在提供这项服务一样。</p>
<p>同样，目前已有厂商研究以<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%86%B1%E6%B3%B5" >热泵 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>或<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%A9%BA%E8%AA%BF" >空调 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>来提供电网提供辅助服务[<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0#cite_note-Sustainable_Buildings_and_Cities-4" >4] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。只要保持室内的舒适性，就可以选择性地关闭和打开分散式热泵，以改变其总功率消耗。</p>
<p>由于虚拟发电厂可以并行运行，因此与发电厂相比，虚拟发电厂可以具有更高的<a class="link"   href="https://zh.wikipedia.org/wiki/%E9%B4%A8%E5%AD%90%E6%9B%B2%E7%B7%9A" >鸭子曲线 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>（Duck Curve），这在早晨和傍晚有较高<a class="link"   href="https://zh.wikipedia.org/wiki/%E9%B4%A8%E5%AD%90%E6%9B%B2%E7%B7%9A" >鸭子曲线 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>的电网中尤为重要。但是，分散式性质会产生通信和延迟问题，这可能需要诸如频率调节之类的快速服务。</p>
<h2 id="能源交易-编辑"><a href="#能源交易-编辑" class="headerlink" title="能源交易[编辑]"></a>能源交易[<a class="link"   href="https://zh.wikipedia.org/w/index.php?title=%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0&action=edit&section=3" >编辑 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>]</h2><p>虚拟发电厂为基于电网云的中央或分散式控制中心，它利用<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%B3%87%E8%A8%8A%E5%8F%8A%E9%80%9A%E8%A8%8A%E7%A7%91%E6%8A%80" >资讯及通讯科技 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>（ICT）和<a class="link"   href="https://zh.wikipedia.org/wiki/%E7%89%A9%E8%81%94%E7%BD%91" >物联网 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>（IoT）设备来整合异构分散式能源，目的是在趸售电力市场上进行能源交易，或为系统运营商提供辅助服务[<a class="link"   href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E9%9B%BB%E5%BB%A0#cite_note-VPP_FSD_2017-5" >5] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p><strong>相较于传统能源发电，新能源发电具有随机性、波动性等特点，大规模的新能源并网，电力系统是否也将面临较大挑战？挑战主要体现在哪些方面？</strong></p>
<p><strong>大规模性能源并网是否也将面临较大挑战？</strong></p>
<p>是的</p>
<p><strong>挑战主要体现在哪些方面？</strong></p>
<p>1)风电、太阳能等发电形式将对电网出力端形成较大的冲击，影响到电力系统的稳定性维护。</p>
<p>2)峰谷差问题催生的储能、分布式电源的大规模装机也增加了出力资源的数量，调度复杂度大幅提升。</p>
<p>但是虚拟电厂能够有效聚合分布式电源和储能电站等资源，依靠物联网等技术，处理风电、光伏等出力端带来的不确定性，帮助电网实现协调优化控制，加强新型电力系统内部各单元间的协同，从而提升电力系统的灵活性与稳定性。</p>
<p>三大业务板块：</p>
<p><strong>“注源控流”业务板块</strong></p>
<p>使分布式发电有组织、有规律地接入系统和服务平 台，进行统一协调运维管理，形成一定规模合力， 相对可调可控，最终实现并网运行。与此同时，控 制调节负荷侧的电力流向及流量。尽可能多地接入 可调节用电负荷，使其有序、有规律地按计划用电， 并提升综合能效管理，在最大限度地不影响生产生 活用电的情况下，综合考虑外部电网供电情况、内部自发电情况、各类用电成本、电网需求侧智能管 控等因素，科学合理并按最优经济性安排用电计划。</p>
<p><strong>“电力储备”业务板块</strong></p>
<p>多元化储能是实现“注源控流”的关键支撑。对分散的分布式小型新能源发电进行聚合，实现聚合多元化资源更 有力量、更易调控、更具操作空间。同时，聚合资源统一服从上级调令在聚合资源圈内配套需要的储能系统。对于“控流业务”同样需要配置配套的储能系统才能更灵活、便捷地制定最佳用电方案。</p>
<p><strong>“商业”业务板块</strong></p>
<p>在聚合多类资源后，最终要参与到电力市场中来才能 获得收益。商业模式主要有2种：1.电力交易，虚拟电厂作为售电企业与用户直接交易，或从火电厂购买发电权;2.辅助服务市场，虚拟电厂通过负荷低谷时减少出力或增加负荷、在负荷高峰时增加出力或削减负荷来参与调峰服务交易，以及类似参与调频等服务市场。</p>
<p>在实际的运行中，虚拟电厂会从描述个分布式能源的参数组合中创建一个操作配置文件，这个文件也正是虚拟电厂的信息核心。换句话说，虚拟电厂参与了</p>
<ol>
<li><p>电力交易（例如在批发市场中签订合同）</p>
</li>
<li><p>分布式能源组合信息（用于向系统运营商提供管理与辅助服务）</p>
</li>
</ol>
<p>这两种不同用途的配置文件也正是CVPP和TVPP运行的核心信息。</p>
<p>在CVPP的实际运行中，每个分布式能源主体都需要上报其运行参数、边际成本等信息，一般可由CVPP安装在这些分布式能源处的终端装置完成信息采集，这些分布式能源的输入信息，市场分析、地方数据等其他输入信息一起汇集到单一的虚拟电厂中创建配置文件，每个配置文件都代表了一个分布式能源实时组合的运行描述。 随着CVPP有越来越多这样的配置文件，它会获得越来越多的市场信息，那么下一步他就可以完成在远期合同市场、期货市场、电能量市场及辅助服务市场的投资组合方案，并实时评估相关交易能力。</p>
<p><strong>1.发电设备：</strong>屋顶光伏、燃料电池、发电机、热电联产系统、 可再生能源发电设备等。</p>
<p>**2.储能设备:**家用蓄电池、车载蓄电池、电子热水器、固定式蓄电池、热泵、蓄热空调、电子热水机等。</p>
<p>**3.节电设备:**空调、照明、通风设备、风扇、压缩机、冷却器等。</p>
<hr>
<p>这些功能有两个重要功能。首先，这些设备产生的数据量比以往任何时候都大得多。收集、处理、分析和使用这些数据来做出决策和确定行动需要带宽、足够的处理能力和速度。其次，设备是异构的。例如，对于在很短的距离内有效通信的物联网设备，蓝牙可能是可能的或有利的。但是对于跨越数公里进行通信的设备，必须使用蜂窝通信。有些设备可以通过互联网安全有效地连接和协调，而有些设备则不能，尤其是在涉及直接访问关键基础设施的情况下。，在虚拟电厂最雄心勃勃的情况下，虚拟电厂将涉及通过机器学习算法进行电网优化。随着 DER 和 VPP 集成到电力系统中，云和边缘的使用将成为安全性、弹性和处理速度的决定性特征之一。显然，系统将两者兼而有之;运营电力系统需要处理和操作大量分散的数据，随着分散式 DER 和 VPP 的数量增加到数十万，每个 DER 和 VPP 都与家庭物联网以及相互通信，哪些信息应该在本地处理，哪些可以发送到云端将成为新的考试问题。</p>
<hr>
<p><strong>虚拟电厂 + 需求响应：</strong>聚合分布式可控资源参与需求侧响应服务，获得经济收益。</p>
<p><strong>虚拟电厂 + 辅助服务：</strong>聚合分布式可控资源参与调峰等电力辅助服务交易，获得经济收益。</p>
<p><strong>虚拟电厂 + 风光电站运营服务：</strong>为风光电站提供运营服务，通过收取软件服务费及合同能源管理方式。</p>
<p><strong>虚拟电厂 + 储能资源运营服务：</strong>为风光电站提供运营服务，通过收取软件服务费及合同能源管理方式。</p>
<p><strong>虚拟电厂 + 增值服务：</strong>通过提供绿电、绿证、双碳等相关产品咨询及购买服务，获取经济收益。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic3.zhimg.com/v2-f7871f13da08720388cb39d7249a5aa6_r.jpg"
                      alt="img"
                ></p>
<p>虚拟电厂的三个角色：虚拟电厂产品提供方，负责开发、建设、运营和管理各类虚拟资源，并且抽象成虚拟电厂产品组合；虚拟电厂产品购买方，主要是电网调度部门和营销部门，未来也可以包括地方政府、配电公司、售电公司、<a class="link"   href="https://www.zhihu.com/search?q=%E7%94%B5%E5%8A%9B%E7%94%A8%E6%88%B7&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3153493652%7D" >电力用户 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，甚至其他市场主体；虚拟电厂产品的<a class="link"   href="https://www.zhihu.com/search?q=%E4%BA%A4%E6%98%93%E5%B9%B3%E5%8F%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3153493652%7D" >交易平台 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，这和交易模式有关，如果是双边交易，则可以不经过集中式交易平台，由购买方-提供方协商完成交易。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://picx.zhimg.com/v2-7f3dc918818a8f1d6832045ea6c90c2b_r.jpg?source=1940ef5c"
                      alt="img" style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://pic3.zhimg.com/v2-10194a780386f46a2235c81b750de9c2_r.jpg"
                      alt="img" style="zoom:50%;" 
                >

<hr>
<p>什么是虚拟电厂</p>
<p>可再生能源接入电力系统比例的大幅提升带来了新的问题，由于风电和光伏等新能源在出力特性上具有随机性、间歇性、周期性、波动性的特点，高比例新能源接入电力系统，使得发电侧的电能产出无法控制。同时，由于新能源汽车等高功率负荷的高速增长，也使得用电侧负荷变得难以预估。电源侧和负荷侧双重不确定造成难以实现电能生产量和需求量的严格匹配，对电力系统的稳定性构成严重威胁。</p>
<p><strong>构建新型电力系统是实现“双碳”目标的重要手段，以新能源为主体是新型电力系统的主要特征，对高比例可再生能源的消纳和调控是新型电力系统的核心能力。</strong></p>
<p>随着分布式新能源并网容量的迅速提升，各类分布式储能系统也被大量配置于分布式新能源发电侧、配电网侧、用户侧和微电网，用于提升新能源消纳比例、保障供电稳定性、提升电能质量、峰谷套利等。与此同时，近年来在国家一系列政策助力下，我国新能源汽车数量也大幅增长。<strong>这些数量庞大的分布式新能源、分布式储能系统、电动汽车共同构成了新型电力系统下的分布式资源。</strong></p>
<p>然而，<strong>现阶段大量的分布式资源由于单体规模较小，无法独立满足电网的调度需求，发挥最大效益。</strong></p>
<h5 id="首先，可缓解分布式发电的负面效应，提高电网运行稳定性。"><a href="#首先，可缓解分布式发电的负面效应，提高电网运行稳定性。" class="headerlink" title="首先，可缓解分布式发电的负面效应，提高电网运行稳定性。"></a>首先，可缓解分布式发电的负面效应，提高电网运行稳定性。</h5><p>虚拟电厂作为一种可视化的自组织模式，不仅能够通过组合多种分布式资源实现发电，同时也能够通过调节可控负荷、采用分时电价、可中断电价以及用户时段储能等措施，来实现节能储备。这种协调控制优化大大降低了分布式资源并网对电网所造成的冲击，从而降低了分布式资源增长所带来的调度难度，使得配电管理更加合理有序，进而提高了系统运行的稳定性。</p>
<h5 id="其次，可高效利用和促进分布式能源发电。"><a href="#其次，可高效利用和促进分布式能源发电。" class="headerlink" title="其次，可高效利用和促进分布式能源发电。"></a>其次，可高效利用和促进分布式能源发电。</h5><p>随着我国分布式光伏和分散式风电等分布式能源增长迅速，其大规模、高比例接入给电力系统的平衡和电网安全运行带来了一系列挑战。如果这些分布式发电以虚拟电厂的形式参与电网的运行，通过内部的组合优化，可以消除其波动对电网的影响，从而实现高效利用。此外，虚拟电厂还能使分布式能源从电力市场中获取最大的经济效益，缩短成本回收周期，从而吸引和扩大此类投资，进而促进分布式能源的发展。</p>
<h5 id="最后，可以以市场手段促进发电资源的优化配置。"><a href="#最后，可以以市场手段促进发电资源的优化配置。" class="headerlink" title="最后，可以以市场手段促进发电资源的优化配置。"></a>最后，可以以市场手段促进发电资源的优化配置。</h5><p>虚拟电厂表现为传统的可调度发电厂。由于拥有多样化的发电资源，虚拟电厂不仅可以参与主能量市场，也可以参与辅助服务市场，从而参与多种电力市场的运营模式及其调度框架，对发电资源的广泛优化配置起到了积极的促进作用。</p>
]]></content>
  </entry>
  <entry>
    <title>联邦学习在电力数据场景下的隐私保护研究</title>
    <url>/2023/12/04/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%94%B5%E5%8A%9B%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<p>基于联邦学习的个人车主用户数据加密和应用</p>
<p><strong>请您充分知晓，根据法律法规，当存在以下合法事由时，我们收集、使用您的个人信息无需征得您的授权同意：</strong></p>
<p><strong>1)</strong>  <strong>为订立、履行您作为一方当事人的合同所必需；</strong></p>
<p><strong>2)</strong>  <strong>为履行法定职责或者法定义务所必需，例如与国家安全、国防安全、公共安全以及与司法侦查、起诉、审判和判决执行等直接相关的法定职责或者法定义务；</strong></p>
<p><strong>3)</strong>  <strong>为应对突发公共卫生事件，或者紧急情况下为保护自然人的生命健康和财产安全所必需；</strong></p>
<p><strong>4)</strong>  <strong>为公共利益实施新闻报道、舆论监督等行为，在合理的范围内处理个人信息；</strong></p>
<p><strong>5)</strong>  <strong>依照《中华人民共和国个人信息保护法》规定在合理的范围内处理个人自行公开或者其他已经合法公开的个人信息；</strong></p>
<p><strong>6)</strong>  <strong>法律、行政法规规定的其他情形。</strong></p>
<h3 id="二、我们如何对外提供、转让、公开披露您的个人信息"><a href="#二、我们如何对外提供、转让、公开披露您的个人信息" class="headerlink" title="二、我们如何对外提供、转让、公开披露您的个人信息"></a>二、我们如何对外提供、转让、公开披露您的个人信息</h3><h3 id="（一）对外提供"><a href="#（一）对外提供" class="headerlink" title="（一）对外提供"></a>（一）对外提供</h3><p>我们会以高度的勤勉义务对待您的个人信息。除非征得您的授权同意，或遵照有关法律法规的其他合法基础外，我们不会向蔚来汽车以外的任何公司、组织和个人提供您的个人信息。</p>
<p>我们提供的部分产品&#x2F;服务需要第三方的参与才能完成，因此我们可能会向我们的关联公司以及第三方服务商或合作伙伴提供您的部分个人信息，以保障和优化我们为您提供的产品&#x2F;服务。我们将遵照法律法规的规定，对个人信息的对外提供进行严格的限制和管理。对于委托处理您个人信息的场景，我们会与受托方根据法律规定签署相关处理协议，要求其根据我们的要求、本隐私政策处理您的个人信息，并对其个人信息处理活动进行监督。对于对外共享您个人信息场景，我们会基于本隐私政策以下列明的情形基于合法、正当、必要原则对外共享您的个人信息。<strong>具体而言，我们对外提供您的个人信息的接受方包括提供车辆购买&#x2F;交付支持服务的第三方、提供车主服务的第三方、提供金融服务的第三方、提供技术服务及研发的供应商、商城物流配送服务的第三方，详情请查看此处</strong>**<a class="link"   href="https://www.nio.cn/policies/description-of-nios-data-entrusted-processing-and-sharing" >《蔚来汽车数据委托处理和共享情况说明》 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>**<strong>。</strong></p>
<p><strong>1)</strong>   <strong>事先获得您明确的同意或授权</strong>。</p>
<p><strong>2)</strong>   **实现产品&#x2F;**<strong>服务功能</strong>。为实现产品能力或向您提供服务，我们会将您的个人信息提供给以下第三方。</p>
<p>  <strong>（1）</strong>  <strong>我们的关联公司：</strong>我们会在遵循统一管理、控制、或拥有重大权益的关联公司之间共享您的信息，且受本隐私政策中所声明目的的约束。如果我们的关联公司改变个人信息处理目的，将再次征求您的授权同意。</p>
<p>  <strong>（2）</strong>  <strong>蔚来汽车的第三方服务提供商或合作伙伴</strong>：如实现蔚来 App、蔚来车辆功能的第三方。对我们与之共享个人信息的第三方，限于实现合作目的所需的范围，我们将与其签署相应的个人信息保护协议或者条款，要求其根据双方之间达成的协议、本隐私政策处理和保护您的个人信息，且我们会通过协议要求其不得将此信息用于其他任何目的，并要求其采取足够的安全保障措施来处理我们共享的信息。</p>
<p><strong>3)</strong>   <strong>根据适用法律法规、行政或司法要求而提供。</strong>例如：① 根据法律法规、法律程序、或有权行政和司法机关的要求提供您的信息；② 根据法律法规要求，我们将进行必要的车辆数据监控，并将其接入新能源汽车数据政府采集&#x2F;监测平台以及蔚来汽车及其关联公司的数据采集&#x2F;监测平台。</p>
<p><strong>4)</strong>   <strong>应您需求为您处理您与他人的纠纷或争议。</strong> </p>
<p><strong>5)</strong>   <strong>权利保护。</strong>在法律法规要求或允许的范围内，为维护我们、我们的关联方或合作伙伴、您或其他用户、社会公众的利益、财产或安全免遭损害而确有必要提供的。</p>
<p><strong>6)</strong>   <strong>研究新项目和新服务。</strong>为了为您提供更优质的服务，蔚来可能与第三方合作伙伴进行潜在业务合作项目的探索和推进，并可能会将您的部分个人信息经过去标识化、匿名化等适当的处理分享给潜在业务合作伙伴。</p>
<h3 id="（四）公开披露"><a href="#（四）公开披露" class="headerlink" title="（四）公开披露"></a>（四）公开披露</h3><p><strong>我们<strong><strong>将遵守相关法律法规，对</strong></strong>您的个人信息<strong><strong>予以保密</strong></strong>。****我们不会主动公开您未自行公开的个人信息，除非遵循法律法规规定或获得您的单独同意。</strong></p>
<h3 id="（五）共享、转让、公开披露时征得同意的例外"><a href="#（五）共享、转让、公开披露时征得同意的例外" class="headerlink" title="（五）共享、转让、公开披露时征得同意的例外"></a>（五）共享、转让、公开披露时征得同意的例外</h3><p><strong>请您充分知晓，根据法律法规，当存在以下合法事由时，我们共享、转让、公开披露您的个人信息不必事先征得您的授权同意：</strong></p>
<p><strong>1)</strong>  <strong>为订立、履行您作为一方当事人的合同所必需；</strong></p>
<p><strong>2)</strong>  <strong>为履行法定职责或者法定义务所必需，例如与国家安全、国防安全、公共安全以及与司法侦查、起诉、审判和判决执行等直接相关的法定职责或者法定义务；</strong></p>
<p><strong>3)</strong>  <strong>为应对突发公共卫生事件，或者紧急情况下为保护自然人的生命健康和财产安全所必需；</strong></p>
<p><strong>4)</strong>  <strong>为公共利益实施新闻报道、舆论监督等行为，在合理的范围内处理个人信息；</strong></p>
<p><strong>5)</strong>  <strong>依照《中华人民共和国个人信息保护法》规定在合理的范围内处理个人自行公开或者其他已经合法公开的个人信息；</strong></p>
<p><strong>6)</strong>  <strong>法律、行政法规规定的其他情形。</strong></p>
<p><strong>第一，法律规范的位阶高低和应用场景。</strong>如上图所示，汽车行业处理个人信息，受到一般性和行业性个人信息保护法律规范的双重规制。其中，《个人信息保护法》（以下简称<strong>“《个保法》”</strong>）是隐私保护领域的基础性法律6；部门规章《汽车数据安全管理若干规定（试行）》（以下简称<strong>“《若干规定》”</strong>）是目前汽车行业下位阶最高的具有强制性效力的法律规范，对于开展在车联网个人信息保护合规有十分重要的指导意义；规范性文件以下的各类文件和标准，虽然不具备法律意义上的强制性效力，但为企业在实操层面落地高位阶、原则性的法律要求提供了更加场景化和具体化的解读。</p>
<p><strong>第二，要注意追踪领域内的最新立法动态。</strong>例如《网络数据安全管理条例（征求意见稿）》和《数据出境安全评估办法（征求意见稿）》，前者作为《个人信息保护法》之下位阶最高的相关领域法律，在诸多方面对于个人信息处理者的义务做了细化的规定；后者则为数据跨境的细化规定，明确了必须以安全评估作为个人信息跨境法定依据的情形。</p>
<p><strong>第三，要注意个人信息保护细分领域的法律规范文件。</strong>例如上表中列出的《必要个人信息范围规定》，因为主机厂通常会在车辆中集成大量第三方应用，第三方应用通常作为受委托方参与到车联网系统下个人信息的处理当中，同时其处理行为也受到上述规范性文件的约束。</p>
<p><strong>第四，还可以关注地方出台的法规和指导性文件。</strong>例如深圳市《深圳经济特区数据条例》、上海市的《企业数据合规指引》等。</p>
<p><strong>三、车联网场景下的个人信息 &#x2F;&#x2F;&#x2F;</strong></p>
<p>本文所讨论的车联网场景下的个人信息，是指配备电子控制单元的车辆在与车内和车外的其它设备进行数据交互的过程中，涉及的以电子或者其他方式记录的与已识别或者可识别的车主、驾驶人、乘车人、车外人员等有关的各种信息7。具体来说，根据车辆自身配置功能的不同，网联汽车可能会收集到的个人信息包括但不限于以下类型8：</p>
<p><strong>1.用户的身份信息。</strong>主要是在注册和登录车联网系统账号时，如车机屏、车辆配套的APP时，需要收集车主的身份信息，包括姓名、身份证件号、电话、邮箱等，有生物识别登录功能的还会进一步收集车主的人脸、指纹等信息。</p>
<p><strong>2.用户的使用行为信息。</strong>车辆智能系统需要收集用户的驾驶习惯信息，如座椅角度、后视镜位置等进行个性化配置的调节，车载娱乐系统也通常配备收集和存储用户偏好设置的功能；使用自动辅助驾驶功能除了收集外部环境数据，通常还需要通过摄像头收集驾驶员疲劳或分神状态——以上都属于用户的使用行为信息。此外，这些功能也通常通过收集指纹、声音等生物识别信息的方式来验证用户身份。</p>
<p><strong>3.车辆的地理位置信息。</strong>用户使用地图导航、紧急道路救援、寻找加油站&#x2F;充电桩等功能需要收集车辆位置信息。《若干规定》也明确了车辆的行踪轨迹属于敏感个人信息。</p>
<p><strong>4.车辆的使用状态和技术信息。</strong>如车架号、软硬件版本、里程、电池、油量、车内温度等，用于用户在车辆配套的APP端查看车辆状况、车企监测车辆健康状况、进行故障分析、远程维护等多种目的。大部分上述车辆信息由于和个人信息主体之间存在一定的关联，根据《个保法》和《若干规定》对于个人信息的定义，也属于个人信息的范畴。</p>
<p><strong>.做好车联网下个人信息的分类分级。</strong>对个人信息进行分级分类是《个人信息保护法》的要求，也是企业履行个人信息处理安全保障义务的基本思路。进行分级分类既要考虑到强制性法律规范的明确要求，例如个人信息保护法将个人信息分为一般和敏感个人信息，又要考虑分级对业务模式是否足够友好便利。企业可参考《个人信息安全规范》及《用户个人信息保护要求》的分类分级方法。</p>
<p>2.应当按个人信息的实现功能或处理目的之不同，<strong>明确不同类型个人信息的存储期限。</strong>例如，为导航目的收集的车辆位置和轨迹信息，在导航结束后即删除；车联网用户账号相关的个人身份信息可以在注销或停用后，在诉讼时效期限内保留；为进行车辆远程维护的相关数据，可以在车辆的整个生命周期保留。</p>
<p><strong>3.部署安全的传输、存储和访问措施。</strong>例如，通过最先进的算法对通信信道进行加密；保护加密密钥不被泄露；将车辆至关重要的功能与始终依赖联网能力的功能（例如信息娱乐功能）进行分割；使用可靠的用户认证技术（密码、电子证书等）访问个人信息；存储任何访问车辆信息系统的日志记录，例如最长可追溯到六个月，以便了解任何潜在攻击的来源，并定期对日志记录进行审查，以检测可能存在的异常情况11。</p>
<p><strong>（三）与第三方共享个人信息</strong> </p>
<p><strong>要确定企业自身和第三方的主体身份关系。</strong>对于企业委托第三方进行个人信息处理的，例如使用第三方互联网应用提供娱乐服务、天气查询功能，应当按个保法的要求与第三方<strong>签订数据处理协议，</strong>并在协议中明确处理的目的、期限、处理方式、个人信息的种类、保护措施以及双方的权利和义务等等；对于将个人信息提供给其它个人信息处理者的，例如提供给基于驾驶里程数和&#x2F;或驾驶习惯而区分驾驶员保险费用高低（Usage-based insurance）的保险公司，应当按个保法的要求明确告知用户并且征得其单独同意。</p>
<p><a class="link"   href="https://www.sunshinelawfirm.com/newsinfo.aspx?id=2360" >非常好 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://events.xiaopeng.com/gd8nk0.html" >https://events.xiaopeng.com/gd8nk0.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://auto.china.com.cn/jt/20230524/723151.shtml" >https://auto.china.com.cn/jt/20230524/723151.shtml <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="http://ft.newdu.com/m/Print.asp?ArticleID=108862" >http://ft.newdu.com/m/Print.asp?ArticleID=108862 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://www.chinanews.com.cn/sh/2023/05-11/10005116.shtml" >https://www.chinanews.com.cn/sh/2023/05-11/10005116.shtml <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>[车联网场景]: </p>
<p><a class="link"   href="https://www.yenlex.com/news/content_295.html" >车联网 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/621053556" >很好 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://www.kwm.com/cn/zh/insights/latest-thinking/are-you-ready-for-a-data-processing-agreement-in-the-flow-of-personal-information.html" >你准备好了吗 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://www.kwm.com/cn/zh/insights/latest-thinking/data-compliance-concerning-auto-charging-piles.html" >宠儿无忧 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>在中国稳步推进碳达峰碳中和的背景下，我国电动汽车的保有量持续增长。作为关联产业，汽车充电桩行业也在不断发展。根据相关数据显示，截至2022年12月，我国充电基础设施累计数量约500余万台，同比增加99.1%，车桩比约为2.5:1[1]。根据国家发改委等部门的实施意见，到2025年末，我国要能够满足超过2000万辆电动汽车的充电需求[2]。由此可见，未来汽车充电桩行业或将继续迎来扩张期。</p>
<p>充电桩运营商由于直接面向用户提供充电服务，往往涉及直接处理大量个人信息及其他类型数据。随着充电桩数量大量增加，充电桩用户数量大幅上升，充电桩运营商的数据合规压力也随之加重。本文将聚焦充电桩运营商在经营活动中处理的主要数据类型，结合典型业务场景，探讨充电桩运营商的数据合规义务。</p>
<h2 id="充电桩运营商处理的主要数据类型"><a href="#充电桩运营商处理的主要数据类型" class="headerlink" title="充电桩运营商处理的主要数据类型"></a><strong>充电桩运营商处理的主要数据类型</strong></h2><h3 id="（一）汽车数据"><a href="#（一）汽车数据" class="headerlink" title="（一）汽车数据"></a>（<strong>一）汽车数据</strong></h3><p>根据《汽车数据安全管理若干规定（试行）》（“《汽车数据规定》”），汽车数据包括汽车设计、生产、销售、使用、运维等过程中涉及的个人信息和重要数据。汽车数据处理者，是指开展汽车数据处理活动的组织，包括汽车制造商、零部件和软件供应商、经销商、维修机构以及出行服务企业等。</p>
<p>充电桩运营商提供充电等服务时，往往涉及采集车辆识别码（Vehicle Identification Number，“<strong>VIN码</strong>”）、车主联系方式等个人信息以及汽车与电池状态信息等车况信息，其中大规模的充电桩运营商还可能涉及处理车辆流量、汽车充电网运行数据等，该等信息和数据均落入汽车数据的范畴。</p>
<p>由此可见，充电桩运营商处理的数据与汽车数据密切相关。汽车数据主要由个人信息以及包含重要数据在内的非个人信息组成。</p>
<h3 id="（二）个人信息"><a href="#（二）个人信息" class="headerlink" title="（二）个人信息"></a><strong>（二）个人信息</strong></h3><p>我们注意到，充电桩运营商通常以APP作为集成各项业务的平台，因此大部分个人信息一般直接通过APP采集。</p>
<p>作为APP运营者，为完成用户注册、支付、咨询、投诉等常规功能，充电桩运营商和其他领域的APP运营者一样，需要收集用户的基本信息、身份信息、设备信息等。例如，为注册账号，需要收集用户手机号、账号密码等；为保障APP稳定运行，需要收集设备信息、平台日志等；为支付与退款，需要收集交易记录、金融账户信息等；以及为提供客服服务，需要收集聊天记录、通话录音等。</p>
<p>除了以上常见的个人信息类型，为提供充电服务，充电桩运营商还需收集以下与充电服务直接相关的个人信息：</p>
<h4 id="1-汽车充电"><a href="#1-汽车充电" class="headerlink" title="1. 汽车充电"></a><strong>1. 汽车充电</strong></h4><p>为提供充电服务，充电桩运营商需要收集车辆识别信息、车辆与电池参数，以判断车辆及电池型号，输出适配的电流，并保障充电安全。</p>
<p>除此之外，为了实现扩展功能，如推荐附近的充电桩、导航至目的地充电桩，在用户授权同意的情况下，充电桩运营商通常还会收集用户的位置信息，以便为用户就近提供充电服务。</p>
<p>其中车辆识别信息主要包括车牌号和VIN码。</p>
<p>对于车牌号，其作为车辆对外展示的识别信息，有助于快速识别车辆，因此常用于车辆快速通过充电场站的道闸、停车时长统计等功能。</p>
<p>对于VIN码，正如身份证号码是公民身份的识别代码，每辆车也有其唯一的VIN码作为其“身份证号码”。由于每辆车的VIN码不存在重复，因此成为充电桩运营商识别车辆身份的理想方式。实践中，用户可通过APP上传车辆行驶证，由APP自动提取其中的VIN码信息；或者，用户也可授权充电桩在插枪后自动识别车辆的VIN码。</p>
<p>充电桩运营商采集VIN码的重要用途之一，是为用户提供“即插即充”服务。根据《电动汽车非车载传导式充电机与电池管理系统之间的通信协议》（GB&#x2F;T 27930-2015），即插即充是指用户插枪后，即可自动启动充电。这其中的重要环节之一即是车辆与充电桩之间“握手”识别，确定车辆的身份[5]。依据2015年发布的《电动汽车非车载传导式充电机与电池管理系统之间的通信协议》（GB&#x2F;T 27930-2015），VIN码作为“可选项”被列入了车辆识别报文（BRM）[6]。根据《电动汽车无线充电系统 第7部分：互操作性要求及测试 车辆端》（GB&#x2F;T 38775.7-2021），在车辆配对预检实现流程中提及的配对请求信息，包括了车载设备的ID或VIN码或其他可代表车载设备身份的信息[7]。依据现行的标准要求，虽然VIN码并非唯一的配对信息，但已作为推荐的配对信息类型，构成“握手”配对技术要求的一部分。实践中，VIN码目前是汽车充电行业中广泛使用的“握手”识别符。</p>
<h4 id="2-营运车认证"><a href="#2-营运车认证" class="headerlink" title="2. 营运车认证"></a><strong>2. 营运车认证</strong></h4><p>网约车是电动汽车的主要使用场景之一，网约车司机也因此成为共享充电桩的主要客户群体。部分充电桩运营商推出了面向网约车等营运车辆的充电优惠政策，因此需要收集驾驶员身份证、营运车驾驶员证、驾驶员人脸信息及网约车运输证等个人信息以核实营运车司机身份并核实司机与营运车辆的对应关系。</p>
<h4 id="3-充电站安全监控"><a href="#3-充电站安全监控" class="headerlink" title="3. 充电站安全监控"></a><strong>3. 充电站安全监控</strong></h4><p>相当数量的充电桩场站为运营商自营场地。为维护公共安全，充电桩运营商可能安装公共监控设备，以记录用户使用充电服务的过程，其中涉及用户的人脸信息以及车辆车牌信息等个人信息。在发生纠纷或安全事故时，公共监控设备能有效地辅助核实事实、处理投诉、以及方便场地管理方维护场站秩序及公共安全。</p>
<h3 id="（三）非个人信息"><a href="#（三）非个人信息" class="headerlink" title="（三）非个人信息"></a><strong>（三）非个人信息</strong></h3><p>除个人信息外，充电桩运营商还涉及处理属于非个人信息的汽车数据，如：（1）车辆流量。车辆流量是指单位时间内通过某一区域的车辆数量。在充电桩运营商自营的充电桩场站中，通过统计一定时间内进入场站充电的汽车数量，充电桩运营商可以获得其运营场站的车辆流量数据；（2）汽车充电网的运行数据。为了保障充电安全，充电桩运营商需要获得其运营的汽车充电网的运行数据，以输出适配电流、检测充电安全状态、防范和预警充电安全隐患等。大型充电桩运营商可能在城市、港口、机场、火车站等各处广泛建设充电网，并掌握其运行数据。</p>
<p>根据《汽车数据规定》，该等车辆流量、汽车充电网的运行数据均可能构成重要数据。充电桩运营商除关注针对汽车数据、个人信息的合规义务外，还需关注针对重要数据的合规义务[8]。需要注意的是，重要数据与个人信息并不是互斥的概念，个人信息如达到一定规模，将通过量变引起质变，从而落入重要数据的范畴。根据《汽车数据规定》，10万人以上的个人信息属于重要数据[9]。</p>
<p>充电桩运营商拥有广泛的用户群体，掌握大量个人信息、重要数据等汽车数据。在充电桩运营商扩张市场、谋求新机遇的同时，也应关注企业的合规经营状况，尽早开始梳理数据资产，以便了解自身掌握的数据类型与规模，并相应制定风险防范措施。</p>
<h3 id="处理个人信息的合规义务"><a href="#处理个人信息的合规义务" class="headerlink" title="处理个人信息的合规义务"></a><strong>处理个人信息的合规义务</strong></h3><p>作为个人信息处理者，充电桩运营商需要进行个人信息全生命周期的管理，在收集、使用、提供、存储、删除等各个环节，建立并落实有效的个人信息保护合规制度。</p>
<p>针对充电桩运营商的行业特性，充电桩运营商需注意以下场景下的个人信息合规义务：</p>
<h4 id="1-第三方合作"><a href="#1-第三方合作" class="headerlink" title="1. 第三方合作"></a><strong>1. 第三方合作</strong></h4><p>除了常见的广告推送、第三方支付、数据分析等第三方合作场景，充电桩运营商有其特别的第三方合作需求：</p>
<p>（1）不同运营商之间的互联互通。汽车充电桩市场正呈现群雄逐鹿之势。对于用户而言，其核心需求是方便快捷地实现充电。如今，市场上已有多家充电桩运营商实现互联互通，在一家充电平台上即可搜索到并使用其他品牌的充电桩。</p>
<p>（2）与整车厂合作。不少整车厂为了向用户提供更好的配套充电服务选择与第三方充电运营商进行合作，以便使用第三方充电运营商的充电桩运营网络。合作过程中，充电桩运营商一般会向整车厂共享充电站点的地理位置、坐标、工作状态、收费标准等数据信息用于在整车厂自有充换电服务平台中展示，使整车厂用户可以实现查询、筛选、导航、充电、支付等服务；而整车厂通常会向充电桩运营商提供车辆VIN码，从而使整车厂用户可以享用即插即充服务。</p>
<p>（3）与第三方合作运营充电网。充电桩运营商具备专业的规划、选址、建设、运营管理等经验，能够利用自身优势与第三方合作建设充电网，并代理合作方或与合作方共同合作运营充电网。运营过程中，根据充电桩运营商与合作方之间的约定，充电桩运营商或是事实上的第一手数据处理者，后续需依约定向合作方提供运营所得数据。</p>
<p>充电桩运营商几乎不可避免与第三方合作，其中涉及数据交互的，一方面应当明确与第三方之间的数据处理关系为委托处理、共享还是共同处理，另一方面应当与第三方相应签署数据处理协议。关于数据处理协议应当具备的主要内容与注意事项，请参考我们的文章<a class="link"   href="https://www.kwm.com/cn/zh/insights/latest-thinking/are-you-ready-for-a-data-processing-agreement-in-the-flow-of-personal-information.html" >《个人信息流动中的数据处理协议，你准备好了吗？》 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<h4 id="2-私桩共享"><a href="#2-私桩共享" class="headerlink" title="2. 私桩共享"></a><strong>2. 私桩共享</strong></h4><p>部分充电桩运营商鼓励个人用户将自己的充电桩展示在充电平台上，供其他用户有偿使用。由于大量私桩位于用户所在的小区，桩主需公布所在小区具体地址才能供他人使用私桩共享功能。此外，为保证顺利充电，桩主还需提供联系电话以供充电需求方随时联系。</p>
<p>私桩共享有助于充分利用私人充电桩在闲暇时间的充电位置，但其中存在大量值得警惕的个人信息安全风险。其一，我们观察到许多充电APP上有社区板块，用户可发布帖子、评价充电体验。用户可能会未经他人允许，将获取到的私桩桩主的联系电话、充电桩位置及其他个人信息公开。其二，不乏桩主与充电需求方绕过平台私下联系，以锁定长期的用桩需求。双方在私下联系中更易获得对方的个人信息，包括照片、朋友圈内容、职业信息、家庭状况等。一旦产生纠纷，可能存在不理智的用户径直将对方的个人信息公之于众。</p>
<h4 id="3-摄像头采集信息"><a href="#3-摄像头采集信息" class="headerlink" title="3. 摄像头采集信息"></a><strong>3. 摄像头采集信息</strong></h4><p>如前所述，充电桩运营商可能安装监控设备以保障公共安全。根据《个人信息保护法》及《信息安全技术 个人信息安全规范》（GB&#x2F;T 35273-2020），基于维护公共安全目的，充电桩运营商安装摄像头处理个人信息无需取得个人信息主体的同意[14]，但仍需履行告知义务。</p>
<p>根据《个人信息处理中告知和同意的实施指南》（GB&#x2F;T 42574-2023），充电桩运营商在公共场所安装摄像头时，可以考虑以如下方式进行告知：在安装摄像头的场所入口处、摄像头摄像范围边界入口处等醒目位置，以显著方式提供个人信息的处理规则，并以扫描二维码等方式提供用户线上点击“同意”的途径。例如，可以在大屏幕上滚动播放个人信息处理规则，或是播放精简版本并公布获取全部信息的途径[15]。值得注意的是，出于公共安全之外目的在公共场所采集个人图像、身份识别信息的，需取得用户的单独同意。以上告知的形式并不能豁免取得用户单独同意的合规要求，充电桩营运商仍需结合实际场景，寻找合适的触点收集用户的单独同意。</p>
<h3 id="（三）处理重要数据合规义务"><a href="#（三）处理重要数据合规义务" class="headerlink" title="（三）处理重要数据合规义务"></a><strong>（三）处理重要数据合规义务</strong></h3><p>前文提到，充电桩运营商可能构成重要数据的处理者。充电桩运营商属于工业领域的数据处理者，又涉及汽车数据的处理活动，因此，其除了《数据安全法》以外，也应关注《工业和信息化领域数据安全管理办法（试行）》（“<strong>《工信领域数据办法》</strong>”）和《汽车数据规定》对重要数据处理者的合规要求。</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>新能源汽车充电桩在相关政策规定中一般被称作“充电设施”或“充电基础设施”（下文统一简称为“充电设施”）。尽管不同地方的规定对于充电设施的具体分类和定义存在差异，但一般而言，根据充电设施面向的服务对象，充电设施一般包括以下几种类型：</p>
<ul>
<li><p>自用充电设施，指专为某个私人用户提供的充电设施；</p>
</li>
<li><p>专用充电设施，指专为某个法人单位及其职工提供充电服务的充电设施，以及在住宅小区内为全体业主提供服务的充电设施；</p>
</li>
<li><p>公用充电设施，指服务于社会电动车辆的充电设施，包括经营性集中式充电设施。</p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/621053556" >数据合规风险 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
</li>
</ul>
<p><a class="link"   href="https://www.51welink.com/contents/10/784.html" >我国充电桩行业政策与建设规划 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
  </entry>
  <entry>
    <title>Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad</title>
    <url>/2024/01/03/Pytorch%E4%BC%98%E5%8C%96%E5%99%A8%E5%85%A8%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89SGD%E3%80%81ASGD%E3%80%81Rprop%E3%80%81Adagrad/</url>
    <content><![CDATA[<h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1><p>**torch.optim.Adam,**该类实现 Adam(Adaptive Moment Estimation))优化方法。Adam 是一种自适应学习率的优化方法，Adam 利用梯度的一阶矩估计和二阶矩估计动态的调整学习率。Adam 是结合了 Momentum 和 RMSprop，并进行了偏差修正。 了解了Adagrad 和RMSProp</p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>RMSProp算法有效解决了这个问题。通过累计各个变量的梯度的平方r，然后用每个变量的梯度除以r，即可有效缓解变量间的梯度差异。如下伪代码是计算过程。</p>
<h2 id="pytorch-RMSProp参数"><a href="#pytorch-RMSProp参数" class="headerlink" title="pytorch RMSProp参数"></a><a class="link"   href="https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020" >pytorch <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> RMSProp参数</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.RMSprop(params,</span><br><span class="line">                    lr=<span class="number">0.01</span>,</span><br><span class="line">                    alpha=<span class="number">0.99</span>, <span class="comment">### 平滑常数</span></span><br><span class="line">                    eps=<span class="number">1e-08</span>,  <span class="comment">### epsilon,加在分母上防止除0</span></span><br><span class="line">                    weight_decay=<span class="number">0</span>, <span class="comment">## weight_decay的作用是用当前可学习参数p的值修改偏导数，即</span></span><br><span class="line">                    momentum=<span class="number">0</span>,</span><br><span class="line">                    centered=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>$$<br>alpha 平滑常数 \<br>epsilon,加在分母上防止除0 \<br>weight_decay的作用是用当前可学习参数p的值修改偏导数，即g_t &#x3D; g_t+(p*weight_decay)<br>$$</p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>我们定义一个通用的思路框架，方便在后面理解各算法之间的关系和改进。首先定义待优化参数 $\theta$，目标函数$J(\theta)$，学习率为$\alpha$ ，然后我们进行迭代优化，假设当前的epoch为(<a class="link"   href="https://latex.csdn.net/eq?t)%EF%BC%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E6%AD%A5%E9%AA%A4%E5%A6%82%E4%B8%8B%EF%BC%9A" >https://latex.csdn.net/eq?t)，参数更新步骤如下： <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<ol>
<li>计算目标函数关于当前参数的梯度：</li>
</ol>
<p>$$<br>\begin{equation}g_t&#x3D; \nabla J(\theta)\end{equation}\tag{1}<br>$$</p>
<ol start="2">
<li><p>根据历史梯度计算一阶动量和二阶动量 $m_t和v_t$</p>
</li>
<li><p>计算当前时刻的下降梯度</p>
</li>
</ol>
<p>$$<br>\eta_t &#x3D; α·m_t&#x2F;\sqrt{V_t} \tag{2}<br>$$</p>
<ol start="4">
<li>根据下降梯度进行更新：</li>
</ol>
<p>$$<br>\theta_{t+1} &#x3D; \theta_t-\eta_t \tag{3}<br>$$</p>
<p>下面介绍的所有优化算法基本都能套用这个流程，只是式子（3）的形式会有变化。</p>
<h1 id="SGD随机梯度下降"><a href="#SGD随机梯度下降" class="headerlink" title="SGD随机梯度下降"></a>SGD随机梯度下降</h1><p>随机梯度下降每一次随机对一个训练样本计算梯度，并更新参数θ<br>$$<br>\theta &#x3D; \theta -\eta ·\nabla_{\theta}J(\theta:minibatch) 		\tag{6}<br>$$<br>优点：</p>
<ul>
<li>由于一次只用一个数据，因此梯度更新很快</li>
<li>也会处于一个高 variance 的状态，更新时 loss 比较震荡，可能会使得其跳出局部最优点到达一个更好的局部最优。</li>
</ul>
<p>缺点：</p>
<ul>
<li>选择合适的学习率仍然是一个玄学</li>
<li>学习率 schedule 需要预设不能自适应数据集的特点</li>
<li>学习率针对所有参数，而并非所有参数需要同样的学习率</li>
<li>对于非凸问题极易陷入局部最优</li>
</ul>
<h2 id="SGD-with-Momentum"><a href="#SGD-with-Momentum" class="headerlink" title="SGD with Momentum"></a>SGD with Momentum</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.SGD(params, lr=&lt;<span class="built_in">object</span> <span class="built_in">object</span>&gt;, momentum=<span class="number">0</span>, dampening=<span class="number">0</span>, weight_decay=<span class="number">0</span>, nesterov=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>动量是一种有助于在相关方向上加速SGD并抑制振荡的方法，<strong>通过将当前梯度与过去梯度加权平均，来获取即将更新的梯度</strong>。如下图b图所示。它通过将过去时间步长的更新向量的一小部分添加到当前更新向量来实现这一点。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img-blog.csdnimg.cn/img_convert/0ebaf5af890536caa3c97730e7bc5871.png"
                     
                ></p>
<p>参数更新公式如下，其中ρ 是动量衰减率，m是速率（即一阶动量）：<br>$$<br>g_t &#x3D; \nabla_{\theta}J(\theta_{t-1})		 \tag{5}<br>$$</p>
<p>$$<br>m_t &#x3D; \rho *m_{t-1}+g_t 			\tag{6}<br>$$</p>
<p>$$<br>\theta_t &#x3D; \theta_{t-1}-\eta*m_t  		\tag{7}<br>$$</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.SGD(params, lr=<span class="number">0.01</span>, momentum=<span class="number">0</span>, dampening=<span class="number">0</span>, weight_decay=<span class="number">0</span>, nesterov=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>使用了Momentum有如下特点：</p>
<p>优点：加快收敛速度，有一定摆脱局部最优的能力，一定程度上缓解了没有动量的时候的问题</p>
<p>缺点：a.仍然继承了一部分SGD的缺点</p>
<p>​	 b.在随机梯度情况下，NAG对收敛率的作用不是很大</p>
<p>​	 c.Momentum都是为了使梯度更新更灵活。但是人工设计的学习率总是有些生硬</p>
<h1 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h1><p>Adagrad 是一种自适应梯度的优化器，它有什么特点呢？它对不同参数使用不同的学习率，对于更新频率较低的参数施以较大的学习率，对于更新频率较高的参数用以较小的学习率。我们先来看一下公式：$$g_{t,i}&#x3D; \nabla_{\theta_{t}} J(\theta_{t,i})$$</p>
<p>$$g_{t,i}$$代表了第 t 步的第 i 个参数 $$\theta_{t,i}$$ 的梯度，梯度更新则使用下列式子：<br>$$<br>J(\theta_{t+1,i})&#x3D;J(\theta_{t,i})-\frac{\eta}{\sqrt{(G_{t,ii}+\epsilon)}}·g_{t,i} 				\tag{8}<br>$$</p>
<p>实际上，Adagrad 在优化稀疏数据的时候表现会比较好，但是其缺点也是显而易见的，由于 Gt,ii��,�� 是一个非负数，随着步数增加很容易越累积越大，从导致学习率过早变小，学习缓慢。</p>
<p>AdaGrad对学习率进行了一个约束，对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。这样大大提高梯度下降的鲁棒性。而该方法中开始使用二阶动量，才意味着“自适应学习率”优化算法时代的到来。<br>        在SGD中，我们每次迭代对所有参数进行更新，因为每个参数使用相同的学习率。而AdaGrad在每个时间步长对每个参数使用不同的学习率。AdaGrad消除了手动调整学习率的需要。AdaGrad在迭代过程中不断调整学习率，并让目标函数中的每个参数都分别拥有自己的学习率。大多数实现使用学习率默认值为0.01，开始设置一个较大的学习率。<br> AdaGrad引入了二阶动量。二阶动量是迄今为止所有梯度值的平方$ V_t&#x3D;\sum_{t}^{i&#x3D;1}g^{2}<em>{i}$它是用来度量历史更新频率的。也就是说，我们的学习率现在是**$\frac{\eta}{\sqrt{(G_{t,ii}+\epsilon)}}$**从这里我们就会发现分母恒大于0，而且参数更新越频繁，二阶动量越大，学习率就越小，这一方法在稀疏数据场景下表现非常好，参数更新公式如下：<br>$$<br>v_t &#x3D; \sum</em>{i&#x3D;1}^{t}g_{t}^{2}			\tag{9}<br>$$</p>
<p>$$<br>\theta_t&#x3D;\theta_{t-1}-\frac{\eta}{\sqrt{v_t+\epsilon}} *g_t			\tag{10}<br>$$</p>
<p><strong>显然$\frac{\eta}{\sqrt{(G_{t,ii}+\epsilon)}}$会趋近于0</strong>，</p>
<p><strong>总结</strong></p>
<p>​        AdaGrad在每个时间步长对每个参数使用不同的学习率。并且引入了二阶动量，二阶动量是迄今为止所有梯度值的平方和。</p>
<p>优点：AdaGrad消除了手动调整学习率的需要。AdaGrad在迭代过程中不断调整学习率，并让目标函数中的每个参数都分别拥有自己的学习率。</p>
<p>缺点：a.仍需要手工设置一个全局学习率  , 如果  设置过大的话，会使regularizer过于敏感，对梯度的调节太大</p>
<p>​    b.<strong>在分母中累积平方梯度，由于每个添加项都是正数，因此在训练过程中累积和不断增长</strong>。这导致学习率不断变小并最终变得无限小，此时算法不再能够获得额外的知识即导致模型不会再次学习。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">params (iterable) – 待优化参数的iterable或者是定义了参数组的dict</span></span><br><span class="line"><span class="string">lr (float, 可选) – 学习率（默认: 1e-2）</span></span><br><span class="line"><span class="string">lr_decay (float, 可选) – 学习率衰减（默认: 0）</span></span><br><span class="line"><span class="string">weight_decay (float, 可选) – 权重衰减（L2惩罚）（默认: 0）</span></span><br><span class="line"><span class="string">initial_accumulator_value - 累加器的起始值，必须为正。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.Adagrad(params, lr=<span class="number">0.01</span>, lr_decay=<span class="number">0</span>, weight_decay=<span class="number">0</span>, initial_accumulator_value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></div>



<h1 id="RMSProp-1"><a href="#RMSProp-1" class="headerlink" title="RMSProp"></a>RMSProp</h1><p>RMSProp算法有效解决了这个问题。通过累计各个变量的梯度的平方r，然后用每个变量的梯度除以r，即可有效缓解变量间的梯度差异。如下伪代码是计算过程。</p>
<p> 该类实现 RMSprop 优化方法（Hinton 提出），RMS 是均方根（root meam square）的意思。RMSprop 和 Adadelta 一样，也是对 Adagrad 的一种改进。RMSprop 采用<strong>均方根作为分母</strong>，可缓解 Adagrad 学习率下降较快的问题，并且引入均方根，可以减少摆动。</p>
<p>RMSprop与Adadelta属于同一时期的作品，都是对Adagrad的优化，解决了Adagrad多次迭代后，学习率将逐渐下降至0的问题。RMSProp算法将AdaGrad的梯度平方和累改加为指数加权的移动平均，使得其在非凸设定下效果更好。设定参数：全局初始率 $l$默认设为0.001，decay rate$\rho$ ，默认设置为0.9，一个极小的常量$\epsilon$  ，通常为10e-6，参数更新公式如下：</p>
<p>$$<br>v_t &#x3D;\rho v_{t-1}+(1-\rho)g_{t}^2			\tag{11}<br>$$</p>
<p>$$<br>\theta_t&#x3D;\theta_{t-1}-\frac{\eta}{\sqrt{v_t}+\epsilon} *g_t			\tag{10}<br>$$</p>
<p> 可以看到式子（15）和Adadelta的（13）的分母是基本一样的（只是的位置有所区别），两者虽然思想不一样，但是实现一样的，都是指数加权的移动平均，也算殊途同归了。</p>
<p><strong>总结</strong></p>
<p> RMSprop算是Adagrad的一种发展，用梯度平方的指数加权平均代替了全部梯度的平方和，相当于只实现了Adadelta的第一个修改，效果趋于RMSprop和Adadelta二者之间。</p>
<p>优点：适合处理非平稳目标(包括季节性和周期性)——对于RNN效果很好</p>
<p>缺点：RMSprop依然依赖于全局学习率 </p>
<p><a class="link"   href="https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020" >pytorch <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> RMSProp参数</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">torch.optim.RMSprop(params,</span><br><span class="line">                    lr=<span class="number">0.01</span>,</span><br><span class="line">                    alpha=<span class="number">0.99</span>, <span class="comment">### 平滑常数</span></span><br><span class="line">                    eps=<span class="number">1e-08</span>,  <span class="comment">### epsilon,加在分母上防止除0</span></span><br><span class="line">                    weight_decay=<span class="number">0</span>, <span class="comment">## weight_decay的作用是用当前可学习参数p的值修改偏导数，即</span></span><br><span class="line">                    momentum=<span class="number">0</span>,</span><br><span class="line">                    centered=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>$alpha 平滑常数$<br>$epsilon,加在分母上防止除0 $</p>
<p>$weight_decay的作用是用当前可学习参数p的值修改偏导数，即g_t &#x3D; g_t+(p*weight_decay)$</p>
<h1 id="Adam-1"><a href="#Adam-1" class="headerlink" title="Adam"></a>Adam</h1><p>**torch.optim.Adam,**该类实现 Adam(Adaptive Moment Estimation))优化方法。Adam 是一种自适应学习率的优化方法，Adam 利用梯度的一阶矩估计和二阶矩估计动态的调整学习率。Adam 是结合了 Momentum 和 RMSprop，并进行了偏差修正。 了解了Adagrad 和RMSProp。</p>
<p>​    <strong>在adam中，一阶矩来控制模型更新的方向，二阶矩控制步长(学习率)。利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。</strong></p>
<p>$$<br>m_t &#x3D; \beta_1*m_{t-1}+(1-\beta_1)*g_t 		\tag{13}<br>$$</p>
<p>$$<br>v_t  &#x3D;\beta_2*v_{t-1}+(1-\beta_2)*g_t^2			\tag{14}<br>$$</p>
<p>$$<br>\hat{m_t}&#x3D;\frac{m_t}{1-\beta_1^t}		\tag{15}<br>$$</p>
<p>$$<br>\hat{v_t}&#x3D;\frac{v_t}{1-\beta_2^t}   \tag{16}<br>$$</p>
<p>$$<br>\theta_t &#x3D; \theta_{t-1}-\eta*\frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}				\tag{17}<br>$$</p>
<p>式子(17)更新模型参数 ，分子表示在过去一段时间内各分量的平均值，即梯度更新的大致走向，分母表示在过去一段时间内各分量的平均大小。相当于分两步走，第一步是确定一个合适的下降方向（即分子项），第二步，对这个选定的方向上的各个子方向做一下微调（分母项），这样，推进较快的子方向会慢下来，推进较慢的子方向会加快速度，动态调整了各个子方向的学习率。因此，Adam结合了Momentum和RMSprop两种算法的优点</p>
<p>主要包含以下几个显著的优点：</p>
<p>\1. 实现简单，计算高效，对内存需求少</p>
<p>\2. 参数的更新不受梯度的伸缩变换影响</p>
<p>\3. 超参数具有很好的解释性，且通常无需调整或仅需很少的微调</p>
<p>\4. 更新的步长能够被限制在大致的范围内（初始学习率）</p>
<p>\5. 能自然地实现步长退火过程（自动调整学习率）</p>
<p>\6. 很适合应用于大规模的数据及参数的场景</p>
<p>\7. 适用于不稳定目标函数</p>
<p>\8. 适用于梯度稀疏或梯度存在很大噪声的问题</p>
<p>β1 系数为指数衰减率，控制权重分配（动量与当前梯度），通常取接近于1的值。</p>
<p>β2 系数为指数衰减率，控制之前的梯度平方的影响情况。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.Adam(params, lr=<span class="number">0.001</span>, betas=(<span class="number">0.9</span>, <span class="number">0.999</span>), eps=<span class="number">1e-08</span>, weight_decay=<span class="number">0</span>)   <span class="comment">#betas(β1,β2)</span></span><br></pre></td></tr></table></figure></div>

]]></content>
  </entry>
  <entry>
    <title>基础模型pytorch学习笔记</title>
    <url>/2023/12/25/%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8Bpytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20/</url>
    <content><![CDATA[<h1 id="Resnet"><a href="#Resnet" class="headerlink" title="Resnet"></a>Resnet</h1><p><strong>问题：随着神经网络的不断加深，一定会带来好处吗？</strong></p>
<p>蓝色五角星表示最优值<br>标有Fi的闭合区域表示函数，闭合区域的面积代表函数的复杂程度，在这个区域中能够找到一个最优的模型（可以用区域中的一个点来表示，该点到最优值的距离可以用来衡量模型的好坏）<br>从上图中可以看出，随着函数的复杂度的不断增加，虽然函数的区域面积增大了，但是在该区域中所能找到的最优模型（该区域内的某一点）离最优值的距离可能会越来越远（也就是模型所在的区域随着函数复杂度的增加，逐渐偏离了原来的区域，离最优值越来越远）（非嵌套函数（non-nested function））<br>解决上述问题（模型走偏）的方法：每一次增加函数复杂度之后函数所覆盖的区域会包含原来函数所在的区域（嵌套函数（nested function）），只有当较复杂的函数类包含复杂度较小的函数类时，才能确保提高它的性能，如下图所示 </p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://i0.hdslb.com/bfs/note/c2e5b2e4475660b29a5166856b0c224e2ce52faf.png@1014w_!web-note.avif"
                      alt="残差块"
                ></p>
<p>之前增加模型深度的方法都是层层堆叠的方法，ResNet的思想是在堆叠层数的同时不会增加模型的复杂度<br>上图中左侧表示一个正常块，右侧表示一个残差块<br>x：原始输入<br>f(x)：理想映射（也是激活函数的输入）<br>对于正常块中来说，虚线框中的部分需要直接拟合出理想映射 f(x)；而对于残差块来说，同样的虚线框中的部分需要拟合出残差映射 f(x) - x<br>残差映射在现实中往往更容易优化<br>如果以恒等映射 f(x) &#x3D; x 作为所想要学出的理想映射 f(x)，则只需要将残差块中虚线框内加权运算的权重和偏置参数设置为 0，f(x) 就变成恒等映射了<br>在实际中，当理想映射 f(x) 极接近于恒等映射时，残差映射易于捕捉恒等映射的细微波动<br>在残差块中，输入可以通过跨层数据线路更快地向前传播  </p>
<p>残差块使得很深的网络更加容易训练（不管网络有多深，因为有跨层数据通路连接的存在，使得始终能够包含小的网络，因为跳转连接的存在，所以会先将下层的小型网络训练好再去训练更深层次的网络），甚至可以训练一千层的网络（只要内存足够，优化算法就能够实现）<br>学习嵌套函数是神经网络的理想情况，在深层神经网络中，学习另一层作为恒等映射比较容易<br>残差映射可以更容易地学习同一函数，例如将权重层中的参数近似为零<br>利用残差块可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播<br>残差网络对随后的深层神经网络的设计产生了深远影响，无论是卷积类网络还是全连接类网络，几乎现在所有的网络都会用到，因为只有这样才能够让网络搭建的更深</p>
<hr>
<h2 id="残差块"><a href="#残差块" class="headerlink" title="残差块:"></a>残差块:</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, num_channels,</span></span><br><span class="line"><span class="params">                 use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides)</span><br><span class="line">        self.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        Y += X</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y)</span><br></pre></td></tr></table></figure></div>

<p>通俗的说就是如果加了conv3的效果好，loss小了  就用，不然就不用</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://zh-v2.d2l.ai/_images/resnet-block.svg"
                      alt="包含以及不包含 1×1 卷积层的残差块"
                ></p>
<h2 id="Resnet模型"><a href="#Resnet模型" class="headerlink" title="Resnet模型"></a>Resnet模型</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></table></figure></div>

]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2024/01/03/Pytorch%E4%BC%98%E5%8C%96%E5%99%A8SGD%E3%80%81SGDM%E3%80%81Rprop%E3%80%81Adagrad%E3%80%81Adma/</url>
    <content><![CDATA[]]></content>
  </entry>
</search>
