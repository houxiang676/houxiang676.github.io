<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="深情小小侯">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2024/01/03/pytorch优化器全总结（一）sgd、asgd、rprop、adagrad/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="Adam**torch.optim.Adam,**该类实现 Adam(Adaptive Moment Estimation))优化方法。Adam 是一种自适应学习率的优化方法，Adam 利用梯度的一阶矩估计和二阶矩估计动态的调整学习率。Adam 是结合了 Momentum 和 RMSprop，并进行了偏差修正。 了解了Adagrad 和RMSProp RMSPropRMSProp算法有效解决了这个">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad">
<meta property="og:url" content="http://example.com/2024/01/03/Pytorch%E4%BC%98%E5%8C%96%E5%99%A8%E5%85%A8%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89SGD%E3%80%81ASGD%E3%80%81Rprop%E3%80%81Adagrad/index.html">
<meta property="og:site_name" content="深情小小侯的博客">
<meta property="og:description" content="Adam**torch.optim.Adam,**该类实现 Adam(Adaptive Moment Estimation))优化方法。Adam 是一种自适应学习率的优化方法，Adam 利用梯度的一阶矩估计和二阶矩估计动态的调整学习率。Adam 是结合了 Momentum 和 RMSprop，并进行了偏差修正。 了解了Adagrad 和RMSProp RMSPropRMSProp算法有效解决了这个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/0ebaf5af890536caa3c97730e7bc5871.png">
<meta property="article:published_time" content="2024-01-03T01:30:29.000Z">
<meta property="article:modified_time" content="2024-06-05T14:30:01.813Z">
<meta property="article:author" content="深情小小侯">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/img_convert/0ebaf5af890536caa3c97730e7bc5871.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/redefine-favicon.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/redefine-favicon.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/redefine-favicon.svg">
    <!--- Page Info-->
    
    <title>
        
            Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad -
        
        深情小小侯的博客
    </title>
    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/assets/build/styles.css">

    

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    window.config = {"hostname":"example.com","root":"/","language":"zh-CN","path":"search.xml"};
    window.theme = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":true,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"走得快走得慢不重要，走下去就是胜利","subtitle":{"text":[],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"links":{"github":null,"instagram":null,"zhihu":null,"twitter":null,"email":null},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.5.0","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"文档":{"path":"/archives","icon":"fa-regular fa-archive"},"相册":{"icon":"fa-solid fa-image","submenus":{"假日出行":"/masonry","小乖":"/gallery"}}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":"纸上得来终觉浅，绝知此事要躬行","links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2022/8/17 11:45:14"};
    window.lang_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
    window.data = {"masonry":true};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="swup-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container" id="swup">

    

    <div class="main-content-container">


        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                深情小小侯的博客
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        首页
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        文档
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-solid fa-image"></i>
                                        
                                        相册&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/masonry">假日出行
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a href="/gallery">小乖
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer w-full absolute top-0 left-0 bg-background-color">
        <ul class="drawer-navbar-list flex flex-col justify-start items-center">
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                首页
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                文档
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-solid fa-image"></i>
                                
                                相册&nbsp;<i class="group-hover:rotate-180 transition-transform fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/masonry">假日出行</a>
                            </li>
                        
                            <li class="drawer-navbar-item text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="/gallery">小乖</a>
                            </li>
                        
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="post-page-container">
    <div class="article-content-container">

        <div class="article-title">
            
                <h1 class="article-title-regular">Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad</h1>
            
            </div>
            
                    
        
        
            <div class="article-header flex flex-row gap-2 items-center">
                <div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]">
                    <img src="/images/redefine-avatar.svg">
                </div>
                <div class="info flex flex-col justify-between">
                    <div class="author flex items-center">
                        <span class="name text-default-text-color text-lg font-semibold">深情小小侯</span>
                        
                            <span class="author-label ml-1.5 text-xs px-2 py-0.5 rounded-small text-third-text-color border border-shadow-color-1">Lv3</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2024-01-03 09:30:29</span>
        <span class="mobile">2024-01-03 09:30:29</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2024-06-05 22:30:01</span>
            <span class="mobile">2024-06-05 22:30:01</span>
            <span class="hover-info">更新</span>
        </span>
    

    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        


        <div class="article-content markdown-body">
            <h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1><p>**torch.optim.Adam,**该类实现 Adam(Adaptive Moment Estimation))优化方法。Adam 是一种自适应学习率的优化方法，Adam 利用梯度的一阶矩估计和二阶矩估计动态的调整学习率。Adam 是结合了 Momentum 和 RMSprop，并进行了偏差修正。 了解了Adagrad 和RMSProp</p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>RMSProp算法有效解决了这个问题。通过累计各个变量的梯度的平方r，然后用每个变量的梯度除以r，即可有效缓解变量间的梯度差异。如下伪代码是计算过程。</p>
<h2 id="pytorch-RMSProp参数"><a href="#pytorch-RMSProp参数" class="headerlink" title="pytorch RMSProp参数"></a><a class="link"   target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020" >pytorch <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> RMSProp参数</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.RMSprop(params,</span><br><span class="line">                    lr=<span class="number">0.01</span>,</span><br><span class="line">                    alpha=<span class="number">0.99</span>, <span class="comment">### 平滑常数</span></span><br><span class="line">                    eps=<span class="number">1e-08</span>,  <span class="comment">### epsilon,加在分母上防止除0</span></span><br><span class="line">                    weight_decay=<span class="number">0</span>, <span class="comment">## weight_decay的作用是用当前可学习参数p的值修改偏导数，即</span></span><br><span class="line">                    momentum=<span class="number">0</span>,</span><br><span class="line">                    centered=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>$$<br>alpha 平滑常数 \<br>epsilon,加在分母上防止除0 \<br>weight_decay的作用是用当前可学习参数p的值修改偏导数，即g_t &#x3D; g_t+(p*weight_decay)<br>$$</p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>我们定义一个通用的思路框架，方便在后面理解各算法之间的关系和改进。首先定义待优化参数 $\theta$，目标函数$J(\theta)$，学习率为$\alpha$ ，然后我们进行迭代优化，假设当前的epoch为(<a class="link"   target="_blank" rel="noopener" href="https://latex.csdn.net/eq?t)%EF%BC%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E6%AD%A5%E9%AA%A4%E5%A6%82%E4%B8%8B%EF%BC%9A" >https://latex.csdn.net/eq?t)，参数更新步骤如下： <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<ol>
<li>计算目标函数关于当前参数的梯度：</li>
</ol>
<p>$$<br>\begin{equation}g_t&#x3D; \nabla J(\theta)\end{equation}\tag{1}<br>$$</p>
<ol start="2">
<li><p>根据历史梯度计算一阶动量和二阶动量 $m_t和v_t$</p>
</li>
<li><p>计算当前时刻的下降梯度</p>
</li>
</ol>
<p>$$<br>\eta_t &#x3D; α·m_t&#x2F;\sqrt{V_t} \tag{2}<br>$$</p>
<ol start="4">
<li>根据下降梯度进行更新：</li>
</ol>
<p>$$<br>\theta_{t+1} &#x3D; \theta_t-\eta_t \tag{3}<br>$$</p>
<p>下面介绍的所有优化算法基本都能套用这个流程，只是式子（3）的形式会有变化。</p>
<h1 id="SGD随机梯度下降"><a href="#SGD随机梯度下降" class="headerlink" title="SGD随机梯度下降"></a>SGD随机梯度下降</h1><p>随机梯度下降每一次随机对一个训练样本计算梯度，并更新参数θ<br>$$<br>\theta &#x3D; \theta -\eta ·\nabla_{\theta}J(\theta:minibatch) 		\tag{6}<br>$$<br>优点：</p>
<ul>
<li>由于一次只用一个数据，因此梯度更新很快</li>
<li>也会处于一个高 variance 的状态，更新时 loss 比较震荡，可能会使得其跳出局部最优点到达一个更好的局部最优。</li>
</ul>
<p>缺点：</p>
<ul>
<li>选择合适的学习率仍然是一个玄学</li>
<li>学习率 schedule 需要预设不能自适应数据集的特点</li>
<li>学习率针对所有参数，而并非所有参数需要同样的学习率</li>
<li>对于非凸问题极易陷入局部最优</li>
</ul>
<h2 id="SGD-with-Momentum"><a href="#SGD-with-Momentum" class="headerlink" title="SGD with Momentum"></a>SGD with Momentum</h2><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.SGD(params, lr=&lt;<span class="built_in">object</span> <span class="built_in">object</span>&gt;, momentum=<span class="number">0</span>, dampening=<span class="number">0</span>, weight_decay=<span class="number">0</span>, nesterov=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>动量是一种有助于在相关方向上加速SGD并抑制振荡的方法，<strong>通过将当前梯度与过去梯度加权平均，来获取即将更新的梯度</strong>。如下图b图所示。它通过将过去时间步长的更新向量的一小部分添加到当前更新向量来实现这一点。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://img-blog.csdnimg.cn/img_convert/0ebaf5af890536caa3c97730e7bc5871.png"
                     
                ></p>
<p>参数更新公式如下，其中ρ 是动量衰减率，m是速率（即一阶动量）：<br>$$<br>g_t &#x3D; \nabla_{\theta}J(\theta_{t-1})		 \tag{5}<br>$$</p>
<p>$$<br>m_t &#x3D; \rho *m_{t-1}+g_t 			\tag{6}<br>$$</p>
<p>$$<br>\theta_t &#x3D; \theta_{t-1}-\eta*m_t  		\tag{7}<br>$$</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.SGD(params, lr=<span class="number">0.01</span>, momentum=<span class="number">0</span>, dampening=<span class="number">0</span>, weight_decay=<span class="number">0</span>, nesterov=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>使用了Momentum有如下特点：</p>
<p>优点：加快收敛速度，有一定摆脱局部最优的能力，一定程度上缓解了没有动量的时候的问题</p>
<p>缺点：a.仍然继承了一部分SGD的缺点</p>
<p>​	 b.在随机梯度情况下，NAG对收敛率的作用不是很大</p>
<p>​	 c.Momentum都是为了使梯度更新更灵活。但是人工设计的学习率总是有些生硬</p>
<h1 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h1><p>Adagrad 是一种自适应梯度的优化器，它有什么特点呢？它对不同参数使用不同的学习率，对于更新频率较低的参数施以较大的学习率，对于更新频率较高的参数用以较小的学习率。我们先来看一下公式：$$g_{t,i}&#x3D; \nabla_{\theta_{t}} J(\theta_{t,i})$$</p>
<p>$$g_{t,i}$$代表了第 t 步的第 i 个参数 $$\theta_{t,i}$$ 的梯度，梯度更新则使用下列式子：<br>$$<br>J(\theta_{t+1,i})&#x3D;J(\theta_{t,i})-\frac{\eta}{\sqrt{(G_{t,ii}+\epsilon)}}·g_{t,i} 				\tag{8}<br>$$</p>
<p>实际上，Adagrad 在优化稀疏数据的时候表现会比较好，但是其缺点也是显而易见的，由于 Gt,ii��,�� 是一个非负数，随着步数增加很容易越累积越大，从导致学习率过早变小，学习缓慢。</p>
<p>AdaGrad对学习率进行了一个约束，对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。这样大大提高梯度下降的鲁棒性。而该方法中开始使用二阶动量，才意味着“自适应学习率”优化算法时代的到来。<br>        在SGD中，我们每次迭代对所有参数进行更新，因为每个参数使用相同的学习率。而AdaGrad在每个时间步长对每个参数使用不同的学习率。AdaGrad消除了手动调整学习率的需要。AdaGrad在迭代过程中不断调整学习率，并让目标函数中的每个参数都分别拥有自己的学习率。大多数实现使用学习率默认值为0.01，开始设置一个较大的学习率。<br> AdaGrad引入了二阶动量。二阶动量是迄今为止所有梯度值的平方$ V_t&#x3D;\sum_{t}^{i&#x3D;1}g^{2}<em>{i}$它是用来度量历史更新频率的。也就是说，我们的学习率现在是**$\frac{\eta}{\sqrt{(G_{t,ii}+\epsilon)}}$**从这里我们就会发现分母恒大于0，而且参数更新越频繁，二阶动量越大，学习率就越小，这一方法在稀疏数据场景下表现非常好，参数更新公式如下：<br>$$<br>v_t &#x3D; \sum</em>{i&#x3D;1}^{t}g_{t}^{2}			\tag{9}<br>$$</p>
<p>$$<br>\theta_t&#x3D;\theta_{t-1}-\frac{\eta}{\sqrt{v_t+\epsilon}} *g_t			\tag{10}<br>$$</p>
<p><strong>显然$\frac{\eta}{\sqrt{(G_{t,ii}+\epsilon)}}$会趋近于0</strong>，</p>
<p><strong>总结</strong></p>
<p>​        AdaGrad在每个时间步长对每个参数使用不同的学习率。并且引入了二阶动量，二阶动量是迄今为止所有梯度值的平方和。</p>
<p>优点：AdaGrad消除了手动调整学习率的需要。AdaGrad在迭代过程中不断调整学习率，并让目标函数中的每个参数都分别拥有自己的学习率。</p>
<p>缺点：a.仍需要手工设置一个全局学习率  , 如果  设置过大的话，会使regularizer过于敏感，对梯度的调节太大</p>
<p>​    b.<strong>在分母中累积平方梯度，由于每个添加项都是正数，因此在训练过程中累积和不断增长</strong>。这导致学习率不断变小并最终变得无限小，此时算法不再能够获得额外的知识即导致模型不会再次学习。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">params (iterable) – 待优化参数的iterable或者是定义了参数组的dict</span></span><br><span class="line"><span class="string">lr (float, 可选) – 学习率（默认: 1e-2）</span></span><br><span class="line"><span class="string">lr_decay (float, 可选) – 学习率衰减（默认: 0）</span></span><br><span class="line"><span class="string">weight_decay (float, 可选) – 权重衰减（L2惩罚）（默认: 0）</span></span><br><span class="line"><span class="string">initial_accumulator_value - 累加器的起始值，必须为正。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.Adagrad(params, lr=<span class="number">0.01</span>, lr_decay=<span class="number">0</span>, weight_decay=<span class="number">0</span>, initial_accumulator_value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></div>



<h1 id="RMSProp-1"><a href="#RMSProp-1" class="headerlink" title="RMSProp"></a>RMSProp</h1><p>RMSProp算法有效解决了这个问题。通过累计各个变量的梯度的平方r，然后用每个变量的梯度除以r，即可有效缓解变量间的梯度差异。如下伪代码是计算过程。</p>
<p> 该类实现 RMSprop 优化方法（Hinton 提出），RMS 是均方根（root meam square）的意思。RMSprop 和 Adadelta 一样，也是对 Adagrad 的一种改进。RMSprop 采用<strong>均方根作为分母</strong>，可缓解 Adagrad 学习率下降较快的问题，并且引入均方根，可以减少摆动。</p>
<p>RMSprop与Adadelta属于同一时期的作品，都是对Adagrad的优化，解决了Adagrad多次迭代后，学习率将逐渐下降至0的问题。RMSProp算法将AdaGrad的梯度平方和累改加为指数加权的移动平均，使得其在非凸设定下效果更好。设定参数：全局初始率 $l$默认设为0.001，decay rate$\rho$ ，默认设置为0.9，一个极小的常量$\epsilon$  ，通常为10e-6，参数更新公式如下：</p>
<p>$$<br>v_t &#x3D;\rho v_{t-1}+(1-\rho)g_{t}^2			\tag{11}<br>$$</p>
<p>$$<br>\theta_t&#x3D;\theta_{t-1}-\frac{\eta}{\sqrt{v_t}+\epsilon} *g_t			\tag{10}<br>$$</p>
<p> 可以看到式子（15）和Adadelta的（13）的分母是基本一样的（只是的位置有所区别），两者虽然思想不一样，但是实现一样的，都是指数加权的移动平均，也算殊途同归了。</p>
<p><strong>总结</strong></p>
<p> RMSprop算是Adagrad的一种发展，用梯度平方的指数加权平均代替了全部梯度的平方和，相当于只实现了Adadelta的第一个修改，效果趋于RMSprop和Adadelta二者之间。</p>
<p>优点：适合处理非平稳目标(包括季节性和周期性)——对于RNN效果很好</p>
<p>缺点：RMSprop依然依赖于全局学习率 </p>
<p><a class="link"   target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020" >pytorch <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> RMSProp参数</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.RMSprop(params,</span><br><span class="line">                    lr=<span class="number">0.01</span>,</span><br><span class="line">                    alpha=<span class="number">0.99</span>, <span class="comment">### 平滑常数</span></span><br><span class="line">                    eps=<span class="number">1e-08</span>,  <span class="comment">### epsilon,加在分母上防止除0</span></span><br><span class="line">                    weight_decay=<span class="number">0</span>, <span class="comment">## weight_decay的作用是用当前可学习参数p的值修改偏导数，即</span></span><br><span class="line">                    momentum=<span class="number">0</span>,</span><br><span class="line">                    centered=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div>

<p>$alpha 平滑常数$<br>$epsilon,加在分母上防止除0 $</p>
<p>$weight_decay的作用是用当前可学习参数p的值修改偏导数，即g_t &#x3D; g_t+(p*weight_decay)$</p>
<h1 id="Adam-1"><a href="#Adam-1" class="headerlink" title="Adam"></a>Adam</h1><p>**torch.optim.Adam,**该类实现 Adam(Adaptive Moment Estimation))优化方法。Adam 是一种自适应学习率的优化方法，Adam 利用梯度的一阶矩估计和二阶矩估计动态的调整学习率。Adam 是结合了 Momentum 和 RMSprop，并进行了偏差修正。 了解了Adagrad 和RMSProp。</p>
<p>​    <strong>在adam中，一阶矩来控制模型更新的方向，二阶矩控制步长(学习率)。利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。</strong></p>
<p>$$<br>m_t &#x3D; \beta_1*m_{t-1}+(1-\beta_1)*g_t 		\tag{13}<br>$$</p>
<p>$$<br>v_t  &#x3D;\beta_2*v_{t-1}+(1-\beta_2)*g_t^2			\tag{14}<br>$$</p>
<p>$$<br>\hat{m_t}&#x3D;\frac{m_t}{1-\beta_1^t}		\tag{15}<br>$$</p>
<p>$$<br>\hat{v_t}&#x3D;\frac{v_t}{1-\beta_2^t}   \tag{16}<br>$$</p>
<p>$$<br>\theta_t &#x3D; \theta_{t-1}-\eta*\frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}				\tag{17}<br>$$</p>
<p>式子(17)更新模型参数 ，分子表示在过去一段时间内各分量的平均值，即梯度更新的大致走向，分母表示在过去一段时间内各分量的平均大小。相当于分两步走，第一步是确定一个合适的下降方向（即分子项），第二步，对这个选定的方向上的各个子方向做一下微调（分母项），这样，推进较快的子方向会慢下来，推进较慢的子方向会加快速度，动态调整了各个子方向的学习率。因此，Adam结合了Momentum和RMSprop两种算法的优点</p>
<p>主要包含以下几个显著的优点：</p>
<p>\1. 实现简单，计算高效，对内存需求少</p>
<p>\2. 参数的更新不受梯度的伸缩变换影响</p>
<p>\3. 超参数具有很好的解释性，且通常无需调整或仅需很少的微调</p>
<p>\4. 更新的步长能够被限制在大致的范围内（初始学习率）</p>
<p>\5. 能自然地实现步长退火过程（自动调整学习率）</p>
<p>\6. 很适合应用于大规模的数据及参数的场景</p>
<p>\7. 适用于不稳定目标函数</p>
<p>\8. 适用于梯度稀疏或梯度存在很大噪声的问题</p>
<p>β1 系数为指数衰减率，控制权重分配（动量与当前梯度），通常取接近于1的值。</p>
<p>β2 系数为指数衰减率，控制之前的梯度平方的影响情况。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.optim.Adam(params, lr=<span class="number">0.001</span>, betas=(<span class="number">0.9</span>, <span class="number">0.999</span>), eps=<span class="number">1e-08</span>, weight_decay=<span class="number">0</span>)   <span class="comment">#betas(β1,β2)</span></span><br></pre></td></tr></table></figure></div>



<ol>
<li><p>初始：学习率$\eta$，平滑常数(或者叫做衰减速率) $\beta_1 $, $\beta_2 $，分别用于平滑m和v，全局模型$g_t$，本地模型$w_t$，全局回合t</p>
</li>
<li><p>服务器：</p>
<p>$g_t&#x3D;\sum_1^nw_{t-1}^i$ </p>
<p>$m_t &#x3D; \beta_1*m_{t-1}+(1-\beta_1)*g_t 		\tag{13}$</p>
<p>$v_t  &#x3D;\beta_2*v_{t-1}+(1-\beta_2)*g_t^2			\tag{14}$</p>
</li>
<li><p>客户端：</p>
<p>$\hat{w_t} &#x3D; w_{t-1}-\eta *\frac{m_t}{\sqrt{v_t}+\epsilon}				\tag{17}$</p>
<p>local.train($\hat{w_t}$)</p>
</li>
<li></li>
<li></li>
<li><p>服务器：</p>
<p>​	初始化</p>
<p>​	$m_t &#x3D; \beta_1*m_{t-1}+(1-\beta_1)*g_t 		\tag{13}$</p>
<p>​	$v_t  &#x3D;\beta_2*v_{t-1}+(1-\beta_2)*g_t^2			\tag{14}$</p>
<ol start="6">
<li></li>
</ol>
<p>​	</p>
</li>
<li><p>客户端$i$：</p>
</li>
</ol>
<p>​	$w_t^i$→$w_{t1}^i$,$w_{t2}^i$,$w_{t3}^i$</p>
<ol start="2">
<li>服务器:</li>
</ol>
<p>​	服务器1：$\hat{g}<em>{t1}&#x3D;\sum_1^nw</em>{t1}^i$   </p>
<p>​					$g_{t1}$ &#x3D; $\hat{g}_{t1}$+$nosiy$</p>
<p>​	服务器2：$\hat{g}<em>{t2}&#x3D;\sum_1^nw</em>{t2}^i$ </p>
<p>​					$g_{t2}$ &#x3D; $\hat{g}_{t2}$+$nosiy$</p>
<p>​	服务器3：$\hat{g}<em>{t3}&#x3D;\sum_1^nw</em>{t3}^i$ </p>
<p>​					$g_{t3}$ &#x3D; $\hat{g}_{t3}$+$nosiy$</p>
<p>​	$g_{t}&#x3D;$$g_{t1}$ +$g_{t2}$ +$g_{t3}$ </p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li><strong>标题:</strong> Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad</li>
        <li><strong>作者:</strong> 深情小小侯</li>
        <li><strong>创建于
                :</strong> 2024-01-03 09:30:29</li>
        
            <li>
                <strong>更新于
                    :</strong> 2024-06-05 22:30:01
            </li>
        
        <li>
            <strong>链接:</strong> https://redefine.ohevan.com/2024/01/03/Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad/
        </li>
        <li>
            <strong>
                版权声明:
            </strong>
            
            本文章采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a> 进行许可。
            

        </li>
    </ul>
</div>

            </div>
        

        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                        rel="prev"
                        href="/2024/01/03/Pytorch%E4%BC%98%E5%8C%96%E5%99%A8SGD%E3%80%81SGDM%E3%80%81Rprop%E3%80%81Adagrad%E3%80%81Adma/"
                        >
                            <span class="left arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-left"></i>
                            </span>
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item"></span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                        rel="next"
                        href="/2023/12/25/%E2%80%9C%E6%9D%8E%E6%B2%90%E8%8A%B1%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%9D/"
                        >
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">“基础模型pytorch学习笔记”</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                            <span class="right arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        


        
            <div class="comment-container">
                <div class="comments-container pjax">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;评论
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-swup-reload-script>
        import { init } from '/js/libs/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

            </div>
        
    </div>

    
        <div class="toc-content-container">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">此页目录</div>
        <div class="page-title">Pytorch优化器全总结（一）SGD、ASGD、Rprop、Adagrad</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Adam"><span class="nav-number">1.</span> <span class="nav-text">Adam</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#RMSProp"><span class="nav-number">1.1.</span> <span class="nav-text">RMSProp</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch-RMSProp%E5%8F%82%E6%95%B0"><span class="nav-number">1.2.</span> <span class="nav-text">pytorch  RMSProp参数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="nav-number">2.</span> <span class="nav-text">写在前面</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SGD%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">3.</span> <span class="nav-text">SGD随机梯度下降</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SGD-with-Momentum"><span class="nav-number">3.1.</span> <span class="nav-text">SGD with Momentum</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AdaGrad"><span class="nav-number">4.</span> <span class="nav-text">AdaGrad</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RMSProp-1"><span class="nav-number">5.</span> <span class="nav-text">RMSProp</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adam-1"><span class="nav-number">6.</span> <span class="nav-text">Adam</span></a></li></ol>

    </div>
</div>
        </div>
    
</div>



                

            </div>

            

        </div>

        <div class="main-content-footer">
            <footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
        <div class="text-center">
            &copy;
            
              <span>2022</span>
              -
            
            2024&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">深情小小侯</a>
        </div>
        
            <script data-swup-reload-script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">访问人数</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">总访问量</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a> 驱动</span>
            <span class="text-sm lg:block">主题&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.5.0</a></span>
        </div>
        
        
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    

</main>


    
<script src="/js/libs/Swup.min.js"></script>

<script src="/js/libs/SwupSlideTheme.min.js"></script>

<script src="/js/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/libs/SwupScrollPlugin.min.js"></script>

<script src="/js/libs/SwupPreloadPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
            new SwupPreloadPlugin(),
        ],
        containers: ["#swup"],
    });
</script>







<script src="/js/tools/imageViewer.js" type="module"></script>

<script src="/js/utils.js" type="module"></script>

<script src="/js/main.js" type="module"></script>

<script src="/js/layouts/navbarShrink.js" type="module"></script>

<script src="/js/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/layouts/categoryList.js" type="module"></script>





    
<script src="/js/tools/codeBlock.js" type="module"></script>




    
<script src="/js/layouts/lazyload.js" type="module"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js" type="module"></script>






    
<script src="/js/libs/minimasonry.min.js"></script>

    
<script src="/js/plugins/masonry.js" type="module"></script>




<div class="post-scripts" data-swup-reload-script>
    
        
<script src="/js/libs/anime.min.js"></script>

        
<script src="/js/tools/tocToggle.js" type="module"></script>

<script src="/js/layouts/toc.js" type="module"></script>

<script src="/js/plugins/tabs.js" type="module"></script>

    
</div>


</body>
</html>
